<!--
Google IO 2012 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mahe <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title>Haskell</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="all" href="theme/css/tomamic.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

<slide class="title-slide segue nobackground">
  <aside class="gdbar"><img src="images/logo.png"></aside>
  <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
  <h1 data-config-title><!-- populated from slide_config.json --></h1>
  <figure><img src="images/fun/function.png"></figure>
  <hgroup>
    <h2>Functional programming</h2>
    <p>Michele Tomaiuolo<br>Ingegneria dell'Informazione, UniPR</p>
  </hgroup>
</slide>


<slide  >
  
    <hgroup>
      <h2>Interactive shell</h2>
      <h3></h3>
    </hgroup>
    <article >
      <ul>
<li>Install the “<em>Glasgow Haskell Compiler</em>”<ul>
<li><code>sudo apt install ghc</code></li>
</ul>
</li>
<li>REPL: Read-Eval-Print Loop<ul>
<li><code>ghci</code></li>
</ul>
</li>
<li>Expressions an operators<ul>
<li><code>+, -, *, /, ^, **</code></li>
<li><code>&amp;&amp;, ||, not</code></li>
<li><code>==, /=, &lt;, &lt;=, &gt;, &gt;=</code></li>
</ul>
</li>
</ul>
<pre class="prettyprint" data-lang="haskell"><code>Prelude&gt; 2 ^ 3
8
</code></pre></article>
 
</slide>

<slide  >
  
    <hgroup>
      <h2>Input and Output</h2>
      <h3></h3>
    </hgroup>
    <article >
      <p>We've mentioned that Haskell is a purely functional language. Whereas in imperative languages you usually get things done by giving the computer a series of steps to execute, functional programming is more of defining what stuff is. In Haskell, a function can't change some state, like changing the contents of a variable (when a function changes state, we say that the function has side-effects). The only thing a function can do in Haskell is give us back some result based on the parameters we gave it. If a function is called two times with the same parameters, it has to return the same result. While this may seem a bit limiting when you're coming from an imperative world, we've seen that it's actually really cool. In an imperative language, you have no guarantee that a simple function that should just crunch some numbers won't burn down your house, kidnap your dog and scratch your car with a potato while crunching those numbers. For instance, when we were making a binary search tree, we didn't insert an element into a tree by modifying some tree in place. Our function for inserting into a binary search tree actually returned a new tree, because it can't change the old one.</p>
<p>While functions being unable to change state is good because it helps us reason about our programs, there's one problem with that. If a function can't change anything in the world, how is it supposed to tell us what it calculated? In order to tell us what it calculated, it has to change the state of an output device (usually the state of the screen), which then emits photons that travel to our brain and change the state of our mind, man.</p>
<p>Do not despair, all is not lost. It turns out that Haskell actually has a really clever system for dealing with functions that have side-effects that neatly separates the part of our program that is pure and the part of our program that is impure, which does all the dirty work like talking to the keyboard and the screen. With those two parts separated, we can still reason about our pure program and take advantage of all the things that purity offers, like laziness, robustness and modularity while efficiently communicating with the outside world.
Hello, world!
HELLO!</p>
<p>Up until now, we've always loaded our functions into GHCI to test them out and play with them. We've also explored the standard library functions that way. But now, after eight or so chapters, we're finally going to write our first real Haskell program! Yay! And sure enough, we're going to do the good old "hello, world" schtick.
Hey! For the purposes of this chapter, I'm going to assume you're using a unix-y environment for learning Haskell. If you're in Windows, I'd suggest you download Cygwin, which is a Linux-like environment for Windows, A.K.A. just what you need.</p>
<p>So, for starters, punch in the following in your favorite text editor:</p>
<pre><code>main = putStrLn "hello, world"
</code></pre>
<p>We just defined a name called main and in it we call a function called putStrLn with the parameter "hello, world". Looks pretty much run of the mill, but it isn't, as we'll see in just a few moments. Save that file as helloworld.hs.</p>
<p>And now, we're going to do something we've never done before. We're actually going to compile our program! I'm so excited! Open up your terminal and navigate to the directory where helloworld.hs is located and do the following:</p>
<pre><code>$ ghc --make helloworld  
[1 of 1] Compiling Main             ( helloworld.hs, helloworld.o )  
Linking helloworld ...
</code></pre>
<p>Okay! With any luck, you got something like this and now you can run your program by doing ./helloworld.</p>
<pre><code>$ ./helloworld  
hello, world
</code></pre>
<p>And there we go, our first compiled program that printed out something to the terminal. How extraordinarily boring!</p>
<p>Let's examine what we wrote. First, let's look at the type of the function putStrLn.</p>
<pre><code>ghci&gt; :t putStrLn  
putStrLn :: String -&gt; IO ()  
ghci&gt; :t putStrLn "hello, world"  
putStrLn "hello, world" :: IO ()
</code></pre>
<p>We can read the type of putStrLn like this: putStrLn takes a string and returns an I/O action that has a result type of () (i.e. the empty tuple, also know as unit). An I/O action is something that, when performed, will carry out an action with a side-effect (that's usually either reading from the input or printing stuff to the screen) and will also contain some kind of return value inside it. Printing a string to the terminal doesn't really have any kind of meaningful return value, so a dummy value of () is used.
The empty tuple is a value of () and it also has a type of ().</p>
<p>So, when will an I/O action be performed? Well, this is where main comes in. An I/O action will be performed when we give it a name of main and then run our program.</p>
<p>Having your whole program be just one I/O action seems kind of limiting. That's why we can use do syntax to glue together several I/O actions into one. Take a look at the following example:</p>
<pre><code>main = do  
    putStrLn "Hello, what's your name?"  
    name &lt;- getLine  
    putStrLn ("Hey " ++ name ++ ", you rock!")
</code></pre>
<p>Ah, interesting, new syntax! And this reads pretty much like an imperative program. If you compile it and try it out, it will probably behave just like you expect it to. Notice that we said do and then we laid out a series of steps, like we would in an imperative program. Each of these steps is an I/O action. By putting them together with do syntax, we glued them into one I/O action. The action that we got has a type of IO (), because that's the type of the last I/O action inside.</p>
<p>Because of that, main always has a type signature of main :: IO something, where something is some concrete type. By convention, we don't usually specify a type declaration for main.</p>
<p>An interesting thing that we haven't met before is the third line, which states name &lt;- getLine. It looks like it reads a line from the input and stores it into a variable called name. Does it really? Well, let's examine the type of getLine.</p>
<pre><code>ghci&gt; :t getLine  
getLine :: IO String
</code></pre>
<p>luggage</p>
<p>Aha, o-kay. getLine is an I/O action that contains a result type of String. That makes sense, because it will wait for the user to input something at the terminal and then that something will be represented as a string. So what's up with name &lt;- getLine then? You can read that piece of code like this: perform the I/O action getLine and then bind its result value to name. getLine has a type of IO String, so name will have a type of String. You can think of an I/O action as a box with little feet that will go out into the real world and do something there (like write some graffiti on a wall) and maybe bring back some data. Once it's fetched that data for you, the only way to open the box and get the data inside it is to use the &lt;- construct. And if we're taking data out of an I/O action, we can only take it out when we're inside another I/O action. This is how Haskell manages to neatly separate the pure and impure parts of our code. getLine is in a sense impure because its result value is not guaranteed to be the same when performed twice. That's why it's sort of tainted with the IO type constructor and we can only get that data out in I/O code. And because I/O code is tainted too, any computation that depends on tainted I/O data will have a tainted result.</p>
<p>When I say tainted, I don't mean tainted in such a way that we can never use the result contained in an I/O action ever again in pure code. No, we temporarily un-taint the data inside an I/O action when we bind it to a name. When we do name &lt;- getLine, name is just a normal string, because it represents what's inside the box. We can have a really complicated function that, say, takes your name (a normal string) as a parameter and tells you your fortune and your whole life's future based on your name. We can do this:</p>
<pre><code>main = do  
    putStrLn "Hello, what's your name?"  
    name &lt;- getLine  
    putStrLn $ "Read this carefully, because this is your future: " ++ tellFortune name
</code></pre>
<p>and tellFortune (or any of the functions it passes name to) doesn't have to know anything about I/O, it's just a normal String -&gt; String function!</p>
<p>Take a look at this piece of code. Is it valid?</p>
<pre><code>nameTag = "Hello, my name is " ++ getLine
</code></pre>
<p>If you said no, go eat a cookie. If you said yes, drink a bowl of molten lava. Just kidding, don't! The reason that this doesn't work is that ++ requires both its parameters to be lists over the same type. The left parameter has a type of String (or [Char] if you will), whilst getLine has a type of IO String. You can't concatenate a string and an I/O action. We first have to get the result out of the I/O action to get a value of type String and the only way to do that is to say something like name &lt;- getLine inside some other I/O action. If we want to deal with impure data, we have to do it in an impure environment. So the taint of impurity spreads around much like the undead scourge and it's in our best interest to keep the I/O parts of our code as small as possible.</p>
<p>Every I/O action that gets performed has a result encapsulated within it. That's why our previous example program could also have been written like this:</p>
<pre><code>main = do  
    foo &lt;- putStrLn "Hello, what's your name?"  
    name &lt;- getLine  
    putStrLn ("Hey " ++ name ++ ", you rock!")
</code></pre>
<p>However, foo would just have a value of (), so doing that would be kind of moot. Notice that we didn't bind the last putStrLn to anything. That's because in a do block, the last action cannot be bound to a name like the first two were. We'll see exactly why that is so a bit later when we venture off into the world of monads. For now, you can think of it in the way that the do block automatically extracts the value from the last action and binds it to its own result.</p>
<p>Except for the last line, every line in a do block that doesn't bind can also be written with a bind. So putStrLn "BLAH" can be written as _ &lt;- putStrLn "BLAH". But that's useless, so we leave out the &lt;- for I/O actions that don't contain an important result, like putStrLn something.</p>
<p>Beginners sometimes think that doing</p>
<pre><code>name = getLine
</code></pre>
<p>will read from the input and then bind the value of that to name. Well, it won't, all this does is give the getLine I/O action a different name called, well, name. Remember, to get the value out of an I/O action, you have to perform it inside another I/O action by binding it to a name with &lt;-.</p>
<p>I/O actions will only be performed when they are given a name of main or when they're inside a bigger I/O action that we composed with a do block. We can also use a do block to glue together a few I/O actions and then we can use that I/O action in another do block and so on. Either way, they'll be performed only if they eventually fall into main.</p>
<p>Oh, right, there's also one more case when I/O actions will be performed. When we type out an I/O action in GHCI and press return, it will be performed.</p>
<pre><code>ghci&gt; putStrLn "HEEY"  
HEEY
</code></pre>
<p>Even when we just punch out a number or call a function in GHCI and press return, it will evaluate it (as much as it needs) and then call show on it and then it will print that string to the terminal using putStrLn implicitly.</p>
<p>Remember let bindings? If you don't, refresh your memory on them by reading this section. They have to be in the form of let bindings in expression, where bindings are names to be given to expressions and expression is the expression that is to be evaluated that sees them. We also said that in list comprehensions, the in part isn't needed. Well, you can use them in do blocks pretty much like you use them in list comprehensions. Check this out:</p>
<pre><code>import Data.Char

main = do  
    putStrLn "What's your first name?"  
    firstName &lt;- getLine  
    putStrLn "What's your last name?"  
    lastName &lt;- getLine  
    let bigFirstName = map toUpper firstName  
        bigLastName = map toUpper lastName  
    putStrLn $ "hey " ++ bigFirstName ++ " " ++ bigLastName ++ ", how are you?"
</code></pre>
<p>See how the I/O actions in the do block are lined up? Also notice how the let is lined up with the I/O actions and the names of the let are lined up with each other? That's good practice, because indentation is important in Haskell. Now, we did map toUpper firstName, which turns something like "John" into a much cooler string like "JOHN". We bound that uppercased string to a name and then used it in a string later on that we printed to the terminal.</p>
<p>You may be wondering when to use &lt;- and when to use let bindings? Well, remember, &lt;- is (for now) for performing I/O actions and binding their results to names. map toUpper firstName, however, isn't an I/O action. It's a pure expression in Haskell. So use &lt;- when you want to bind results of I/O actions to names and you can use let bindings to bind pure expressions to names. Had we done something like let firstName = getLine, we would have just called the getLine I/O action a different name and we'd still have to run it through a &lt;- to perform it.</p>
<p>Now we're going to make a program that continuously reads a line and prints out the same line with the words reversed. The program's execution will stop when we input a blank line. This is the program:</p>
<pre><code>main = do   
    line &lt;- getLine  
    if null line  
        then return ()  
        else do  
            putStrLn $ reverseWords line  
            main

reverseWords :: String -&gt; String  
reverseWords = unwords . map reverse . words
</code></pre>
<p>To get a feel of what it does, you can run it before we go over the code.
Protip: To run a program you can either compile it and then run the produced executable file by doing ghc --make helloworld and then ./helloworld or you can use the runhaskell command like so: runhaskell helloworld.hs and your program will be executed on the fly.</p>
<p>First, let's take a look at the reverseWords function. It's just a normal function that takes a string like "hey there man" and then calls words with it to produce a list of words like ["hey","there","man"]. Then we map reverse on the list, getting ["yeh","ereht","nam"] and then we put that back into one string by using unwords and the final result is "yeh ereht nam". See how we used function composition here. Without function composition, we'd have to write something like reverseWords st = unwords (map reverse (words st)).</p>
<p>What about main? First, we get a line from the terminal by performing getLine call that line line. And now, we have a conditional expression. Remember that in Haskell, every if must have a corresponding else because every expression has to have some sort of value. We make the if so that when a condition is true (in our case, the line that we entered is blank), we perform one I/O action and when it isn't, the I/O action under the else is performed. That's why in an I/O do block, ifs have to have a form of if condition then I/O action else I/O action.</p>
<p>Let's first take a look at what happens under the else clause. Because, we have to have exactly one I/O action after the else, we use a do block to glue together two I/O actions into one. You could also write that part out as:</p>
<pre><code>else (do  
    putStrLn $ reverseWords line  
    main)
</code></pre>
<p>This makes it more explicit that the do block can be viewed as one I/O action, but it's uglier. Anyway, inside the do block, we call reverseWords on the line that we got from getLine and then print that out to the terminal. After that, we just perform main. It's called recursively and that's okay, because main is itself an I/O action. So in a sense, we go back to the start of the program.</p>
<p>Now what happens when null line holds true? What's after the then is performed in that case. If we look up, we'll see that it says then return (). If you've done imperative languages like C, Java or Python, you're probably thinking that you know what this return does and chances are you've already skipped this really long paragraph. Well, here's the thing: the return in Haskell is really nothing like the return in most other languages! It has the same name, which confuses a lot of people, but in reality it's quite different. In imperative languages, return usually ends the execution of a method or subroutine and makes it report some sort of value to whoever called it. In Haskell (in I/O actions specifically), it makes an I/O action out of a pure value. If you think about the box analogy from before, it takes a value and wraps it up in a box. The resulting I/O action doesn't actually do anything, it just has that value encapsulated as its result. So in an I/O context, return "haha" will have a type of IO String. What's the point of just transforming a pure value into an I/O action that doesn't do anything? Why taint our program with IO more than it has to be? Well, we needed some I/O action to carry out in the case of an empty input line. That's why we just made a bogus I/O action that doesn't do anything by writing return ().</p>
<p>Using return doesn't cause the I/O do block to end in execution or anything like that. For instance, this program will quite happily carry out all the way to the last line:</p>
<pre><code>main = do  
    return ()  
    return "HAHAHA"  
    line &lt;- getLine  
    return "BLAH BLAH BLAH"  
    return 4  
    putStrLn line
</code></pre>
<p>All these returns do is that they make I/O actions that don't really do anything except have an encapsulated result and that result is thrown away because it isn't bound to a name. We can use return in combination with &lt;- to bind stuff to names.</p>
<pre><code>main = do  
    a &lt;- return "hell"  
    b &lt;- return "yeah!"  
    putStrLn $ a ++ " " ++ b
</code></pre>
<p>So you see, return is sort of the opposite to &lt;-. While return takes a value and wraps it up in a box, &lt;- takes a box (and performs it) and takes the value out of it, binding it to a name. But doing this is kind of redundant, especially since you can use let bindings in do blocks to bind to names, like so:</p>
<pre><code>main = do  
    let a = "hell"  
        b = "yeah"  
    putStrLn $ a ++ " " ++ b
</code></pre>
<p>When dealing with I/O do blocks, we mostly use return either because we need to create an I/O action that doesn't do anything or because we don't want the I/O action that's made up from a do block to have the result value of its last action, but we want it to have a different result value, so we use return to make an I/O action that always has our desired result contained and we put it at the end.
A do block can also have just one I/O action. In that case, it's the same as just writing the I/O action. Some people would prefer writing then do return () in this case because the else also has a do.</p>
<p>Before we move on to files, let's take a look at some functions that are useful when dealing with I/O.</p>
<p>putStr is much like putStrLn in that it takes a string as a parameter and returns an I/O action that will print that string to the terminal, only putStr doesn't jump into a new line after printing out the string while putStrLn does.</p>
<pre><code>main = do   putStr "Hey, "  
            putStr "I'm "  
            putStrLn "Andy!"

$ runhaskell putstr_test.hs  
Hey, I'm Andy!
</code></pre>
<p>Its type signature is putStr :: String -&gt; IO (), so the result encapsulated within the resulting I/O action is the unit. A dud value, so it doesn't make sense to bind it.</p>
<p>putChar takes a character and returns an I/O action that will print it out to the terminal.</p>
<pre><code>main = do   putChar 't'  
            putChar 'e'  
            putChar 'h'

$ runhaskell putchar_test.hs  
teh
</code></pre>
<p>putStr is actually defined recursively with the help of putChar. The edge condition of putStr is the empty string, so if we're printing an empty string, just return an I/O action that does nothing by using return (). If it's not empty, then print the first character of the string by doing putChar and then print of them using putStr.</p>
<pre><code>putStr :: String -&gt; IO ()  
putStr [] = return ()  
putStr (x:xs) = do  
    putChar x  
    putStr xs
</code></pre>
<p>See how we can use recursion in I/O, just like we can use it in pure code. Just like in pure code, we define the edge case and then think what the result actually is. It's an action that first outputs the first character and then outputs the rest of the string.</p>
<p>print takes a value of any type that's an instance of Show (meaning that we know how to represent it as a string), calls show with that value to stringify it and then outputs that string to the terminal. Basically, it's just putStrLn . show. It first runs show on a value and then feeds that to putStrLn, which returns an I/O action that will print out our value.</p>
<pre><code>main = do   print True  
            print 2  
            print "haha"  
            print 3.2  
            print [3,4,3]

$ runhaskell print_test.hs  
True  
2  
"haha"  
3.2  
[3,4,3]
</code></pre>
<p>As you can see, it's a very handy function. Remember how we talked about how I/O actions are performed only when they fall into main or when we try to evaluate them in the GHCI prompt? When we type out a value (like 3 or [1,2,3]) and press the return key, GHCI actually uses print on that value to display it on our terminal!</p>
<pre><code>ghci&gt; 3  
3  
ghci&gt; print 3  
3  
ghci&gt; map (++"!") ["hey","ho","woo"]  
["hey!","ho!","woo!"]  
ghci&gt; print (map (++"!") ["hey","ho","woo"])  
["hey!","ho!","woo!"]
</code></pre>
<p>When we want to print out strings, we usually use putStrLn because we don't want the quotes around them, but for printing out values of other types to the terminal, print is used the most.</p>
<p>getChar is an I/O action that reads a character from the input. Thus, its type signature is getChar :: IO Char, because the result contained within the I/O action is a Char. Note that due to buffering, reading of the characters won't actually happen until the user mashes the return key.</p>
<pre><code>main = do     
    c &lt;- getChar  
    if c /= ' '  
        then do  
            putChar c  
            main  
        else return ()
</code></pre>
<p>This program looks like it should read a character and then check if it's a space. If it is, halt execution and if it isn't, print it to the terminal and then do the same thing all over again. Well, it kind of does, only not in the way you might expect. Check this out:</p>
<pre><code>$ runhaskell getchar_test.hs  
hello sir  
hello
</code></pre>
<p>The second line is the input. We input hello sir and then press return. Due to buffering, the execution of the program will begin only when after we've hit return and not after every inputted character. But once we press return, it acts on what we've been putting in so far. Try playing with this program to get a feel for it!</p>
<p>The when function is found in Control.Monad (to get access to it, do import Control.Monad). It's interesting because in a do block it looks like a control flow statement, but it's actually a normal function. It takes a boolean value and an I/O action if that boolean value is True, it returns the same I/O action that we supplied to it. However, if it's False, it returns the return (), action, so an I/O action that doesn't do anything. Here's how we could rewrite the previous piece of code with which we demonstrated getChar by using when:</p>
<pre><code>import Control.Monad

main = do  
    c &lt;- getChar  
    when (c /= ' ') $ do  
        putChar c  
        main
</code></pre>
<p>So as you can see, it's useful for encapsulating the if something then do some I/O action else return () pattern.</p>
<p>sequence takes a list of I/O actions and returns an I/O actions that will perform those actions one after the other. The result contained in that I/O action will be a list of the results of all the I/O actions that were performed. Its type signature is sequence :: [IO a] -&gt; IO [a]. Doing this:</p>
<pre><code>main = do  
    a &lt;- getLine  
    b &lt;- getLine  
    c &lt;- getLine  
    print [a,b,c]
</code></pre>
<p>Is exactly the same as doing this:.</p>
<pre><code>main = do  
    rs &lt;- sequence [getLine, getLine, getLine]  
    print rs
</code></pre>
<p>So sequence [getLine, getLine, getLine] makes an I/O action that will perform getLine three times. If we bind that action to a name, the result is a list of all the results, so in our case, a list of three things that the user entered at the prompt.</p>
<p>A common pattern with sequence is when we map functions like print or putStrLn over lists. Doing map print [1,2,3,4] won't create an I/O action. It will create a list of I/O actions, because that's like writing [print 1, print 2, print 3, print 4]. If we want to transform that list of I/O actions into an I/O action, we have to sequence it.</p>
<pre><code>ghci&gt; sequence (map print [1,2,3,4,5])  
1  
2  
3  
4  
5  
[(),(),(),(),()]
</code></pre>
<p>What's with the [(),(),(),(),()] at the end? Well, when we evaluate an I/O action in GHCI, it's performed and then its result is printed out, unless that result is (), in which case it's not printed out. That's why evaluating putStrLn "hehe" in GHCI just prints out hehe (because the contained result in putStrLn "hehe" is ()). But when we do getLine in GHCI, the result of that I/O action is printed out, because getLine has a type of IO String.</p>
<p>Because mapping a function that returns an I/O action over a list and then sequencing it is so common, the utility functions mapM and mapM_ were introduced. mapM takes a function and a list, maps the function over the list and then sequences it. mapM_ does the same, only it throws away the result later. We usually use mapM_ when we don't care what result our sequenced I/O actions have.</p>
<pre><code>ghci&gt; mapM print [1,2,3]  
1  
2  
3  
[(),(),()]  
ghci&gt; mapM_ print [1,2,3]  
1  
2  
3
</code></pre>
<p>forever takes an I/O action and returns an I/O action that just repeats the I/O action it got forever. It's located in Control.Monad. This little program will indefinitely ask the user for some input and spit it back to him, CAPSLOCKED:</p>
<pre><code>import Control.Monad  
import Data.Char

main = forever $ do  
    putStr "Give me some input: "  
    l &lt;- getLine  
    putStrLn $ map toUpper l
</code></pre>
<p>forM (located in Control.Monad) is like mapM, only that it has its parameters switched around. The first parameter is the list and the second one is the function to map over that list, which is then sequenced. Why is that useful? Well, with some creative use of lambdas and do notation, we can do stuff like this:</p>
<pre><code>import Control.Monad

main = do   
    colors &lt;- forM [1,2,3,4] (\a -&gt; do  
        putStrLn $ "Which color do you associate with the number " ++ show a ++ "?"  
        color &lt;- getLine  
        return color)  
    putStrLn "The colors that you associate with 1, 2, 3 and 4 are: "  
    mapM putStrLn colors
</code></pre>
<p>The (\a -&gt; do ... ) is a function that takes a number and returns an I/O action. We have to surround it with parentheses, otherwise the lambda thinks the last two I/O actions belong to it. Notice that we do return color in the inside do block. We do that so that the I/O action which the do block defines has the result of our color contained within it. We actually didn't have to do that, because getLine already has that contained within it. Doing color &lt;- getLine and then return color is just unpacking the result from getLine and then repackaging it again, so it's the same as just doing getLine. The forM (called with its two parameters) produces an I/O action, whose result we bind to colors. colors is just a normal list that holds strings. At the end, we print out all those colors by doing mapM putStrLn colors.</p>
<p>You can think of forM as meaning: make an I/O action for every element in this list. What each I/O action will do can depend on the element that was used to make the action. Finally, perform those actions and bind their results to something. We don't have to bind it, we can also just throw it away.</p>
<pre><code>$ runhaskell form_test.hs  
Which color do you associate with the number 1?  
white  
Which color do you associate with the number 2?  
blue  
Which color do you associate with the number 3?  
red  
Which color do you associate with the number 4?  
orange  
The colors that you associate with 1, 2, 3 and 4 are:  
white  
blue  
red  
orange
</code></pre>
<p>We could have actually done that without forM, only with forM it's more readable. Normally we write forM when we want to map and sequence some actions that we define there on the spot using do notation. In the same vein, we could have replaced the last line with forM colors putStrLn.</p>
<p>In this section, we learned the basics of input and output. We also found out what I/O actions are, how they enable us to do input and output and when they are actually performed. To reiterate, I/O actions are values much like any other value in Haskell. We can pass them as parameters to functions and functions can return I/O actions as results. What's special about them is that if they fall into the main function (or are the result in a GHCI line), they are performed. And that's when they get to write stuff on your screen or play Yakety Sax through your speakers. Each I/O action can also encapsulate a result with which it tells you what it got from the real world.</p>
<p>Don't think of a function like putStrLn as a function that takes a string and prints it to the screen. Think of it as a function that takes a string and returns an I/O action. That I/O action will, when performed, print beautiful poetry to your terminal.
Files and streams
streams</p>
<p>getChar is an I/O action that reads a single character from the terminal. getLine is an I/O action that reads a line from the terminal. These two are pretty straightforward and most programming languages have some functions or statements that are parallel to them. But now, let's meet getContents. getContents is an I/O action that reads everything from the standard input until it encounters an end-of-file character. Its type is getContents :: IO String. What's cool about getContents is that it does lazy I/O. When we do foo &lt;- getContents, it doesn't read all of the input at once, store it in memory and then bind it to foo. No, it's lazy! It'll say: "Yeah yeah, I'll read the input from the terminal later as we go along, when you really need it!".</p>
<p>getContents is really useful when we're piping the output from one program into the input of our program. In case you don't know how piping works in unix-y systems, here's a quick primer. Let's make a text file that contains the following little haiku:</p>
<pre><code>I'm a lil' teapot  
What's with that airplane food, huh?  
It's so small, tasteless
</code></pre>
<p>Yeah, the haiku sucks, what of it? If anyone knows of any good haiku tutorials, let me know.</p>
<p>Now, recall the little program we wrote when we were introducing the forever function. It prompted the user for a line, returned it to him in CAPSLOCK and then did that all over again, indefinitely. Just so you don't have to scroll all the way back, here it is again:</p>
<pre><code>import Control.Monad  
import Data.Char

main = forever $ do  
    putStr "Give me some input: "  
    l &lt;- getLine  
    putStrLn $ map toUpper l
</code></pre>
<p>We'll save that program as capslocker.hs or something and compile it. And then, we're going to use a unix pipe to feed our text file directly to our little program. We're going to use the help of the GNU cat program, which prints out a file that's given to it as an argument. Check it out, booyaka!</p>
<pre><code>$ ghc --make capslocker   
[1 of 1] Compiling Main             ( capslocker.hs, capslocker.o )  
Linking capslocker ...  
$ cat haiku.txt  
I'm a lil' teapot  
What's with that airplane food, huh?  
It's so small, tasteless  
$ cat haiku.txt | ./capslocker  
I'M A LIL' TEAPOT  
WHAT'S WITH THAT AIRPLANE FOOD, HUH?  
IT'S SO SMALL, TASTELESS  
capslocker &lt;stdin&gt;: hGetLine: end of file
</code></pre>
<p>As you can see, piping the output of one program (in our case that was cat) to the input of another (capslocker) is done with the | character. What we've done is pretty much equivalent to just running capslocker, typing our haiku at the terminal and then issuing an end-of-file character (that's usually done by pressing Ctrl-D). It's like running cat haiku.txt and saying: “Wait, don't print this out to the terminal, tell it to capslocker instead!”.</p>
<p>So what we're essentially doing with that use of forever is taking the input and transforming it into some output. That's why we can use getContents to make our program even shorter and better:</p>
<pre><code>import Data.Char

main = do  
    contents &lt;- getContents  
    putStr (map toUpper contents)
</code></pre>
<p>We run the getContents I/O action and name the string it produces contents. Then, we map toUpper over that string and print that to the terminal. Keep in mind that because strings are basically lists, which are lazy, and getContents is I/O lazy, it won't try to read the whole content at once and store it into memory before printing out the capslocked version. Rather, it will print out the capslocked version as it reads it, because it will only read a line from the input when it really needs to.</p>
<pre><code>$ cat haiku.txt | ./capslocker  
I'M A LIL' TEAPOT  
WHAT'S WITH THAT AIRPLANE FOOD, HUH?  
IT'S SO SMALL, TASTELESS
</code></pre>
<p>Cool, it works. What if we just run capslocker and try to type in the lines ourselves?</p>
<pre><code>$ ./capslocker  
hey ho  
HEY HO  
lets go  
LETS GO
</code></pre>
<p>We got out of that by pressing Ctrl-D. Pretty nice! As you can see, it prints out our capslocked input back to us line by line. When the result of getContents is bound to contents, it's not represented in memory as a real string, but more like a promise that it will produce the string eventually. When we map toUpper over contents, that's also a promise to map that function over the eventual contents. And finally when putStr happens, it says to the previous promise: "Hey, I need a capslocked line!". It doesn't have any lines yet, so it says to contents: "Hey, how about actually getting a line from the terminal?". So that's when getContents actually reads from the terminal and gives a line to the code that asked it to produce something tangible. That code then maps toUpper over that line and gives it to putStr, which prints it. And then, putStr says: "Hey, I need the next line, come on!" and this repeats until there's no more input, which is signified by an end-of-file character.</p>
<p>Let's make program that takes some input and prints out only those lines that are shorter than 10 characters. Observe:</p>
<pre><code>main = do  
    contents &lt;- getContents  
    putStr (shortLinesOnly contents)

shortLinesOnly :: String -&gt; String  
shortLinesOnly input =   
    let allLines = lines input  
        shortLines = filter (\line -&gt; length line &lt; 10) allLines  
        result = unlines shortLines  
    in  result
</code></pre>
<p>We've made our I/O part of the program as short as possible. Because our program is supposed to take some input and print out some output based on the input, we can implement it by reading the input contents, running a function on them and then printing out what the function gave back.</p>
<p>The shortLinesOnly function works like this: it takes a string, like "short\nlooooooooooooooong\nshort again". That string has three lines, two of them are short and the middle one is long. It runs the lines function on that string, which converts it to ["short", "looooooooooooooong", "short again"], which we then bind to the name allLines. That list of string is then filtered so that only those lines that are shorter than 10 characters remain in the list, producing ["short", "short again"]. And finally, unlines joins that list into a single newline delimited string, giving "short\nshort again". Let's give it a go.</p>
<pre><code>i'm short  
so am i  
i am a loooooooooong line!!!  
yeah i'm long so what hahahaha!!!!!!  
short line  
loooooooooooooooooooooooooooong  
short

$ ghc --make shortlinesonly  
[1 of 1] Compiling Main             ( shortlinesonly.hs, shortlinesonly.o )  
Linking shortlinesonly ...  
$ cat shortlines.txt | ./shortlinesonly  
i'm short  
so am i  
short
</code></pre>
<p>We pipe the contents of shortlines.txt into the output of shortlinesonly and as the output, we only get the short lines.</p>
<p>This pattern of getting some string from the input, transforming it with a function and then outputting that is so common that there exists a function which makes that even easier, called interact. interact takes a function of type String -&gt; String as a parameter and returns an I/O action that will take some input, run that function on it and then print out the function's result. Let's modify our program to use that.</p>
<pre><code>main = interact shortLinesOnly

shortLinesOnly :: String -&gt; String  
shortLinesOnly input =   
    let allLines = lines input  
        shortLines = filter (\line -&gt; length line &lt; 10) allLines  
        result = unlines shortLines  
    in  result
</code></pre>
<p>Just to show that this can be achieved in much less code (even though it will be less readable) and to demonstrate our function composition skill, we're going to rework that a bit further.</p>
<pre><code>main = interact $ unlines . filter ((&lt;10) . length) . lines
</code></pre>
<p>Wow, we actually reduced that to just one line, which is pretty cool!</p>
<p>interact can be used to make programs that are piped some contents into them and then dump some result out or it can be used to make programs that appear to take a line of input from the user, give back some result based on that line and then take another line and so on. There isn't actually a real distinction between the two, it just depends on how the user is supposed to use them.</p>
<p>Let's make a program that continuously reads a line and then tells us if the line is a palindrome or not. We could just use getLine to read a line, tell the user if it's a palindrome and then run main all over again. But it's simpler if we use interact. When using interact, think about what you need to do to transform some input into the desired output. In our case, we have to replace each line of the input with either "palindrome" or "not a palindrome". So we have to write a function that transforms something like "elephant\nABCBA\nwhatever" into "not a palindrome\npalindrome\nnot a palindrome". Let's do this!</p>
<pre><code>respondPalindromes contents = unlines (map (\xs -&gt; if isPalindrome xs then "palindrome" else "not a palindrome") (lines contents))  
    where   isPalindrome xs = xs == reverse xs
</code></pre>
<p>Let's write this in point-free.</p>
<pre><code>respondPalindromes = unlines . map (\xs -&gt; if isPalindrome xs then "palindrome" else "not a palindrome") . lines  
    where   isPalindrome xs = xs == reverse xs
</code></pre>
<p>Pretty straightforward. First it turns something like "elephant\nABCBA\nwhatever" into ["elephant", "ABCBA", "whatever"] and then it maps that lambda over it, giving ["not a palindrome", "palindrome", "not a palindrome"] and then unlines joins that list into a single, newline delimited string. Now we can do</p>
<pre><code>main = interact respondPalindromes
</code></pre>
<p>Let's test this out:</p>
<pre><code>$ runhaskell palindromes.hs  
hehe  
not a palindrome  
ABCBA  
palindrome  
cookie  
not a palindrome
</code></pre>
<p>Even though we made a program that transforms one big string of input into another, it acts like we made a program that does it line by line. That's because Haskell is lazy and it wants to print the first line of the result string, but it can't because it doesn't have the first line of the input yet. So as soon as we give it the first line of input, it prints the first line of the output. We get out of the program by issuing an end-of-line character.</p>
<p>We can also use this program by just piping a file into it. Let's say we have this file:</p>
<pre><code>dogaroo  
radar  
rotor  
madam
</code></pre>
<p>and we save it as words.txt. This is what we get by piping it into our program:</p>
<pre><code>$ cat words.txt | runhaskell palindromes.hs  
not a palindrome  
palindrome  
palindrome  
palindrome
</code></pre>
<p>Again, we get the same output as if we had run our program and put in the words ourselves at the standard input. We just don't see the input that palindromes.hs because the input came from the file and not from us typing the words in.</p>
<p>So now you probably see how lazy I/O works and how we can use it to our advantage. You can just think in terms of what the output is supposed to be for some given input and write a function to do that transformation. In lazy I/O, nothing is eaten from the input until it absolutely has to be because what we want to print right now depends on that input.</p>
<p>So far, we've worked with I/O by printing out stuff to the terminal and reading from it. But what about reading and writing files? Well, in a way, we've already been doing that. One way to think about reading from the terminal is to imagine that it's like reading from a (somewhat special) file. Same goes for writing to the terminal, it's kind of like writing to a file. We can call these two files stdout and stdin, meaning standard output and standard input, respectively. Keeping that in mind, we'll see that writing to and reading from files is very much like writing to the standard output and reading from the standard input.</p>
<p>We'll start off with a really simple program that opens a file called girlfriend.txt, which contains a verse from Avril Lavigne's #1 hit Girlfriend, and just prints out out to the terminal. Here's girlfriend.txt:</p>
<pre><code>Hey! Hey! You! You!   
I don't like your girlfriend!   
No way! No way!   
I think you need a new one!
</code></pre>
<p>And here's our program:</p>
<pre><code>import System.IO

main = do  
    handle &lt;- openFile "girlfriend.txt" ReadMode  
    contents &lt;- hGetContents handle  
    putStr contents  
    hClose handle
</code></pre>
<p>Running it, we get the expected result:</p>
<pre><code>$ runhaskell girlfriend.hs  
Hey! Hey! You! You!  
I don't like your girlfriend!  
No way! No way!  
I think you need a new one!
</code></pre>
<p>Let's go over this line by line. The first line is just four exclamations, to get our attention. In the second line, Avril tells us that she doesn't like our current romantic partner. The third line serves to emphasize that disapproval, whereas the fourth line suggests we should seek out a new girlfriend.</p>
<p>Let's also go over the program line by line! Our program is several I/O actions glued together with a do block. In the first line of the do block, we notice a new function called openFile. This is its type signature: openFile :: FilePath -&gt; IOMode -&gt; IO Handle. If you read that out loud, it states: openFile takes a file path and an IOMode and returns an I/O action that will open a file and have the file's associated handle encapsulated as its result.</p>
<p>FilePath is just a type synonym for String, simply defined as:</p>
<pre><code>type FilePath = String
</code></pre>
<p>IOMode is a type that's defined like this:</p>
<pre><code>data IOMode = ReadMode | WriteMode | AppendMode | ReadWriteMode
</code></pre>
<p>A FILE IN A CAKE!!!</p>
<p>Just like our type that represents the seven possible values for the days of the week, this type is an enumeration that represents what we want to do with our opened file. Very simple. Just note that this type is IOMode and not IO Mode. IO Mode would be the type of an I/O action that has a value of some type Mode as its result, but IOMode is just a simple enumeration.</p>
<p>Finally, it returns an I/O action that will open the specified file in the specified mode. If we bind that action to something we get a Handle. A value of type Handle represents where our file is. We'll use that handle so we know which file to read from. It would be stupid to read a file but not bind that read to a handle because we wouldn't be able to do anything with the file. So in our case, we bound the handle to handle.</p>
<p>In the next line, we see a function called hGetContents. It takes a Handle, so it knows which file to get the contents from and returns an IO String — an I/O action that holds as its result the contents of the file. This function is pretty much like getContents. The only difference is that getContents will automatically read from the standard input (that is from the terminal), whereas hGetContents takes a file handle which tells it which file to read from. In all other respects, they work the same. And just like getContents, hGetContents won't attempt to read the file at once and store it in memory, but it will read it as needed. That's really cool because we can treat contents as the whole contents of the file, but it's not really loaded in memory. So if this were a really huge file, doing hGetContents wouldn't choke up our memory, but it would read only what it needed to from the file, when it needed to.</p>
<p>Note the difference between the handle used to identify a file and the contents of the file, bound in our program to handle and contents. The handle is just something by which we know what our file is. If you imagine your whole file system to be a really big book and each file is a chapter in the book, the handle is a bookmark that shows where you're currently reading (or writing) a chapter, whereas the contents are the actual chapter.</p>
<p>With putStr contents we just print the contents out to the standard output and then we do hClose, which takes a handle and returns an I/O action that closes the file. You have to close the file yourself after opening it with openFile!</p>
<p>Another way of doing what we just did is to use the withFile function, which has a type signature of withFile :: FilePath -&gt; IOMode -&gt; (Handle -&gt; IO a) -&gt; IO a. It takes a path to a file, an IOMode and then it takes a function that takes a handle and returns some I/O action. What it returns is an I/O action that will open that file, do something we want with the file and then close it. The result encapsulated in the final I/O action that's returned is the same as the result of the I/O action that the function we give it returns. This might sound a bit complicated, but it's really simple, especially with lambdas, here's our previous example rewritten to use withFile:</p>
<pre><code>import System.IO

main = do     
    withFile "girlfriend.txt" ReadMode (\handle -&gt; do  
        contents &lt;- hGetContents handle     
        putStr contents)
</code></pre>
<p>As you can see, it's very similar to the previous piece of code. (\handle -&gt; ... ) is the function that takes a handle and returns an I/O action and it's usually done like this, with a lambda. The reason it has to take a function that returns an I/O action instead of just taking an I/O action to do and then close the file is because the I/O action that we'd pass to it wouldn't know on which file to operate. This way, withFile opens the file and then passes the handle to the function we gave it. It gets an I/O action back from that function and then makes an I/O action that's just like it, only it closes the file afterwards. Here's how we can make our own withFile function:</p>
<pre><code>withFile' :: FilePath -&gt; IOMode -&gt; (Handle -&gt; IO a) -&gt; IO a  
withFile' path mode f = do  
    handle &lt;- openFile path mode   
    result &lt;- f handle  
    hClose handle  
    return result
</code></pre>
<p>butter toast</p>
<p>We know the result will be an I/O action so we can just start off with a do. First we open the file and get a handle from it. Then, we apply handle to our function to get back the I/O action that does all the work. We bind that action to result, close the handle and then do return result. By returning the result encapsulated in the I/O action that we got from f, we make it so that our I/O action encapsulates the same result as the one we got from f handle. So if f handle returns an action that will read a number of lines from the standard input and write them to a file and have as its result encapsulated the number of lines it read, if we used that with withFile', the resulting I/O action would also have as its result the number of lines read.</p>
<p>Just like we have hGetContents that works like getContents but for a specific file, there's also hGetLine, hPutStr, hPutStrLn, hGetChar, etc. They work just like their counterparts without the h, only they take a handle as a parameter and operate on that specific file instead of operating on standard input or standard output. Example: putStrLn is a function that takes a string and returns an I/O action that will print out that string to the terminal and a newline after it. hPutStrLn takes a handle and a string and returns an I/O action that will write that string to the file associated with the handle and then put a newline after it. In the same vein, hGetLine takes a handle and returns an I/O action that reads a line from its file.</p>
<p>Loading files and then treating their contents as strings is so common that we have these three nice little functions to make our work even easier:</p>
<p>readFile has a type signature of readFile :: FilePath -&gt; IO String. Remember, FilePath is just a fancy name for String. readFile takes a path to a file and returns an I/O action that will read that file (lazily, of course) and bind its contents to something as a string. It's usually more handy than doing openFile and binding it to a handle and then doing hGetContents. Here's how we could have written our previous example with readFile:</p>
<pre><code>import System.IO

main = do  
    contents &lt;- readFile "girlfriend.txt"  
    putStr contents
</code></pre>
<p>Because we don't get a handle with which to identify our file, we can't close it manually, so Haskell does that for us when we use readFile.</p>
<p>writeFile has a type of writeFile :: FilePath -&gt; String -&gt; IO (). It takes a path to a file and a string to write to that file and returns an I/O action that will do the writing. If such a file already exists, it will be stomped down to zero length before being written on. Here's how to turn girlfriend.txt into a CAPSLOCKED version and write it to girlfriendcaps.txt:</p>
<pre><code>import System.IO     
import Data.Char

main = do     
    contents &lt;- readFile "girlfriend.txt"     
    writeFile "girlfriendcaps.txt" (map toUpper contents)

$ runhaskell girlfriendtocaps.hs  
$ cat girlfriendcaps.txt  
HEY! HEY! YOU! YOU!  
I DON'T LIKE YOUR GIRLFRIEND!  
NO WAY! NO WAY!  
I THINK YOU NEED A NEW ONE!
</code></pre>
<p>appendFile has a type signature that's just like writeFile, only appendFile doesn't truncate the file to zero length if it already exists but it appends stuff to it.</p>
<p>Let's say we have a file todo.txt that has one task per line that we have to do. Now let's make a program that takes a line from the standard input and adds that to our to-do list.</p>
<pre><code>import System.IO

main = do     
    todoItem &lt;- getLine  
    appendFile "todo.txt" (todoItem ++ "\n")

$ runhaskell appendtodo.hs  
Iron the dishes  
$ runhaskell appendtodo.hs  
Dust the dog  
$ runhaskell appendtodo.hs  
Take salad out of the oven  
$ cat todo.txt  
Iron the dishes  
Dust the dog  
Take salad out of the oven
</code></pre>
<p>We needed to add the "\n" to the end of each line because getLine doesn't give us a newline character at the end.</p>
<p>Ooh, one more thing. We talked about how doing contents &lt;- hGetContents handle doesn't cause the whole file to be read at once and stored in-memory. It's I/O lazy, so doing this:</p>
<pre><code>main = do   
    withFile "something.txt" ReadMode (\handle -&gt; do  
        contents &lt;- hGetContents handle  
        putStr contents)
</code></pre>
<p>is actually like connecting a pipe from the file to the output. Just like you can think of lists as streams, you can also think of files as streams. This will read one line at a time and print it out to the terminal as it goes along. So you may be asking, how wide is this pipe then? How often will the disk be accessed? Well, for text files, the default buffering is line-buffering usually. That means that the smallest part of the file to be read at once is one line. That's why in this case it actually reads a line, prints it to the output, reads the next line, prints it, etc. For binary files, the default buffering is usually block-buffering. That means that it will read the file chunk by chunk. The chunk size is some size that your operating system thinks is cool.</p>
<p>You can control how exactly buffering is done by using the hSetBuffering function. It takes a handle and a BufferMode and returns an I/O action that sets the buffering. BufferMode is a simple enumeration data type and the possible values it can hold are: NoBuffering, LineBuffering or BlockBuffering (Maybe Int). The Maybe Int is for how big the chunk should be, in bytes. If it's Nothing, then the operating system determines the chunk size. NoBuffering means that it will be read one character at a time. NoBuffering usually sucks as a buffering mode because it has to access the disk so much.</p>
<p>Here's our previous piece of code, only it doesn't read it line by line but reads the whole file in chunks of 2048 bytes.</p>
<pre><code>main = do   
    withFile "something.txt" ReadMode (\handle -&gt; do  
        hSetBuffering handle $ BlockBuffering (Just 2048)  
        contents &lt;- hGetContents handle  
        putStr contents)
</code></pre>
<p>Reading files in bigger chunks can help if we want to minimize disk access or when our file is actually a slow network resource.</p>
<p>We can also use hFlush, which is a function that takes a handle and returns an I/O action that will flush the buffer of the file associated with the handle. When we're doing line-buffering, the buffer is flushed after every line. When we're doing block-buffering, it's after we've read a chunk. It's also flushed after closing a handle. That means that when we've reached a newline character, the reading (or writing) mechanism reports all the data so far. But we can use hFlush to force that reporting of data that has been read so far. After flushing, the data is available to other programs that are running at the same time.</p>
<p>Think of reading a block-buffered file like this: your toilet bowl is set to flush itself after it has one gallon of water inside it. So you start pouring in water and once the gallon mark is reached, that water is automatically flushed and the data in the water that you've poured in so far is read. But you can flush the toilet manually too by pressing the button on the toilet. This makes the toilet flush and all the water (data) inside the toilet is read. In case you haven't noticed, flushing the toilet manually is a metaphor for hFlush. This is not a very great analogy by programming analogy standards, but I wanted a real world object that can be flushed for the punchline.</p>
<p>We already made a program to add a new item to our to-do list in todo.txt, now let's make a program to remove an item. I'll just paste the code and then we'll go over the program together so you see that it's really easy. We'll be using a few new functions from System.Directory and one new function from System.IO, but they'll all be explained.</p>
<p>Anyway, here's the program for removing an item from todo.txt:</p>
<pre><code>import System.IO  
import System.Directory  
import Data.List

main = do        
    handle &lt;- openFile "todo.txt" ReadMode  
    (tempName, tempHandle) &lt;- openTempFile "." "temp"  
    contents &lt;- hGetContents handle  
    let todoTasks = lines contents     
        numberedTasks = zipWith (\n line -&gt; show n ++ " - " ++ line) [0..] todoTasks     
    putStrLn "These are your TO-DO items:"  
    putStr $ unlines numberedTasks  
    putStrLn "Which one do you want to delete?"     
    numberString &lt;- getLine     
    let number = read numberString     
        newTodoItems = delete (todoTasks !! number) todoTasks     
    hPutStr tempHandle $ unlines newTodoItems  
    hClose handle  
    hClose tempHandle  
    removeFile "todo.txt"  
    renameFile tempName "todo.txt"
</code></pre>
<p>At first, we just open todo.txt in read mode and bind its handle to handle.</p>
<p>Next up, we use a function that we haven't met before which is from System.IO — openTempFile. Its name is pretty self-explanatory. It takes a path to a temporary directory and a template name for a file and opens a temporary file. We used "." for the temporary directory, because . denotes the current directory on just about any OS. We used "temp" as the template name for the temporary file, which means that the temporary file will be named temp plus some random characters. It returns an I/O action that makes the temporary file and the result in that I/O action is a pair of values: the name of the temporary file and a handle. We could just open a normal file called todo2.txt or something like that but it's better practice to use openTempFile so you know you're probably not overwriting anything.</p>
<p>The reason we didn't use getCurrentDirectory to get the current directory and then pass it to openTempFile but instead just passed "." to openTempFile is because . refers to the current directory on unix-like system and Windows</p>
<p>Next up, we bind the contents of todo.txt to contents. Then, split that string into a list of strings, each string one line. So todoTasks is now something like ["Iron the dishes", "Dust the dog", "Take salad out of the oven"]. We zip the numbers from 0 onwards and that list with a function that takes a number, like 3, and a string, like "hey" and returns "3 - hey", so numberedTasks is ["0 - Iron the dishes", "1 - Dust the dog" .... We join that list of strings into a single newline delimited string with unlines and print that string out to the terminal. Note that instead of doing that, we could have also done mapM putStrLn numberedTasks</p>
<p>We ask the user which one they want to delete and wait for them to enter a number. Let's say they want to delete number 1, which is Dust the dog, so they punch in 1. numberString is now "1" and because we want a number, not a string, we run read on that to get 1 and bind that to number.</p>
<p>Remember the delete and !! functions from Data.List. !! returns an element from a list with some index and delete deletes the first occurence of an element in a list and returns a new list without that occurence. (todoTasks !! number) (number is now 1) returns "Dust the dog". We bind todoTasks without the first occurence of "Dust the dog" to newTodoItems and then join that into a single string with unlines before writing it to the temporary file that we opened. The old file is now unchanged and the temporary file contains all the lines that the old one does, except the one we deleted.</p>
<p>After that we close both the original and the temporary files and then we remove the original one with removeFile, which, as you can see, takes a path to a file and deletes it. After deleting the old todo.txt, we use renameFile to rename the temporary file to todo.txt. Be careful, removeFile and renameFile (which are both in System.Directory by the way) take file paths as their parameters, not handles.</p>
<p>And that's that! We could have done this in even fewer lines, but we were very careful not to overwrite any existing files and politely asked the operating system to tell us where we can put our temporary file. Let's give this a go!</p>
<pre><code>$ runhaskell deletetodo.hs  
These are your TO-DO items:  
0 - Iron the dishes  
1 - Dust the dog  
2 - Take salad out of the oven  
Which one do you want to delete?  
1

$ cat todo.txt  
Iron the dishes  
Take salad out of the oven

$ runhaskell deletetodo.hs  
These are your TO-DO items:  
0 - Iron the dishes  
1 - Take salad out of the oven  
Which one do you want to delete?  
0

$ cat todo.txt  
Take salad out of the oven
</code></pre>
<p>Command line arguments
COMMAND LINE ARGUMENTS!!! ARGH</p>
<p>Dealing with command line arguments is pretty much a necessity if you want to make a script or application that runs on a terminal. Luckily, Haskell's standard library has a nice way of getting command line arguments of a program.</p>
<p>In the previous section, we made one program for adding a to-do item to our to-do list and one program for removing an item. There are two problems with the approach we took. The first one is that we just hardcoded the name of our to-do file in our code. We just decided that the file will be named todo.txt and that the user will never have a need for managing several to-do lists.</p>
<p>One way to solve that is to always ask the user which file they want to use as their to-do list. We used that approach when we wanted to know which item the user wants to delete. It works, but it's not so good, because it requires the user to run the program, wait for the program to ask something and then tell that to the program. That's called an interactive program and the difficult bit with interactive command line programs is this — what if you want to automate the execution of that program, like with a batch script? It's harder to make a batch script that interacts with a program than a batch script that just calls one program or several of them.</p>
<p>That's why it's sometimes better to have the user tell the program what they want when they run the program, instead of having the program ask the user once it's run. And what better way to have the user tell the program what they want it to do when they run it than via command line arguments!</p>
<p>The System.Environment module has two cool I/O actions. One is getArgs, which has a type of getArgs :: IO [String] and is an I/O action that will get the arguments that the program was run with and have as its contained result a list with the arguments. getProgName has a type of getProgName :: IO String and is an I/O action that contains the program name.</p>
<p>Here's a small program that demonstrates how these two work:</p>
<pre><code>import System.Environment   
import Data.List

main = do  
   args &lt;- getArgs  
   progName &lt;- getProgName  
   putStrLn "The arguments are:"  
   mapM putStrLn args  
   putStrLn "The program name is:"  
   putStrLn progName
</code></pre>
<p>We bind getArgs and progName to args and progName. We say The arguments are: and then for every argument in args, we do putStrLn. Finally, we also print out the program name. Let's compile this as arg-test.</p>
<pre><code>$ ./arg-test first second w00t "multi word arg"  
The arguments are:  
first  
second  
w00t  
multi word arg  
The program name is:  
arg-test
</code></pre>
<p>Nice. Armed with this knowledge you could create some cool command line apps. In fact, let's go ahead and make one. In the previous section, we made a separate program for adding tasks and a separate program for deleting them. Now, we're going to join that into one program, what it does will depend on the command line arguments. We're also going to make it so it can operate on different files, not just todo.txt.</p>
<p>We'll call it simply todo and it'll be able to do (haha!) three different things:</p>
<pre><code>View tasks
Add tasks
Delete tasks
</code></pre>
<p>We're not going to concern ourselves with possible bad input too much right now.</p>
<p>Our program will be made so that if we want to add the task Find the magic sword of power to the file todo.txt, we have to punch in todo add todo.txt "Find the magic sword of power" in our terminal. To view the tasks we'll just do todo view todo.txt and to remove the task with the index of 2, we'll do todo remove todo.txt 2.</p>
<p>We'll start by making a dispatch association list. It's going to be a simple association list that has command line arguments as keys and functions as their corresponding values. All these functions will be of type [String] -&gt; IO (). They're going to take the argument list as a parameter and return an I/O action that does the viewing, adding, deleting, etc.</p>
<pre><code>import System.Environment   
import System.Directory  
import System.IO  
import Data.List

dispatch :: [(String, [String] -&gt; IO ())]  
dispatch =  [ ("add", add)  
            , ("view", view)  
            , ("remove", remove)  
            ]
</code></pre>
<p>We have yet to define main, add, view and remove, so let's start with main:</p>
<pre><code>main = do  
    (command:args) &lt;- getArgs  
    let (Just action) = lookup command dispatch  
    action args
</code></pre>
<p>First, we get the arguments and bind them to (command:args). If you remember your pattern matching, this means that the first argument will get bound to command and the rest of them will get bound to args. If we call our program like todo add todo.txt "Spank the monkey", command will be "add" and args will be ["todo.xt", "Spank the monkey"].</p>
<p>In the next line, we look up our command in the dispatch list. Because "add" points to add, we get Just add as a result. We use pattern matching again to extract our function out of the Maybe. What happens if our command isn't in the dispatch list? Well then the lookup will return Nothing, but we said we won't concern ourselves with failing gracefully too much, so the pattern matching will fail and our program will throw a fit.</p>
<p>Finally, we call our action function with the rest of the argument list. That will return an I/O action that either adds an item, displays a list of items or deletes an item and because that action is part of the main do block, it will get performed. If we follow our concrete example so far and our action function is add, it will get called with args (so ["todo.txt", "Spank the monkey"]) and return an I/O action that adds Spank the monkey to todo.txt.</p>
<p>Great! All that's left now is to implement add, view and remove. Let's start with add:</p>
<pre><code>add :: [String] -&gt; IO ()  
add [fileName, todoItem] = appendFile fileName (todoItem ++ "\n")
</code></pre>
<p>If we call our program like todo add todo.txt "Spank the monkey", the "add" will get bound to command in the first pattern match in the main block, whereas ["todo.txt", "Spank the monkey"] will get passed to the function that we get from the dispatch list. So, because we're not dealing with bad input right now, we just pattern match against a list with those two elements right away and return an I/O action that appends that line to the end of the file, along with a newline character.</p>
<p>Next, let's implement the list viewing functionality. If we want to view the items in a file, we do todo view todo.txt. So in the first pattern match, command will be "view" and args will be ["todo.txt"].</p>
<pre><code>view :: [String] -&gt; IO ()  
view [fileName] = do  
    contents &lt;- readFile fileName  
    let todoTasks = lines contents  
        numberedTasks = zipWith (\n line -&gt; show n ++ " - " ++ line) [0..] todoTasks  
    putStr $ unlines numberedTasks
</code></pre>
<p>We already did pretty much the same thing in the program that only deleted tasks when we were displaying the tasks so that the user can choose one for deletion, only here we just display the tasks.</p>
<p>And finally, we're going to implement remove. It's going to be very similar to the program that only deleted the tasks, so if you don't understand how deleting an item here works, check out the explanation under that program. The main difference is that we're not hardcoding todo.txt but getting it as an argument. We're also not prompting the user for the task number to delete, we're getting it as an argument.</p>
<pre><code>remove :: [String] -&gt; IO ()  
remove [fileName, numberString] = do  
    handle &lt;- openFile fileName ReadMode  
    (tempName, tempHandle) &lt;- openTempFile "." "temp"  
    contents &lt;- hGetContents handle  
    let number = read numberString  
        todoTasks = lines contents  
        newTodoItems = delete (todoTasks !! number) todoTasks  
    hPutStr tempHandle $ unlines newTodoItems  
    hClose handle  
    hClose tempHandle  
    removeFile fileName  
    renameFile tempName fileName
</code></pre>
<p>We opened up the file based on fileName and opened a temporary file, deleted the line with the index that the user wants to delete, wrote that to the temporary file, removed the original file and renamed the temporary file back to fileName.</p>
<p>Here's the whole program at once, in all its glory!</p>
<pre><code>import System.Environment   
import System.Directory  
import System.IO  
import Data.List

dispatch :: [(String, [String] -&gt; IO ())]  
dispatch =  [ ("add", add)  
            , ("view", view)  
            , ("remove", remove)  
            ]

main = do  
    (command:args) &lt;- getArgs  
    let (Just action) = lookup command dispatch  
    action args

add :: [String] -&gt; IO ()  
add [fileName, todoItem] = appendFile fileName (todoItem ++ "\n")

view :: [String] -&gt; IO ()  
view [fileName] = do  
    contents &lt;- readFile fileName  
    let todoTasks = lines contents  
        numberedTasks = zipWith (\n line -&gt; show n ++ " - " ++ line) [0..] todoTasks  
    putStr $ unlines numberedTasks

remove :: [String] -&gt; IO ()  
remove [fileName, numberString] = do  
    handle &lt;- openFile fileName ReadMode  
    (tempName, tempHandle) &lt;- openTempFile "." "temp"  
    contents &lt;- hGetContents handle  
    let number = read numberString  
        todoTasks = lines contents  
        newTodoItems = delete (todoTasks !! number) todoTasks  
    hPutStr tempHandle $ unlines newTodoItems  
    hClose handle  
    hClose tempHandle  
    removeFile fileName  
    renameFile tempName fileName
</code></pre>
<p>fresh baked salad</p>
<p>To summarize our solution: we made a dispatch association that maps from commands to functions that take some command line arguments and return an I/O action. We see what the command is and based on that we get the appropriate function from the dispatch list. We call that function with the rest of the command line arguments to get back an I/O action that will do the appropriate thing and then just perform that action!</p>
<p>In other languages, we might have implemented this with a big switch case statement or whatever, but using higher order functions allows us to just tell the dispatch list to give us the appropriate function and then tell that function to give us an I/O action for some command line arguments.</p>
<p>Let's try our app out!</p>
<pre><code>$ ./todo view todo.txt  
0 - Iron the dishes  
1 - Dust the dog  
2 - Take salad out of the oven

$ ./todo add todo.txt "Pick up children from drycleaners"

$ ./todo view todo.txt  
0 - Iron the dishes  
1 - Dust the dog  
2 - Take salad out of the oven  
3 - Pick up children from drycleaners

$ ./todo remove todo.txt 2

$ ./todo view todo.txt  
0 - Iron the dishes  
1 - Dust the dog  
2 - Pick up children from drycleaners
</code></pre>
<p>Another cool thing about this is that it's easy to add extra functionality. Just add an entry in the dispatch association list and implement the corresponding function and you're laughing! As an exercise, you can try implementing a bump function that will take a file and a task number and return an I/O action that bumps that task to the top of the to-do list.</p>
<p>You could make this program fail a bit more gracefully in case of bad input (for example, if someone runs todo UP YOURS HAHAHAHA) by making an I/O action that just reports there has been an error (say, errorExit :: IO ()) and then check for possible erronous input and if there is erronous input, perform the error reporting I/O action. Another way is to use exceptions, which we will meet soon.
Randomness
this picture is the ultimate source of randomness and wackiness</p>
<p>Many times while programming, you need to get some random data. Maybe you're making a game where a die needs to be thrown or you need to generate some test data to test out your program. There are a lot of uses for random data when programming. Well, actually, pseudo-random, because we all know that the only true source of randomness is a monkey on a unicycle with a cheese in one hand and its butt in the other. In this section, we'll take a look at how to make Haskell generate seemingly random data.</p>
<p>In most other programming languages, you have functions that give you back some random number. Each time you call that function, you get back a (hopefully) different random number. How about Haskell? Well, remember, Haskell is a pure functional language. What that means is that it has referential transparency. What THAT means is that a function, if given the same parameters twice, must produce the same result twice. That's really cool because it allows us to reason differently about programs and it enables us to defer evaluation until we really need it. If I call a function, I can be sure that it won't do any funny stuff before giving me the results. All that matters are its results. However, this makes it a bit tricky for getting random numbers. If I have a function like this:</p>
<pre><code>randomNumber :: (Num a) =&gt; a  
randomNumber = 4
</code></pre>
<p>It's not very useful as a random number function because it will always return 4, even though I can assure you that the 4 is completely random, because I used a die to determine it.</p>
<p>How do other languages make seemingly random numbers? Well, they take various info from your computer, like the current time, how much and where you moved your mouse and what kind of noises you made behind your computer and based on that, give a number that looks really random. The combination of those factors (that randomness) is probably different in any given moment in time, so you get a different random number.</p>
<p>Ah. So in Haskell, we can make a random number then if we make a function that takes as its parameter that randomness and based on that returns some number (or other data type).</p>
<p>Enter the System.Random module. It has all the functions that satisfy our need for randomness. Let's just dive into one of the functions it exports then, namely random. Here's its type: random :: (RandomGen g, Random a) =&gt; g -&gt; (a, g). Whoa! Some new typeclasses in this type declaration up in here! The RandomGen typeclass is for types that can act as sources of randomness. The Random typeclass is for things that can take on random values. A boolean value can take on a random value, namely True or False. A number can also take up a plethora of different random values. Can a function take on a random value? I don't think so, probably not! If we try to translate the type declaration of random to English, we get something like: it takes a random generator (that's our source of randomness) and returns a random value and a new random generator. Why does it also return a new generator as well as a random value? Well, we'll see in a moment.</p>
<p>To use our random function, we have to get our hands on one of those random generators. The System.Random module exports a cool type, namely StdGen that is an instance of the RandomGen typeclass. We can either make a StdGen manually or we can tell the system to give us one based on a multitude of sort of random stuff.</p>
<p>To manually make a random generator, use the mkStdGen function. It has a type of mkStdGen :: Int -&gt; StdGen. It takes an integer and based on that, gives us a random generator. Okay then, let's try using random and mkStdGen in tandem to get a (hardly random) number.</p>
<pre><code>ghci&gt; random (mkStdGen 100)

&lt;interactive&gt;:1:0:  
    Ambiguous type variable `a' in the constraint:  
      `Random a' arising from a use of `random' at &lt;interactive&gt;:1:0-20  
    Probable fix: add a type signature that fixes these type variable(s)
</code></pre>
<p>What's this? Ah, right, the random function can return a value of any type that's part of the Random typeclass, so we have to inform Haskell what kind of type we want. Also let's not forget that it returns a random value and a random generator in a pair.</p>
<pre><code>ghci&gt; random (mkStdGen 100) :: (Int, StdGen)  
(-1352021624,651872571 1655838864)
</code></pre>
<p>Finally! A number that looks kind of random! The first component of the tuple is our number whereas the second component is a textual representation of our new random generator. What happens if we call random with the same random generator again?</p>
<pre><code>ghci&gt; random (mkStdGen 100) :: (Int, StdGen)  
(-1352021624,651872571 1655838864)
</code></pre>
<p>Of course. The same result for the same parameters. So let's try giving it a different random generator as a parameter.</p>
<pre><code>ghci&gt; random (mkStdGen 949494) :: (Int, StdGen)  
(539963926,466647808 1655838864)
</code></pre>
<p>Alright, cool, great, a different number. We can use the type annotation to get different types back from that function.</p>
<pre><code>ghci&gt; random (mkStdGen 949488) :: (Float, StdGen)  
(0.8938442,1597344447 1655838864)  
ghci&gt; random (mkStdGen 949488) :: (Bool, StdGen)  
(False,1485632275 40692)  
ghci&gt; random (mkStdGen 949488) :: (Integer, StdGen)  
(1691547873,1597344447 1655838864)
</code></pre>
<p>Let's make a function that simulates tossing a coin three times. If random didn't return a new generator along with a random value, we'd have to make this function take three random generators as a parameter and then return coin tosses for each of them. But that sounds wrong because if one generator can make a random value of type Int (which can take on a load of different values), it should be able to make three coin tosses (which can take on precisely eight combinations). So this is where random returning a new generator along with a value really comes in handy.</p>
<p>We'll represent a coin with a simple Bool. True is tails, False is heads.</p>
<pre><code>threeCoins :: StdGen -&gt; (Bool, Bool, Bool)  
threeCoins gen =   
    let (firstCoin, newGen) = random gen  
        (secondCoin, newGen') = random newGen  
        (thirdCoin, newGen'') = random newGen'  
    in  (firstCoin, secondCoin, thirdCoin)
</code></pre>
<p>We call random with the generator we got as a parameter to get a coin and a new generator. Then we call it again, only this time with our new generator, to get the second coin. We do the same for the third coin. Had we called it with the same generator every time, all the coins would have had the same value and we'd only be able to get (False, False, False) or (True, True, True) as a result.</p>
<pre><code>ghci&gt; threeCoins (mkStdGen 21)  
(True,True,True)  
ghci&gt; threeCoins (mkStdGen 22)  
(True,False,True)  
ghci&gt; threeCoins (mkStdGen 943)  
(True,False,True)  
ghci&gt; threeCoins (mkStdGen 944)  
(True,True,True)
</code></pre>
<p>Notice that we didn't have to do random gen :: (Bool, StdGen). That's because we already specified that we want booleans in the type declaration of the function. That's why Haskell can infer that we want a boolean value in this case.</p>
<p>So what if we want to flip four coins? Or five? Well, there's a function called randoms that takes a generator and returns an infinite sequence of values based on that generator.</p>
<pre><code>ghci&gt; take 5 $ randoms (mkStdGen 11) :: [Int]  
[-1807975507,545074951,-1015194702,-1622477312,-502893664]  
ghci&gt; take 5 $ randoms (mkStdGen 11) :: [Bool]  
[True,True,True,True,False]  
ghci&gt; take 5 $ randoms (mkStdGen 11) :: [Float]  
[7.904789e-2,0.62691015,0.26363158,0.12223756,0.38291094]
</code></pre>
<p>Why doesn't randoms return a new generator as well as a list? We could implement the randoms function very easily like this:</p>
<pre><code>randoms' :: (RandomGen g, Random a) =&gt; g -&gt; [a]  
randoms' gen = let (value, newGen) = random gen in value:randoms' newGen
</code></pre>
<p>A recursive definition. We get a random value and a new generator from the current generator and then make a list that has the value as its head and random numbers based on the new generator as its tail. Because we have to be able to potentially generate an infinite amount of numbers, we can't give the new random generator back.</p>
<p>We could make a function that generates a finite stream of numbers and a new generator like this:</p>
<pre><code>finiteRandoms :: (RandomGen g, Random a, Num n) =&gt; n -&gt; g -&gt; ([a], g)  
finiteRandoms 0 gen = ([], gen)  
finiteRandoms n gen =   
    let (value, newGen) = random gen  
        (restOfList, finalGen) = finiteRandoms (n-1) newGen  
    in  (value:restOfList, finalGen)
</code></pre>
<p>Again, a recursive definition. We say that if we want 0 numbers, we just return an empty list and the generator that was given to us. For any other number of random values, we first get one random number and a new generator. That will be the head. Then we say that the tail will be n - 1 numbers generated with the new generator. Then we return the head and the rest of the list joined and the final generator that we got from getting the n - 1 random numbers.</p>
<p>What if we want a random value in some sort of range? All the random integers so far were outrageously big or small. What if we want to to throw a die? Well, we use randomR for that purpose. It has a type of randomR :: (RandomGen g, Random a) :: (a, a) -&gt; g -&gt; (a, g), meaning that it's kind of like random, only it takes as its first parameter a pair of values that set the lower and upper bounds and the final value produced will be within those bounds.</p>
<pre><code>ghci&gt; randomR (1,6) (mkStdGen 359353)  
(6,1494289578 40692)  
ghci&gt; randomR (1,6) (mkStdGen 35935335)  
(3,1250031057 40692)
</code></pre>
<p>There's also randomRs, which produces a stream of random values within our defined ranges. Check this out:</p>
<pre><code>ghci&gt; take 10 $ randomRs ('a','z') (mkStdGen 3) :: [Char]  
"ndkxbvmomg"
</code></pre>
<p>Nice, looks like a super secret password or something.</p>
<p>You may be asking yourself, what does this section have to do with I/O anyway? We haven't done anything concerning I/O so far. Well, so far we've always made our random number generator manually by making it with some arbitrary integer. The problem is, if we do that in our real programs, they will always return the same random numbers, which is no good for us. That's why System.Random offers the getStdGen I/O action, which has a type of IO StdGen. When your program starts, it asks the system for a good random number generator and stores that in a so called global generator. getStdGen fetches you that global random generator when you bind it to something.</p>
<p>Here's a simple program that generates a random string.</p>
<pre><code>import System.Random

main = do  
    gen &lt;- getStdGen  
    putStr $ take 20 (randomRs ('a','z') gen)

$ runhaskell random_string.hs  
pybphhzzhuepknbykxhe  
$ runhaskell random_string.hs  
eiqgcxykivpudlsvvjpg  
$ runhaskell random_string.hs  
nzdceoconysdgcyqjruo  
$ runhaskell random_string.hs  
bakzhnnuzrkgvesqplrx
</code></pre>
<p>Be careful though, just performing getStdGen twice will ask the system for the same global generator twice. If you do this:</p>
<pre><code>import System.Random

main = do  
    gen &lt;- getStdGen  
    putStrLn $ take 20 (randomRs ('a','z') gen)  
    gen2 &lt;- getStdGen  
    putStr $ take 20 (randomRs ('a','z') gen2)
</code></pre>
<p>you will get the same string printed out twice! One way to get two different strings of length 20 is to set up an infinite stream and then take the first 20 characters and print them out in one line and then take the second set of 20 characters and print them out in the second line. For this, we can use the splitAt function from Data.List, which splits a list at some index and returns a tuple that has the first part as the first component and the second part as the second component.</p>
<pre><code>import System.Random  
import Data.List

main = do  
    gen &lt;- getStdGen  
    let randomChars = randomRs ('a','z') gen  
        (first20, rest) = splitAt 20 randomChars  
        (second20, _) = splitAt 20 rest  
    putStrLn first20  
    putStr second20
</code></pre>
<p>Another way is to use the newStdGen action, which splits our current random generator into two generators. It updates the global random generator with one of them and encapsulates the other as its result.</p>
<pre><code>import System.Random

main = do     
    gen &lt;- getStdGen     
    putStrLn $ take 20 (randomRs ('a','z') gen)     
    gen' &lt;- newStdGen  
    putStr $ take 20 (randomRs ('a','z') gen')
</code></pre>
<p>Not only do we get a new random generator when we bind newStdGen to something, the global one gets updated as well, so if we do getStdGen again and bind it to something, we'll get a generator that's not the same as gen.</p>
<p>Here's a little program that will make the user guess which number it's thinking of.</p>
<pre><code>import System.Random  
import Control.Monad(when)

main = do  
    gen &lt;- getStdGen  
    askForNumber gen

askForNumber :: StdGen -&gt; IO ()  
askForNumber gen = do  
    let (randNumber, newGen) = randomR (1,10) gen :: (Int, StdGen)  
    putStr "Which number in the range from 1 to 10 am I thinking of? "  
    numberString &lt;- getLine  
    when (not $ null numberString) $ do  
        let number = read numberString  
        if randNumber == number   
            then putStrLn "You are correct!"  
            else putStrLn $ "Sorry, it was " ++ show randNumber  
        askForNumber newGen
</code></pre>
<p>jack of diamonds</p>
<p>We make a function askForNumber, which takes a random number generator and returns an I/O action that will prompt the user for a number and tell him if he guessed it right. In that function, we first generate a random number and a new generator based on the generator that we got as a parameter and call them randNumber and newGen. Let's say that the number generated was 7. Then we tell the user to guess which number we're thinking of. We perform getLine and bind its result to numberString. When the user enters 7, numberString becomes "7". Next, we use when to check if the string the user entered is an empty string. If it is, an empty I/O action of return () is performed, which effectively ends the program. If it isn't, the action consisting of that do block right there gets performed. We use read on numberString to convert it to a number, so number is now 7.
Excuse me! If the user gives us some input here that read can't read (like "haha"), our program will crash with an ugly error message. If you don't want your program to crash on erronous input, use reads, which returns an empty list when it fails to read a string. When it succeeds, it returns a singleton list with a tuple that has our desired value as one component and a string with what it didn't consume as the other.</p>
<p>We check if the number that we entered is equal to the one generated randomly and give the user the appropriate message. And then we call askForNumber recursively, only this time with the new generator that we got, which gives us an I/O action that's just like the one we performed, only it depends on a different generator and we perform it.</p>
<p>main consists of just getting a random generator from the system and calling askForNumber with it to get the initial action.</p>
<p>Here's our program in action!</p>
<pre><code>$ runhaskell guess_the_number.hs  
Which number in the range from 1 to 10 am I thinking of? 4  
Sorry, it was 3  
Which number in the range from 1 to 10 am I thinking of? 10  
You are correct!  
Which number in the range from 1 to 10 am I thinking of? 2  
Sorry, it was 4  
Which number in the range from 1 to 10 am I thinking of? 5  
Sorry, it was 10  
Which number in the range from 1 to 10 am I thinking of?
</code></pre>
<p>Another way to make this same program is like this:</p>
<pre><code>import System.Random  
import Control.Monad(when)

main = do  
    gen &lt;- getStdGen  
    let (randNumber, _) = randomR (1,10) gen :: (Int, StdGen)     
    putStr "Which number in the range from 1 to 10 am I thinking of? "  
    numberString &lt;- getLine  
    when (not $ null numberString) $ do  
        let number = read numberString  
        if randNumber == number  
            then putStrLn "You are correct!"  
            else putStrLn $ "Sorry, it was " ++ show randNumber  
        newStdGen  
        main
</code></pre>
<p>It's very similar to the previous version, only instead of making a function that takes a generator and then calls itself recursively with the new updated generator, we do all the work in main. After telling the user whether they were correct in their guess or not, we update the global generator and then call main again. Both approaches are valid but I like the first one more since it does less stuff in main and also provides us with a function that we can reuse easily.
Bytestrings
like normal string, only they byte ... what a pedestrian pun this is</p>
<p>Lists are a cool and useful data structure. So far, we've used them pretty much everywhere. There are a multitude of functions that operate on them and Haskell's laziness allows us to exchange the for and while loops of other languages for filtering and mapping over lists, because evaluation will only happen once it really needs to, so things like infinite lists (and even infinite lists of infinite lists!) are no problem for us. That's why lists can also be used to represent streams, either when reading from the standard input or when reading from files. We can just open a file and read it as a string, even though it will only be accessed when the need arises.</p>
<p>However, processing files as strings has one drawback: it tends to be slow. As you know, String is a type synonym for [Char]. Chars don't have a fixed size, because it takes several bytes to represent a character from, say, Unicode. Furthemore, lists are really lazy. If you have a list like [1,2,3,4], it will be evaluated only when completely necessary. So the whole list is sort of a promise of a list. Remember that [1,2,3,4] is syntactic sugar for 1:2:3:4:[]. When the first element of the list is forcibly evaluated (say by printing it), the rest of the list 2:3:4:[] is still just a promise of a list, and so on. So you can think of lists as promises that the next element will be delivered once it really has to and along with it, the promise of the element after it. It doesn't take a big mental leap to conclude that processing a simple list of numbers as a series of promises might not be the most efficient thing in the world.</p>
<p>That overhead doesn't bother us so much most of the time, but it turns out to be a liability when reading big files and manipulating them. That's why Haskell has bytestrings. Bytestrings are sort of like lists, only each element is one byte (or 8 bits) in size. The way they handle laziness is also different.</p>
<p>Bytestrings come in two flavors: strict and lazy ones. Strict bytestrings reside in Data.ByteString and they do away with the laziness completely. There are no promises involved; a strict bytestring represents a series of bytes in an array. You can't have things like infinite strict bytestrings. If you evaluate the first byte of a strict bytestring, you have to evaluate it whole. The upside is that there's less overhead because there are no thunks (the technical term for promise) involved. The downside is that they're likely to fill your memory up faster because they're read into memory at once.</p>
<p>The other variety of bytestrings resides in Data.ByteString.Lazy. They're lazy, but not quite as lazy as lists. Like we said before, there are as many thunks in a list as there are elements. That's what makes them kind of slow for some purposes. Lazy bytestrings take a different approach — they are stored in chunks (not to be confused with thunks!), each chunk has a size of 64K. So if you evaluate a byte in a lazy bytestring (by printing it or something), the first 64K will be evaluated. After that, it's just a promise for the rest of the chunks. Lazy bytestrings are kind of like lists of strict bytestrings with a size of 64K. When you process a file with lazy bytestrings, it will be read chunk by chunk. This is cool because it won't cause the memory usage to skyrocket and the 64K probably fits neatly into your CPU's L2 cache.</p>
<p>If you look through the documentation for Data.ByteString.Lazy, you'll see that it has a lot of functions that have the same names as the ones from Data.List, only the type signatures have ByteString instead of [a] and Word8 instead of a in them. The functions with the same names mostly act the same as the ones that work on lists. Because the names are the same, we're going to do a qualified import in a script and then load that script into GHCI to play with bytestrings.</p>
<pre><code>import qualified Data.ByteString.Lazy as B  
import qualified Data.ByteString as S
</code></pre>
<p>B has lazy bytestring types and functions, whereas S has strict ones. We'll mostly be using the lazy version.</p>
<p>The function pack has the type signature pack :: [Word8] -&gt; ByteString. What that means is that it takes a list of bytes of type Word8 and returns a ByteString. You can think of it as taking a list, which is lazy, and making it less lazy, so that it's lazy only at 64K intervals.</p>
<p>What's the deal with that Word8 type? Well, it's like Int, only that it has a much smaller range, namely 0-255. It represents an 8-bit number. And just like Int, it's in the Num typeclass. For instance, we know that the value 5 is polymorphic in that it can act like any numeral type. Well, it can also take the type of Word8.</p>
<pre><code>ghci&gt; B.pack [99,97,110]  
Chunk "can" Empty  
ghci&gt; B.pack [98..120]  
Chunk "bcdefghijklmnopqrstuvwx" Empty
</code></pre>
<p>As you can see, you usually don't have to worry about the Word8 too much, because the type system can makes the numbers choose that type. If you try to use a big number, like 336 as a Word8, it will just wrap around to 80.</p>
<p>We packed only a handful of values into a ByteString, so they fit inside one chunk. The Empty is like the [] for lists.</p>
<p>unpack is the inverse function of pack. It takes a bytestring and turns it into a list of bytes.</p>
<p>fromChunks takes a list of strict bytestrings and converts it to a lazy bytestring. toChunks takes a lazy bytestring and converts it to a list of strict ones.</p>
<pre><code>ghci&gt; B.fromChunks [S.pack [40,41,42], S.pack [43,44,45], S.pack [46,47,48]]  
Chunk "()*" (Chunk "+,-" (Chunk "./0" Empty))
</code></pre>
<p>This is good if you have a lot of small strict bytestrings and you want to process them efficiently without joining them into one big strict bytestring in memory first.</p>
<p>The bytestring version of : is called cons It takes a byte and a bytestring and puts the byte at the beginning. It's lazy though, so it will make a new chunk even if the first chunk in the bytestring isn't full. That's why it's better to use the strict version of cons, cons' if you're going to be inserting a lot of bytes at the beginning of a bytestring.</p>
<pre><code>ghci&gt; B.cons 85 $ B.pack [80,81,82,84]  
Chunk "U" (Chunk "PQRT" Empty)  
ghci&gt; B.cons' 85 $ B.pack [80,81,82,84]  
Chunk "UPQRT" Empty  
ghci&gt; foldr B.cons B.empty [50..60]  
Chunk "2" (Chunk "3" (Chunk "4" (Chunk "5" (Chunk "6" (Chunk "7" (Chunk "8" (Chunk "9" (Chunk ":" (Chunk ";" (Chunk "&lt;"  
Empty))))))))))  
ghci&gt; foldr B.cons' B.empty [50..60]  
Chunk "23456789:;&lt;" Empty
</code></pre>
<p>As you can see empty makes an empty bytestring. See the difference between cons and cons'? With the foldr, we started with an empty bytestring and then went over the list of numbers from the right, adding each number to the beginning of the bytestring. When we used cons, we ended up with one chunk for every byte, which kind of defeats the purpose.</p>
<p>Otherwise, the bytestring modules have a load of functions that are analogous to those in Data.List, including, but not limited to, head, tail, init, null, length, map, reverse, foldl, foldr, concat, takeWhile, filter, etc.</p>
<p>It also has functions that have the same name and behave the same as some functions found in System.IO, only Strings are replaced with ByteStrings. For instance, the readFile function in System.IO has a type of readFile :: FilePath -&gt; IO String, while the readFile from the bytestring modules has a type of readFile :: FilePath -&gt; IO ByteString. Watch out, if you're using strict bytestrings and you attempt to read a file, it will read it into memory at once! With lazy bytestrings, it will read it into neat chunks.</p>
<p>Let's make a simple program that takes two filenames as command-line arguments and copies the first file into the second file. Note that System.Directory already has a function called copyFile, but we're going to implement our own file copying function and program anyway.</p>
<pre><code>import System.Environment  
import qualified Data.ByteString.Lazy as B

main = do  
    (fileName1:fileName2:_) &lt;- getArgs  
    copyFile fileName1 fileName2

copyFile :: FilePath -&gt; FilePath -&gt; IO ()  
copyFile source dest = do  
    contents &lt;- B.readFile source  
    B.writeFile dest contents
</code></pre>
<p>We make our own function that takes two FilePaths (remember, FilePath is just a synonym for String) and returns an I/O action that will copy one file into another using bytestring. In the main function, we just get the arguments and call our function with them to get the I/O action, which is then performed.</p>
<pre><code>$ runhaskell bytestringcopy.hs something.txt ../../something.txt
</code></pre>
<p>Notice that a program that doesn't use bytestrings could look just like this, the only difference is that we used B.readFile and B.writeFile instead of readFile and writeFile. Many times, you can convert a program that uses normal strings to a program that uses bytestrings by just doing the necessary imports and then putting the qualified module names in front of some functions. Sometimes, you have to convert functions that you wrote to work on strings so that they work on bytestrings, but that's not hard.</p>
<p>Whenever you need better performance in a program that reads a lot of data into strings, give bytestrings a try, chances are you'll get some good performance boosts with very little effort on your part. I usually write programs by using normal strings and then convert them to use bytestrings if the performance is not satisfactory.
Exceptions
timberr!!!!</p>
<p>All languages have procedures, functions, and pieces of code that might fail in some way. That's just a fact of life. Different languages have different ways of handling those failures. In C, we usually use some abnormal return value (like -1 or a null pointer) to indicate that what a function returned shouldn't be treated like a normal value. Java and C#, on the other hand, tend to use exceptions to handle failure. When an exception is thrown, the control flow jumps to some code that we've defined that does some cleanup and then maybe re-throws the exception so that some other error handling code can take care of some other stuff.</p>
<p>Haskell has a very good type system. Algebraic data types allow for types like Maybe and Either and we can use values of those types to represent results that may be there or not. In C, returning, say, -1 on failure is completely a matter of convention. It only has special meaning to humans. If we're not careful, we might treat these abnormal values as ordinary ones and then they can cause havoc and dismay in our code. Haskell's type system gives us some much-needed safety in that aspect. A function a -&gt; Maybe b clearly indicates that it it may produce a b wrapped in Just or that it may return Nothing. The type is different from just plain a -&gt; b and if we try to use those two functions interchangeably, the compiler will complain at us.</p>
<p>Despite having expressive types that support failed computations, Haskell still has support for exceptions, because they make more sense in I/O contexts. A lot of things can go wrong when dealing with the outside world because it is so unreliable. For instance, when opening a file, a bunch of things can go wrong. The file might be locked, it might not be there at all or the hard disk drive or something might not be there at all. So it's good to be able to jump to some error handling part of our code when such an error occurs.</p>
<p>Okay, so I/O code (i.e. impure code) can throw exceptions. It makes sense. But what about pure code? Well, it can throw exceptions too. Think about the div and head functions. They have types of (Integral a) =&gt; a -&gt; a -&gt; a and [a] -&gt; a, respectively. No Maybe or Either in their return type and yet they can both fail! div explodes in your face if you try to divide by zero and head throws a tantrum when you give it an empty list.</p>
<pre><code>ghci&gt; 4 `div` 0  
*** Exception: divide by zero  
ghci&gt; head []  
*** Exception: Prelude.head: empty list
</code></pre>
<p>Stop right there, criminal scum! Nobody breaks the law on my watch! Now pay your fine or it's off to jail.</p>
<p>Pure code can throw exceptions, but it they can only be caught in the I/O part of our code (when we're inside a do block that goes into main). That's because you don't know when (or if) anything will be evaluated in pure code, because it is lazy and doesn't have a well-defined order of execution, whereas I/O code does.</p>
<p>Earlier, we talked about how we should spend as little time as possible in the I/O part of our program. The logic of our program should reside mostly within our pure functions, because their results are dependant only on the parameters that the functions are called with. When dealing with pure functions, you only have to think about what a function returns, because it can't do anything else. This makes your life easier. Even though doing some logic in I/O is necessary (like opening files and the like), it should preferably be kept to a minimum. Pure functions are lazy by default, which means that we don't know when they will be evaluated and that it really shouldn't matter. However, once pure functions start throwing exceptions, it matters when they are evaluated. That's why we can only catch exceptions thrown from pure functions in the I/O part of our code. And that's bad, because we want to keep the I/O part as small as possible. However, if we don't catch them in the I/O part of our code, our program crashes. The solution? Don't mix exceptions and pure code. Take advantage of Haskell's powerful type system and use types like Either and Maybe to represent results that may have failed.</p>
<p>That's why we'll just be looking at how to use I/O exceptions for now. I/O exceptions are exceptions that are caused when something goes wrong while we are communicating with the outside world in an I/O action that's part of main. For example, we can try opening a file and then it turns out that the file has been deleted or something. Take a look at this program that opens a file whose name is given to it as a command line argument and tells us how many lines the file has.</p>
<pre><code>import System.Environment  
import System.IO

main = do (fileName:_) &lt;- getArgs  
          contents &lt;- readFile fileName  
          putStrLn $ "The file has " ++ show (length (lines contents)) ++ " lines!"
</code></pre>
<p>A very simple program. We perform the getArgs I/O action and bind the first string in the list that it yields to fileName. Then we call the contents of the file with that name contents. Lastly, we apply lines to those contents to get a list of lines and then we get the length of that list and give it to show to get a string representation of that number. It works as expected, but what happens when we give it the name of a file that doesn't exist?</p>
<pre><code>$ runhaskell linecount.hs i_dont_exist.txt  
linecount.hs: i_dont_exist.txt: openFile: does not exist (No such file or directory)
</code></pre>
<p>Aha, we get an error from GHC, telling us that the file does not exist. Our program crashes. What if we wanted to print out a nicer message if the file doesn't exist? One way to do that is to check if the file exists before trying to open it by using the doesFileExist function from System.Directory.</p>
<pre><code>import System.Environment  
import System.IO  
import System.Directory

main = do (fileName:_) &lt;- getArgs  
          fileExists &lt;- doesFileExist fileName  
          if fileExists  
              then do contents &lt;- readFile fileName  
                      putStrLn $ "The file has " ++ show (length (lines contents)) ++ " lines!"  
              else do putStrLn "The file doesn't exist!"
</code></pre>
<p>We did fileExists &lt;- doesFileExist fileName because doesFileExist has a type of doesFileExist :: FilePath -&gt; IO Bool, which means that it returns an I/O action that has as its result a boolean value which tells us if the file exists. We can't just use doesFileExist in an if expression directly.</p>
<p>Another solution here would be to use exceptions. It's perfectly acceptable to use them in this context. A file not existing is an exception that arises from I/O, so catching it in I/O is fine and dandy.</p>
<p>To deal with this by using exceptions, we're going to take advantage of the catch function from System.IO.Error. Its type is catch :: IO a -&gt; (IOError -&gt; IO a) -&gt; IO a. It takes two parameters. The first one is an I/O action. For instance, it could be an I/O action that tries to open a file. The second one is the so-called handler. If the first I/O action passed to catch throws an I/O exception, that exception gets passed to the handler, which then decides what to do. So the final result is an I/O action that will either act the same as the first parameter or it will do what the handler tells it if the first I/O action throws an exception.
non sequitor</p>
<p>If you're familiar with try-catch blocks in languages like Java or Python, the catch function is similar to them. The first parameter is the thing to try, kind of like the stuff in the try block in other, imperative languages. The second parameter is the handler that takes an exception, just like most catch blocks take exceptions that you can then examine to see what happened. The handler is invoked if an exception is thrown.</p>
<p>The handler takes a value of type IOError, which is a value that signifies that an I/O exception occurred. It also carries information regarding the type of the exception that was thrown. How this type is implemented depends on the implementation of the language itself, which means that we can't inspect values of the type IOError by pattern matching against them, just like we can't pattern match against values of type IO something. We can use a bunch of useful predicates to find out stuff about values of type IOError as we'll learn in a second.</p>
<p>So let's put our new friend catch to use!</p>
<pre><code>import System.Environment  
import System.IO  
import System.IO.Error

main = toTry `catch` handler

toTry :: IO ()  
toTry = do (fileName:_) &lt;- getArgs  
           contents &lt;- readFile fileName  
           putStrLn $ "The file has " ++ show (length (lines contents)) ++ " lines!"

handler :: IOError -&gt; IO ()  
handler e = putStrLn "Whoops, had some trouble!"
</code></pre>
<p>First of all, you'll see that put backticks around it so that we can use it as an infix function, because it takes two parameters. Using it as an infix function makes it more readable. So toTry <code>catch</code> handler is the same as catch toTry handler, which fits well with its type. toTry is the I/O action that we try to carry out and handler is the function that takes an IOError and returns an action to be carried out in case of an exception.</p>
<p>Let's give this a go:</p>
<pre><code>$ runhaskell count_lines.hs i_exist.txt  
The file has 3 lines!

$ runhaskell count_lines.hs i_dont_exist.txt  
Whoops, had some trouble!
</code></pre>
<p>In the handler, we didn't check to see what kind of IOError we got. We just say "Whoops, had some trouble!" for any kind of error. Just catching all types of exceptions in one handler is bad practice in Haskell just like it is in most other languages. What if some other exception happens that we don't want to catch, like us interrupting the program or something? That's why we're going to do the same thing that's usually done in other languages as well: we'll check to see what kind of exception we got. If it's the kind of exception we're waiting to catch, we do our stuff. If it's not, we throw that exception back into the wild. Let's modify our program to catch only the exceptions caused by a file not existing.</p>
<pre><code>import System.Environment  
import System.IO  
import System.IO.Error

main = toTry `catch` handler

toTry :: IO ()  
toTry = do (fileName:_) &lt;- getArgs  
           contents &lt;- readFile fileName  
           putStrLn $ "The file has " ++ show (length (lines contents)) ++ " lines!"

handler :: IOError -&gt; IO ()  
handler e  
    | isDoesNotExistError e = putStrLn "The file doesn't exist!"  
    | otherwise = ioError e
</code></pre>
<p>Everything stays the same except the handler, which we modified to only catch a certain group of I/O exceptions. Here we used two new functions from System.IO.Error — isDoesNotExistError and ioError. isDoesNotExistError is a predicate over IOErrors, which means that it's a function that takes an IOError and returns a True or False, meaning it has a type of isDoesNotExistError :: IOError -&gt; Bool. We use it on the exception that gets passed to our handler to see if it's an error caused by a file not existing. We use guard syntax here, but we could have also used an if else. If it's not caused by a file not existing, we re-throw the exception that was passed by the handler with the ioError function. It has a type of ioError :: IOException -&gt; IO a, so it takes an IOError and produces an I/O action that will throw it. The I/O action has a type of IO a, because it never actually yields a result, so it can act as IO anything.</p>
<p>So the exception thrown in the toTry I/O action that we glued together with a do block isn't caused by a file existing, toTry <code>catch</code> handler will catch that and then re-throw it. Pretty cool, huh?</p>
<p>There are several predicates that act on IOError and if a guard doesn't evaluate to True, evaluation falls through to the next guard. The predicates that act on IOError are:</p>
<pre><code>isAlreadyExistsError
isDoesNotExistError
isAlreadyInUseError
isFullError
isEOFError
isIllegalOperation
isPermissionError
isUserError
</code></pre>
<p>Most of these are pretty self-explanatory. isUserError evaluates to True when we use the function userError to make the exception, which is used for making exceptions from our code and equipping them with a string. For instance, you can do ioError $ userError "remote computer unplugged!", although It's prefered you use types like Either and Maybe to express possible failure instead of throwing exceptions yourself with userError.</p>
<p>So you could have a handler that looks something like this:</p>
<pre><code>handler :: IOError -&gt; IO ()  
handler e  
    | isDoesNotExistError e = putStrLn "The file doesn't exist!"  
    | isFullError e = freeSomeSpace  
    | isIllegalOperation e = notifyCops  
    | otherwise = ioError e
</code></pre>
<p>Where notifyCops and freeSomeSpace are some I/O actions that you define. Be sure to re-throw exceptions if they don't match any of your criteria, otherwise you're causing your program to fail silently in some cases where it shouldn't.</p>
<p>System.IO.Error also exports functions that enable us to ask our exceptions for some attributes, like what the handle of the file that caused the error is, or what the filename is. These start with ioe and you can see a full list of them in the documentation. Say we want to print the filename that caused our error. We can't print the fileName that we got from getArgs, because only the IOError is passed to the handler and the handler doesn't know about anything else. A function depends only on the parameters it was called with. That's why we can use the ioeGetFileName function, which has a type of ioeGetFileName :: IOError -&gt; Maybe FilePath. It takes an IOError as a parameter and maybe returns a FilePath (which is just a type synonym for String, remember, so it's kind of the same thing). Basically, what it does is it extracts the file path from the IOError, if it can. Let's modify our program to print out the file path that's responsible for the exception occurring.</p>
<pre><code>import System.Environment     
import System.IO     
import System.IO.Error

main = toTry `catch` handler

toTry :: IO ()     
toTry = do (fileName:_) &lt;- getArgs     
           contents &lt;- readFile fileName     
           putStrLn $ "The file has " ++ show (length (lines contents)) ++ " lines!"

handler :: IOError -&gt; IO ()     
handler e     
    | isDoesNotExistError e =   
        case ioeGetFileName e of Just path -&gt; putStrLn $ "Whoops! File does not exist at: " ++ path  
                                 Nothing -&gt; putStrLn "Whoops! File does not exist at unknown location!"  
    | otherwise = ioError e
</code></pre>
<p>In the guard where isDoesNotExistError is True, we used a case expression to call ioeGetFileName with e and then pattern match against the Maybe value that it returned. Using case expressions is commonly used when you want to pattern match against something without bringing in a new function.</p>
<p>You don't have to use one handler to catch exceptions in your whole I/O part. You can just cover certain parts of your I/O code with catch or you can cover several of them with catch and use different handlers for them, like so:</p>
<pre><code>main = do toTry `catch` handler1  
          thenTryThis `catch` handler2  
          launchRockets
</code></pre>
<p>Here, toTry uses handler1 as the handler and thenTryThis uses handler2. launchRockets isn't a parameter to catch, so whichever exceptions it might throw will likely crash our program, unless launchRockets uses catch internally to handle its own exceptions. Of course toTry, thenTryThis and launchRockets are I/O actions that have been glued together using do syntax and hypothetically defined somewhere else. This is kind of similar to try-catch blocks of other languages, where you can surround your whole program in a single try-catch or you can use a more fine-grained approach and use different ones in different parts of your code to control what kind of error handling happens where.</p>
<p>Now you know how to deal with I/O exceptions! Throwing exceptions from pure code and dealing with them hasn't been covered here, mainly because, like we said, Haskell offers much better ways to indicate errors than reverting to I/O to catch them. Even when glueing together I/O actions that might fail, I prefer to have their type be something like IO (Either a b), meaning that they're normal I/O actions but the result that they yield when performed is of type Either a b, meaning it's either Left a or Right b.</p>
<pre><code>Making Our Own Types and Typeclasses Table of contents Functionally Solving Problems
</code></pre></article>
 
</slide>

<slide  >
  
    <hgroup>
      <h2>Functors, Applicative Functors and Monoids</h2>
      <h3></h3>
    </hgroup>
    <article >
      <p>Haskell's combination of purity, higher order functions, parameterized algebraic data types, and typeclasses allows us to implement polymorphism on a much higher level than possible in other languages. We don't have to think about types belonging to a big hierarchy of types. Instead, we think about what the types can act like and then connect them with the appropriate typeclasses. An Int can act like a lot of things. It can act like an equatable thing, like an ordered thing, like an enumerable thing, etc.</p>
<p>Typeclasses are open, which means that we can define our own data type, think about what it can act like and connect it with the typeclasses that define its behaviors. Because of that and because of Haskell's great type system that allows us to know a lot about a function just by knowing its type declaration, we can define typeclasses that define behavior that's very general and abstract. We've met typeclasses that define operations for seeing if two things are equal or comparing two things by some ordering. Those are very abstract and elegant behaviors, but we just don't think of them as anything very special because we've been dealing with them for most of our lives. We recently met functors, which are basically things that can be mapped over. That's an example of a useful and yet still pretty abstract property that typeclasses can describe. In this chapter, we'll take a closer look at functors, along with slightly stronger and more useful versions of functors called applicative functors. We'll also take a look at monoids, which are sort of like socks.
Functors redux
frogs dont even need money</p>
<p>We've already talked about functors in their own little section. If you haven't read it yet, you should probably give it a glance right now, or maybe later when you have more time. Or you can just pretend you read it.</p>
<p>Still, here's a quick refresher: Functors are things that can be mapped over, like lists, Maybes, trees, and such. In Haskell, they're described by the typeclass Functor, which has only one typeclass method, namely fmap, which has a type of fmap :: (a -&gt; b) -&gt; f a -&gt; f b. It says: give me a function that takes an a and returns a b and a box with an a (or several of them) inside it and I'll give you a box with a b (or several of them) inside it. It kind of applies the function to the element inside the box.
A word of advice. Many times the box analogy is used to help you get some intuition for how functors work, and later, we'll probably use the same analogy for applicative functors and monads. It's an okay analogy that helps people understand functors at first, just don't take it too literally, because for some functors the box analogy has to be stretched really thin to still hold some truth. A more correct term for what a functor is would be computational context. The context might be that the computation can have a value or it might have failed (Maybe and Either a) or that there might be more values (lists), stuff like that.</p>
<p>If we want to make a type constructor an instance of Functor, it has to have a kind of * -&gt; *, which means that it has to take exactly one concrete type as a type parameter. For example, Maybe can be made an instance because it takes one type parameter to produce a concrete type, like Maybe Int or Maybe String. If a type constructor takes two parameters, like Either, we have to partially apply the type constructor until it only takes one type parameter. So we can't write instance Functor Either where, but we can write instance Functor (Either a) where and then if we imagine that fmap is only for Either a, it would have a type declaration of fmap :: (b -&gt; c) -&gt; Either a b -&gt; Either a c. As you can see, the Either a part is fixed, because Either a takes only one type parameter, whereas just Either takes two so fmap :: (b -&gt; c) -&gt; Either b -&gt; Either c wouldn't really make sense.</p>
<p>We've learned by now how a lot of types (well, type constructors really) are instances of Functor, like [], Maybe, Either a and a Tree type that we made on our own. We saw how we can map functions over them for great good. In this section, we'll take a look at two more instances of functor, namely IO and (-&gt;) r.</p>
<p>If some value has a type of, say, IO String, that means that it's an I/O action that, when performed, will go out into the real world and get some string for us, which it will yield as a result. We can use &lt;- in do syntax to bind that result to a name. We mentioned that I/O actions are like boxes with little feet that go out and fetch some value from the outside world for us. We can inspect what they fetched, but after inspecting, we have to wrap the value back in IO. By thinking about this box with little feet analogy, we can see how IO acts like a functor.</p>
<p>Let's see how IO is an instance of Functor. When we fmap a function over an I/O action, we want to get back an I/O action that does the same thing, but has our function applied over its result value.</p>
<pre><code>instance Functor IO where  
    fmap f action = do  
        result &lt;- action  
        return (f result)
</code></pre>
<p>The result of mapping something over an I/O action will be an I/O action, so right off the bat we use do syntax to glue two actions and make a new one. In the implementation for fmap, we make a new I/O action that first performs the original I/O action and calls its result result. Then, we do return (f result). return is, as you know, a function that makes an I/O action that doesn't do anything but only presents something as its result. The action that a do block produces will always have the result value of its last action. That's why we use return to make an I/O action that doesn't really do anything, it just presents f result as the result of the new I/O action.</p>
<p>We can play around with it to gain some intuition. It's pretty simple really. Check out this piece of code:</p>
<pre><code>main = do line &lt;- getLine   
          let line' = reverse line  
          putStrLn $ "You said " ++ line' ++ " backwards!"  
          putStrLn $ "Yes, you really said" ++ line' ++ " backwards!"
</code></pre>
<p>The user is prompted for a line and we give it back to the user, only reversed. Here's how to rewrite this by using fmap:</p>
<pre><code>main = do line &lt;- fmap reverse getLine  
          putStrLn $ "You said " ++ line ++ " backwards!"  
          putStrLn $ "Yes, you really said" ++ line ++ " backwards!"
</code></pre>
<p>w00ooOoooOO</p>
<p>Just like when we fmap reverse over Just "blah" to get Just "halb", we can fmap reverse over getLine. getLine is an I/O action that has a type of IO String and mapping reverse over it gives us an I/O action that will go out into the real world and get a line and then apply reverse to its result. Like we can apply a function to something that's inside a Maybe box, we can apply a function to what's inside an IO box, only it has to go out into the real world to get something. Then when we bind it to a name by using &lt;-, the name will reflect the result that already has reverse applied to it.</p>
<p>The I/O action fmap (++"!") getLine behaves just like getLine, only that its result always has "!" appended to it!</p>
<p>If we look at what fmap's type would be if it were limited to IO, it would be fmap :: (a -&gt; b) -&gt; IO a -&gt; IO b. fmap takes a function and an I/O action and returns a new I/O action that's like the old one, except that the function is applied to its contained result.</p>
<p>If you ever find yourself binding the result of an I/O action to a name, only to apply a function to that and call that something else, consider using fmap, because it looks prettier. If you want to apply multiple transformations to some data inside a functor, you can declare your own function at the top level, make a lambda function or ideally, use function composition:</p>
<pre><code>import Data.Char  
import Data.List

main = do line &lt;- fmap (intersperse '-' . reverse . map toUpper) getLine  
          putStrLn line

$ runhaskell fmapping_io.hs  
hello there  
E-R-E-H-T- -O-L-L-E-H
</code></pre>
<p>As you probably know, intersperse '-' . reverse . map toUpper is a function that takes a string, maps toUpper over it, the applies reverse to that result and then applies intersperse '-' to that result. It's like writing (\xs -&gt; intersperse '-' (reverse (map toUpper xs))), only prettier.</p>
<p>Another instance of Functor that we've been dealing with all along but didn't know was a Functor is (-&gt;) r. You're probably slightly confused now, since what the heck does (-&gt;) r mean? The function type r -&gt; a can be rewritten as (-&gt;) r a, much like we can write 2 + 3 as (+) 2 3. When we look at it as (-&gt;) r a, we can see (-&gt;) in a slighty different light, because we see that it's just a type constructor that takes two type parameters, just like Either. But remember, we said that a type constructor has to take exactly one type parameter so that it can be made an instance of Functor. That's why we can't make (-&gt;) an instance of Functor, but if we partially apply it to (-&gt;) r, it doesn't pose any problems. If the syntax allowed for type constructors to be partially applied with sections (like we can partially apply + by doing (2+), which is the same as (+) 2), you could write (-&gt;) r as (r -&gt;). How are functions functors? Well, let's take a look at the implementation, which lies in Control.Monad.Instances
We usually mark functions that take anything and return anything as a -&gt; b. r -&gt; a is the same thing, we just used different letters for the type variables.</p>
<pre><code>instance Functor ((-&gt;) r) where  
    fmap f g = (\x -&gt; f (g x))
</code></pre>
<p>If the syntax allowed for it, it could have been written as</p>
<pre><code>instance Functor (r -&gt;) where  
    fmap f g = (\x -&gt; f (g x))
</code></pre>
<p>But it doesn't, so we have to write it in the former fashion.</p>
<p>First of all, let's think about fmap's type. It's fmap :: (a -&gt; b) -&gt; f a -&gt; f b. Now what we'll do is mentally replace all the f's, which are the role that our functor instance plays, with (-&gt;) r's. We'll do that to see how fmap should behave for this particular instance. We get fmap :: (a -&gt; b) -&gt; ((-&gt;) r a) -&gt; ((-&gt;) r b). Now what we can do is write the (-&gt;) r a and (-&gt; r b) types as infix r -&gt; a and r -&gt; b, like we normally do with functions. What we get now is fmap :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; b).</p>
<p>Hmmm OK. Mapping one function over a function has to produce a function, just like mapping a function over a Maybe has to produce a Maybe and mapping a function over a list has to produce a list. What does the type fmap :: (a -&gt; b) -&gt; (r -&gt; a) -&gt; (r -&gt; b) for this instance tell us? Well, we see that it takes a function from a to b and a function from r to a and returns a function from r to b. Does this remind you of anything? Yes! Function composition! We pipe the output of r -&gt; a into the input of a -&gt; b to get a function r -&gt; b, which is exactly what function composition is about. If you look at how the instance is defined above, you'll see that it's just function composition. Another way to write this instance would be:</p>
<pre><code>instance Functor ((-&gt;) r) where  
    fmap = (.)
</code></pre>
<p>This makes the revelation that using fmap over functions is just composition sort of obvious. Do :m + Control.Monad.Instances, since that's where the instance is defined and then try playing with mapping over functions.</p>
<pre><code>ghci&gt; :t fmap (*3) (+100)  
fmap (*3) (+100) :: (Num a) =&gt; a -&gt; a  
ghci&gt; fmap (*3) (+100) 1  
303  
ghci&gt; (*3) `fmap` (+100) $ 1  
303  
ghci&gt; (*3) . (+100) $ 1  
303  
ghci&gt; fmap (show . (*3)) (*100) 1  
"300"
</code></pre>
<p>We can call fmap as an infix function so that the resemblance to . is clear. In the second input line, we're mapping (<em>3) over (+100), which results in a function that will take an input, call (+100) on that and then call (</em>3) on that result. We call that function with 1.</p>
<p>How does the box analogy hold here? Well, if you stretch it, it holds. When we use fmap (+3) over Just 3, it's easy to imagine the Maybe as a box that has some contents on which we apply the function (+3). But what about when we're doing fmap (<em>3) (+100)? Well, you can think of the function (+100) as a box that contains its eventual result. Sort of like how an I/O action can be thought of as a box that will go out into the real world and fetch some result. Using fmap (</em>3) on (+100) will create another function that acts like (+100), only before producing a result, (*3) will be applied to that result. Now we can see how fmap acts just like . for functions.</p>
<p>The fact that fmap is function composition when used on functions isn't so terribly useful right now, but at least it's very interesting. It also bends our minds a bit and let us see how things that act more like computations than boxes (IO and (-&gt;) r) can be functors. The function being mapped over a computation results in the same computation but the result of that computation is modified with the function.
lifting a function is easier than lifting a million pounds</p>
<p>Before we go on to the rules that fmap should follow, let's think about the type of fmap once more. Its type is fmap :: (a -&gt; b) -&gt; f a -&gt; f b. We're missing the class constraint (Functor f) =&gt;, but we left it out here for brevity, because we're talking about functors anyway so we know what the f stands for. When we first learned about curried functions, we said that all Haskell functions actually take one parameter. A function a -&gt; b -&gt; c actually takes just one parameter of type a and then returns a function b -&gt; c, which takes one parameter and returns a c. That's how if we call a function with too few parameters (i.e. partially apply it), we get back a function that takes the number of parameters that we left out (if we're thinking about functions as taking several parameters again). So a -&gt; b -&gt; c can be written as a -&gt; (b -&gt; c), to make the currying more apparent.</p>
<p>In the same vein, if we write fmap :: (a -&gt; b) -&gt; (f a -&gt; f b), we can think of fmap not as a function that takes one function and a functor and returns a functor, but as a function that takes a function and returns a new function that's just like the old one, only it takes a functor as a parameter and returns a functor as the result. It takes an a -&gt; b function and returns a function f a -&gt; f b. This is called lifting a function. Let's play around with that idea by using GHCI's :t command:</p>
<pre><code>ghci&gt; :t fmap (*2)  
fmap (*2) :: (Num a, Functor f) =&gt; f a -&gt; f a  
ghci&gt; :t fmap (replicate 3)  
fmap (replicate 3) :: (Functor f) =&gt; f a -&gt; f [a]
</code></pre>
<p>The expression fmap (*2) is a function that takes a functor f over numbers and returns a functor over numbers. That functor can be a list, a Maybe , an Either String, whatever. The expression fmap (replicate 3) will take a functor over any type and return a functor over a list of elements of that type.
When we say a functor over numbers, you can think of that as a functor that has numbers in it. The former is a bit fancier and more technically correct, but the latter is usually easier to get.</p>
<p>This is even more apparent if we partially apply, say, fmap (++"!") and then bind it to a name in GHCI.</p>
<p>You can think of fmap as either a function that takes a function and a functor and then maps that function over the functor, or you can think of it as a function that takes a function and lifts that function so that it operates on functors. Both views are correct and in Haskell, equivalent.</p>
<p>The type fmap (replicate 3) :: (Functor f) =&gt; f a -&gt; f [a] means that the function will work on any functor. What exactly it will do depends on which functor we use it on. If we use fmap (replicate 3) on a list, the list's implementation for fmap will be chosen, which is just map. If we use it on a Maybe a, it'll apply replicate 3 to the value inside the Just, or if it's Nothing, then it stays Nothing.</p>
<pre><code>ghci&gt; fmap (replicate 3) [1,2,3,4]  
[[1,1,1],[2,2,2],[3,3,3],[4,4,4]]  
ghci&gt; fmap (replicate 3) (Just 4)  
Just [4,4,4]  
ghci&gt; fmap (replicate 3) (Right "blah")  
Right ["blah","blah","blah"]  
ghci&gt; fmap (replicate 3) Nothing  
Nothing  
ghci&gt; fmap (replicate 3) (Left "foo")  
Left "foo"
</code></pre>
<p>Next up, we're going to look at the functor laws. In order for something to be a functor, it should satisfy some laws. All functors are expected to exhibit certain kinds of functor-like properties and behaviors. They should reliably behave as things that can be mapped over. Calling fmap on a functor should just map a function over the functor, nothing more. This behavior is described in the functor laws. There are two of them that all instances of Functor should abide by. They aren't enforced by Haskell automatically, so you have to test them out yourself.</p>
<p>The first functor law states that if we map the id function over a functor, the functor that we get back should be the same as the original functor. If we write that a bit more formally, it means that fmap id = id. So essentially, this says that if we do fmap id over a functor, it should be the same as just calling id on the functor. Remember, id is the identity function, which just returns its parameter unmodified. It can also be written as \x -&gt; x. If we view the functor as something that can be mapped over, the fmap id = id law seems kind of trivial or obvious.</p>
<p>Let's see if this law holds for a few values of functors.</p>
<pre><code>ghci&gt; fmap id (Just 3)  
Just 3  
ghci&gt; id (Just 3)  
Just 3  
ghci&gt; fmap id [1..5]  
[1,2,3,4,5]  
ghci&gt; id [1..5]  
[1,2,3,4,5]  
ghci&gt; fmap id []  
[]  
ghci&gt; fmap id Nothing  
Nothing
</code></pre>
<p>If we look at the implementation of fmap for, say, Maybe, we can figure out why the first functor law holds.</p>
<pre><code>instance Functor Maybe where  
    fmap f (Just x) = Just (f x)  
    fmap f Nothing = Nothing
</code></pre>
<p>We imagine that id plays the role of the f parameter in the implementation. We see that if wee fmap id over Just x, the result will be Just (id x), and because id just returns its parameter, we can deduce that Just (id x) equals Just x. So now we know that if we map id over a Maybe value with a Just value constructor, we get that same value back.</p>
<p>Seeing that mapping id over a Nothing value returns the same value is trivial. So from these two equations in the implementation for fmap, we see that the law fmap id = id holds.
justice is blind, but so is my dog</p>
<p>The second law says that composing two functions and then mapping the resulting function over a functor should be the same as first mapping one function over the functor and then mapping the other one. Formally written, that means that fmap (f . g) = fmap f . fmap g. Or to write it in another way, for any functor F, the following should hold: fmap (f . g) F = fmap f (fmap g F).</p>
<p>If we can show that some type obeys both functor laws, we can rely on it having the same fundamental behaviors as other functors when it comes to mapping. We can know that when we use fmap on it, there won't be anything other than mapping going on behind the scenes and that it will act like a thing that can be mapped over, i.e. a functor. You figure out how the second law holds for some type by looking at the implementation of fmap for that type and then using the method that we used to check if Maybe obeys the first law.</p>
<p>If you want, we can check out how the second functor law holds for Maybe. If we do fmap (f . g) over Nothing, we get Nothing, because doing a fmap with any function over Nothing returns Nothing. If we do fmap f (fmap g Nothing), we get Nothing, for the same reason. OK, seeing how the second law holds for Maybe if it's a Nothing value is pretty easy, almost trivial.</p>
<p>How about if it's a Just something value? Well, if we do fmap (f . g) (Just x), we see from the implementation that it's implemented as Just ((f . g) x), which is, of course, Just (f (g x)). If we do fmap f (fmap g (Just x)), we see from the implementation that fmap g (Just x) is Just (g x). Ergo, fmap f (fmap g (Just x)) equals fmap f (Just (g x)) and from the implementation we see that this equals Just (f (g x)).</p>
<p>If you're a bit confused by this proof, don't worry. Be sure that you understand how function composition works. Many times, you can intuitively see how these laws hold because the types act like containers or functions. You can also just try them on a bunch of different values of a type and be able to say with some certainty that a type does indeed obey the laws.</p>
<p>Let's take a look at a pathological example of a type constructor being an instance of the Functor typeclass but not really being a functor, because it doesn't satisfy the laws. Let's say that we have a type:</p>
<pre><code>data CMaybe a = CNothing | CJust Int a deriving (Show)
</code></pre>
<p>The C here stands for counter. It's a data type that looks much like Maybe a, only the Just part holds two fields instead of one. The first field in the CJust value constructor will always have a type of Int, and it will be some sort of counter and the second field is of type a, which comes from the type parameter and its type will, of course, depend on the concrete type that we choose for CMaybe a. Let's play with our new type to get some intuition for it.</p>
<pre><code>ghci&gt; CNothing  
CNothing  
ghci&gt; CJust 0 "haha"  
CJust 0 "haha"  
ghci&gt; :t CNothing  
CNothing :: CMaybe a  
ghci&gt; :t CJust 0 "haha"  
CJust 0 "haha" :: CMaybe [Char]  
ghci&gt; CJust 100 [1,2,3]  
CJust 100 [1,2,3]
</code></pre>
<p>If we use the CNothing constructor, there are no fields, and if we use the CJust constructor, the first field is an integer and the second field can be any type. Let's make this an instance of Functor so that everytime we use fmap, the function gets applied to the second field, whereas the first field gets increased by 1.</p>
<pre><code>instance Functor CMaybe where  
    fmap f CNothing = CNothing  
    fmap f (CJust counter x) = CJust (counter+1) (f x)
</code></pre>
<p>This is kind of like the instance implementation for Maybe, except that when we do fmap over a value that doesn't represent an empty box (a CJust value), we don't just apply the function to the contents, we also increase the counter by 1. Everything seems cool so far, we can even play with this a bit:</p>
<pre><code>ghci&gt; fmap (++"ha") (CJust 0 "ho")  
CJust 1 "hoha"  
ghci&gt; fmap (++"he") (fmap (++"ha") (CJust 0 "ho"))  
CJust 2 "hohahe"  
ghci&gt; fmap (++"blah") CNothing  
CNothing
</code></pre>
<p>Does this obey the functor laws? In order to see that something doesn't obey a law, it's enough to find just one counter-example.</p>
<pre><code>ghci&gt; fmap id (CJust 0 "haha")  
CJust 1 "haha"  
ghci&gt; id (CJust 0 "haha")  
CJust 0 "haha"
</code></pre>
<p>Ah! We know that the first functor law states that if we map id over a functor, it should be the same as just calling id with the same functor, but as we've seen from this example, this is not true for our CMaybe functor. Even though it's part of the Functor typeclass, it doesn't obey the functor laws and is therefore not a functor. If someone used our CMaybe type as a functor, they would expect it to obey the functor laws like a good functor. But CMaybe fails at being a functor even though it pretends to be one, so using it as a functor might lead to some faulty code. When we use a functor, it shouldn't matter if we first compose a few functions and then map them over the functor or if we just map each function over a functor in succession. But with CMaybe, it matters, because it keeps track of how many times it's been mapped over. Not cool! If we wanted CMaybe to obey the functor laws, we'd have to make it so that the Int field stays the same when we use fmap.</p>
<p>At first, the functor laws might seem a bit confusing and unnecessary, but then we see that if we know that a type obeys both laws, we can make certain assumptions about how it will act. If a type obeys the functor laws, we know that calling fmap on a value of that type will only map the function over it, nothing more. This leads to code that is more abstract and extensible, because we can use laws to reason about behaviors that any functor should have and make functions that operate reliably on any functor.</p>
<p>All the Functor instances in the standard library obey these laws, but you can check for yourself if you don't believe me. And the next time you make a type an instance of Functor, take a minute to make sure that it obeys the functor laws. Once you've dealt with enough functors, you kind of intuitively see the properties and behaviors that they have in common and it's not hard to intuitively see if a type obeys the functor laws. But even without the intuition, you can always just go over the implementation line by line and see if the laws hold or try to find a counter-example.</p>
<p>We can also look at functors as things that output values in a context. For instance, Just 3 outputs the value 3 in the context that it might or not output any values at all. [1,2,3] outputs three values—1, 2, and 3, the context is that there may be multiple values or no values. The function (+3) will output a value, depending on which parameter it is given.</p>
<p>If you think of functors as things that output values, you can think of mapping over functors as attaching a transformation to the output of the functor that changes the value. When we do fmap (+3) [1,2,3], we attach the transformation (+3) to the output of [1,2,3], so whenever we look at a number that the list outputs, (+3) will be applied to it. Another example is mapping over functions. When we do fmap (+3) (<em>3), we attach the transformation (+3) to the eventual output of (</em>3). Looking at it this way gives us some intuition as to why using fmap on functions is just composition (fmap (+3) (<em>3) equals (+3) . (</em>3), which equals \x -&gt; ((x<em>3)+3)), because we take a function like (</em>3) then we attach the transformation (+3) to its output. The result is still a function, only when we give it a number, it will be multiplied by three and then it will go through the attached transformation where it will be added to three. This is what happens with composition.
Applicative functors
disregard this analogy</p>
<p>In this section, we'll take a look at applicative functors, which are beefed up functors, represented in Haskell by the Applicative typeclass, found in the Control.Applicative module.</p>
<p>As you know, functions in Haskell are curried by default, which means that a function that seems to take several parameters actually takes just one parameter and returns a function that takes the next parameter and so on. If a function is of type a -&gt; b -&gt; c, we usually say that it takes two parameters and returns a c, but actually it takes an a and returns a function b -&gt; c. That's why we can call a function as f x y or as (f x) y. This mechanism is what enables us to partially apply functions by just calling them with too few parameters, which results in functions that we can then pass on to other functions.</p>
<p>So far, when we were mapping functions over functors, we usually mapped functions that take only one parameter. But what happens when we map a function like <em>, which takes two parameters, over a functor? Let's take a look at a couple of concrete examples of this. If we have Just 3 and we do fmap (</em>) (Just 3), what do we get? From the instance implementation of Maybe for Functor, we know that if it's a Just something value, it will apply the function to the something inside the Just. Therefore, doing fmap (<em>) (Just 3) results in Just ((</em>) 3), which can also be written as Just (* 3) if we use sections. Interesting! We get a function wrapped in a Just!</p>
<pre><code>ghci&gt; :t fmap (++) (Just "hey")  
fmap (++) (Just "hey") :: Maybe ([Char] -&gt; [Char])  
ghci&gt; :t fmap compare (Just 'a')  
fmap compare (Just 'a') :: Maybe (Char -&gt; Ordering)  
ghci&gt; :t fmap compare "A LIST OF CHARS"  
fmap compare "A LIST OF CHARS" :: [Char -&gt; Ordering]  
ghci&gt; :t fmap (\x y z -&gt; x + y / z) [3,4,5,6]  
fmap (\x y z -&gt; x + y / z) [3,4,5,6] :: (Fractional a) =&gt; [a -&gt; a -&gt; a]
</code></pre>
<p>If we map compare, which has a type of (Ord a) =&gt; a -&gt; a -&gt; Ordering over a list of characters, we get a list of functions of type Char -&gt; Ordering, because the function compare gets partially applied with the characters in the list. It's not a list of (Ord a) =&gt; a -&gt; Ordering function, because the first a that got applied was a Char and so the second a has to decide to be of type Char.</p>
<p>We see how by mapping "multi-parameter" functions over functors, we get functors that contain functions inside them. So now what can we do with them? Well for one, we can map functions that take these functions as parameters over them, because whatever is inside a functor will be given to the function that we're mapping over it as a parameter.</p>
<pre><code>ghci&gt; let a = fmap (*) [1,2,3,4]  
ghci&gt; :t a  
a :: [Integer -&gt; Integer]  
ghci&gt; fmap (\f -&gt; f 9) a  
[9,18,27,36]
</code></pre>
<p>But what if we have a functor value of Just (3 <em>) and a functor value of Just 5 and we want to take out the function from Just (3 </em>) and map it over Just 5? With normal functors, we're out of luck, because all they support is just mapping normal functions over existing functors. Even when we mapped \f -&gt; f 9 over a functor that contained functions inside it, we were just mapping a normal function over it. But we can't map a function that's inside a functor over another functor with what fmap offers us. We could pattern-match against the Just constructor to get the function out of it and then map it over Just 5, but we're looking for a more general and abstract way of doing that, which works across functors.</p>
<p>Meet the Applicative typeclass. It lies in the Control.Applicative module and it defines two methods, pure and &lt;*&gt;. It doesn't provide a default implementation for any of them, so we have to define them both if we want something to be an applicative functor. The class is defined like so:</p>
<pre><code>class (Functor f) =&gt; Applicative f where  
    pure :: a -&gt; f a  
    (&lt;*&gt;) :: f (a -&gt; b) -&gt; f a -&gt; f b
</code></pre>
<p>This simple three line class definition tells us a lot! Let's start at the first line. It starts the definition of the Applicative class and it also introduces a class constraint. It says that if we want to make a type constructor part of the Applicative typeclass, it has to be in Functor first. That's why if we know that if a type constructor is part of the Applicative typeclass, it's also in Functor, so we can use fmap on it.</p>
<p>The first method it defines is called pure. Its type declaration is pure :: a -&gt; f a. f plays the role of our applicative functor instance here. Because Haskell has a very good type system and because everything a function can do is take some parameters and return some value, we can tell a lot from a type declaration and this is no exception. pure should take a value of any type and return an applicative functor with that value inside it. When we say inside it, we're using the box analogy again, even though we've seen that it doesn't always stand up to scrutiny. But the a -&gt; f a type declaration is still pretty descriptive. We take a value and we wrap it in an applicative functor that has that value as the result inside it.</p>
<p>A better way of thinking about pure would be to say that it takes a value and puts it in some sort of default (or pure) context—a minimal context that still yields that value.</p>
<p>The &lt;<em>&gt; function is really interesting. It has a type declaration of f (a -&gt; b) -&gt; f a -&gt; f b. Does this remind you of anything? Of course, fmap :: (a -&gt; b) -&gt; f a -&gt; f b. It's a sort of a beefed up fmap. Whereas fmap takes a function and a functor and applies the function inside the functor, &lt;</em>&gt; takes a functor that has a function in it and another functor and sort of extracts that function from the first functor and then maps it over the second one. When I say extract, I actually sort of mean run and then extract, maybe even sequence. We'll see why soon.</p>
<p>Let's take a look at the Applicative instance implementation for Maybe.</p>
<pre><code>instance Applicative Maybe where  
    pure = Just  
    Nothing &lt;*&gt; _ = Nothing  
    (Just f) &lt;*&gt; something = fmap f something
</code></pre>
<p>Again, from the class definition we see that the f that plays the role of the applicative functor should take one concrete type as a parameter, so we write instance Applicative Maybe where instead of writing instance Applicative (Maybe a) where.</p>
<p>First off, pure. We said earlier that it's supposed to take something and wrap it in an applicative functor. We wrote pure = Just, because value constructors like Just are normal functions. We could have also written pure x = Just x.</p>
<p>Next up, we have the definition for &lt;<em>&gt;. We can't extract a function out of a Nothing, because it has no function inside it. So we say that if we try to extract a function from a Nothing, the result is a Nothing. If you look at the class definition for Applicative, you'll see that there's a Functor class constraint, which means that we can assume that both of &lt;</em>&gt;'s parameters are functors. If the first parameter is not a Nothing, but a Just with some function inside it, we say that we then want to map that function over the second parameter. This also takes care of the case where the second parameter is Nothing, because doing fmap with any function over a Nothing will return a Nothing.</p>
<p>So for Maybe, &lt;*&gt; extracts the function from the left value if it's a Just and maps it over the right value. If any of the parameters is Nothing, Nothing is the result.</p>
<p>OK cool great. Let's give this a whirl.</p>
<pre><code>ghci&gt; Just (+3) &lt;*&gt; Just 9  
Just 12  
ghci&gt; pure (+3) &lt;*&gt; Just 10  
Just 13  
ghci&gt; pure (+3) &lt;*&gt; Just 9  
Just 12  
ghci&gt; Just (++"hahah") &lt;*&gt; Nothing  
Nothing  
ghci&gt; Nothing &lt;*&gt; Just "woot"  
Nothing
</code></pre>
<p>We see how doing pure (+3) and Just (+3) is the same in this case. Use pure if you're dealing with Maybe values in an applicative context (i.e. using them with &lt;*&gt;), otherwise stick to Just. The first four input lines demonstrate how the function is extracted and then mapped, but in this case, they could have been achieved by just mapping unwrapped functions over functors. The last line is interesting, because we try to extract a function from a Nothing and then map it over something, which of course results in a Nothing.</p>
<p>With normal functors, you can just map a function over a functor and then you can't get the result out in any general way, even if the result is a partially applied function. Applicative functors, on the other hand, allow you to operate on several functors with a single function. Check out this piece of code:</p>
<pre><code>ghci&gt; pure (+) &lt;*&gt; Just 3 &lt;*&gt; Just 5  
Just 8  
ghci&gt; pure (+) &lt;*&gt; Just 3 &lt;*&gt; Nothing  
Nothing  
ghci&gt; pure (+) &lt;*&gt; Nothing &lt;*&gt; Just 5  
Nothing
</code></pre>
<p>whaale</p>
<p>What's going on here? Let's take a look, step by step. &lt;<em>&gt; is left-associative, which means that pure (+) &lt;</em>&gt; Just 3 &lt;<em>&gt; Just 5 is the same as (pure (+) &lt;</em>&gt; Just 3) &lt;<em>&gt; Just 5. First, the + function is put in a functor, which is in this case a Maybe value that contains the function. So at first, we have pure (+), which is Just (+). Next, Just (+) &lt;</em>&gt; Just 3 happens. The result of this is Just (3+). This is because of partial application. Only applying 3 to the + function results in a function that takes one parameter and adds 3 to it. Finally, Just (3+) &lt;*&gt; Just 5 is carried out, which results in a Just 8.</p>
<p>Isn't this awesome?! Applicative functors and the applicative style of doing pure f &lt;<em>&gt; x &lt;</em>&gt; y &lt;<em>&gt; ... allow us to take a function that expects parameters that aren't necessarily wrapped in functors and use that function to operate on several values that are in functor contexts. The function can take as many parameters as we want, because it's always partially applied step by step between occurences of &lt;</em>&gt;.</p>
<p>This becomes even more handy and apparent if we consider the fact that pure f &lt;<em>&gt; x equals fmap f x. This is one of the applicative laws. We'll take a closer look at them later, but for now, we can sort of intuitively see that this is so. Think about it, it makes sense. Like we said before, pure puts a value in a default context. If we just put a function in a default context and then extract and apply it to a value inside another applicative functor, we did the same as just mapping that function over that applicative functor. Instead of writing pure f &lt;</em>&gt; x &lt;<em>&gt; y &lt;</em>&gt; ..., we can write fmap f x &lt;<em>&gt; y &lt;</em>&gt; .... This is why Control.Applicative exports a function called &lt;$&gt;, which is just fmap as an infix operator. Here's how it's defined:</p>
<pre><code>(&lt;$&gt;) :: (Functor f) =&gt; (a -&gt; b) -&gt; f a -&gt; f b  
f &lt;$&gt; x = fmap f x
</code></pre>
<p>Yo! Quick reminder: type variables are independent of parameter names or other value names. The f in the function declaration here is a type variable with a class constraint saying that any type constructor that replaces f should be in the Functor typeclass. The f in the function body denotes a function that we map over x. The fact that we used f to represent both of those doesn't mean that they somehow represent the same thing.</p>
<p>By using &lt;$&gt;, the applicative style really shines, because now if we want to apply a function f between three applicative functors, we can write f &lt;$&gt; x &lt;<em>&gt; y &lt;</em>&gt; z. If the parameters weren't applicative functors but normal values, we'd write f x y z.</p>
<p>Let's take a closer look at how this works. We have a value of Just "johntra" and a value of Just "volta" and we want to join them into one String inside a Maybe functor. We do this:</p>
<pre><code>ghci&gt; (++) &lt;$&gt; Just "johntra" &lt;*&gt; Just "volta"  
Just "johntravolta"
</code></pre>
<p>Before we see how this happens, compare the above line with this:</p>
<pre><code>ghci&gt; (++) "johntra" "volta"  
"johntravolta"
</code></pre>
<p>Awesome! To use a normal function on applicative functors, just sprinkle some &lt;$&gt; and &lt;*&gt; about and the function will operate on applicatives and return an applicative. How cool is that?</p>
<p>Anyway, when we do (++) &lt;$&gt; Just "johntra" &lt;<em>&gt; Just "volta", first (++), which has a type of (++) :: [a] -&gt; [a] -&gt; [a] gets mapped over Just "johntra", resulting in a value that's the same as Just ("johntra"++) and has a type of Maybe ([Char] -&gt; [Char]). Notice how the first parameter of (++) got eaten up and how the as turned into Chars. And now Just ("johntra"++) &lt;</em>&gt; Just "volta" happens, which takes the function out of the Just and maps it over Just "volta", resulting in Just "johntravolta". Had any of the two values been Nothing, the result would have also been Nothing.</p>
<p>So far, we've only used Maybe in our examples and you might be thinking that applicative functors are all about Maybe. There are loads of other instances of Applicative, so let's go and meet them!</p>
<p>Lists (actually the list type constructor, []) are applicative functors. What a suprise! Here's how [] is an instance of Applicative:</p>
<pre><code>instance Applicative [] where  
    pure x = [x]  
    fs &lt;*&gt; xs = [f x | f &lt;- fs, x &lt;- xs]
</code></pre>
<p>Earlier, we said that pure takes a value and puts it in a default context. Or in other words, a minimal context that still yields that value. The minimal context for lists would be the empty list, [], but the empty list represents the lack of a value, so it can't hold in itself the value that we used pure on. That's why pure takes a value and puts it in a singleton list. Similarly, the minimal context for the Maybe applicative functor would be a Nothing, but it represents the lack of a value instead of a value, so pure is implemented as Just in the instance implementation for Maybe.</p>
<pre><code>ghci&gt; pure "Hey" :: [String]  
["Hey"]  
ghci&gt; pure "Hey" :: Maybe String  
Just "Hey"
</code></pre>
<p>What about &lt;<em>&gt;? If we look at what &lt;</em>&gt;'s type would be if it were limited only to lists, we get (&lt;<em>&gt;) :: [a -&gt; b] -&gt; [a] -&gt; [b]. It's implemented with a list comprehension. &lt;</em>&gt; has to somehow extract the function out of its left parameter and then map it over the right parameter. But the thing here is that the left list can have zero functions, one function, or several functions inside it. The right list can also hold several values. That's why we use a list comprehension to draw from both lists. We apply every possible function from the left list to every possible value from the right list. The resulting list has every possible combination of applying a function from the left list to a value in the right one.</p>
<pre><code>ghci&gt; [(*0),(+100),(^2)] &lt;*&gt; [1,2,3]  
[0,0,0,101,102,103,1,4,9]
</code></pre>
<p>The left list has three functions and the right list has three values, so the resulting list will have nine elements. Every function in the left list is applied to every function in the right one. If we have a list of functions that take two parameters, we can apply those functions between two lists.</p>
<pre><code>ghci&gt; [(+),(*)] &lt;*&gt; [1,2] &lt;*&gt; [3,4]  
[4,5,5,6,3,4,6,8]
</code></pre>
<p>Because &lt;<em>&gt; is left-associative, [(+),(</em>)] &lt;<em>&gt; [1,2] happens first, resulting in a list that's the same as [(1+),(2+),(1</em>),(2<em>)], because every function on the left gets applied to every value on the right. Then, [(1+),(2+),(1</em>),(2<em>)] &lt;</em>&gt; [3,4] happens, which produces the final result.</p>
<p>Using the applicative style with lists is fun! Watch:</p>
<pre><code>ghci&gt; (++) &lt;$&gt; ["ha","heh","hmm"] &lt;*&gt; ["?","!","."]  
["ha?","ha!","ha.","heh?","heh!","heh.","hmm?","hmm!","hmm."]
</code></pre>
<p>Again, see how we used a normal function that takes two strings between two applicative functors of strings just by inserting the appropriate applicative operators.</p>
<p>You can view lists as non-deterministic computations. A value like 100 or "what" can be viewed as a deterministic computation that has only one result, whereas a list like [1,2,3] can be viewed as a computation that can't decide on which result it wants to have, so it presents us with all of the possible results. So when you do something like (+) &lt;$&gt; [1,2,3] &lt;*&gt; [4,5,6], you can think of it as adding together two non-deterministic computations with +, only to produce another non-deterministic computation that's even less sure about its result.</p>
<p>Using the applicative style on lists is often a good replacement for list comprehensions. In the second chapter, we wanted to see all the possible products of [2,5,10] and [8,10,11], so we did this:</p>
<pre><code>ghci&gt; [ x*y | x &lt;- [2,5,10], y &lt;- [8,10,11]]     
[16,20,22,40,50,55,80,100,110]
</code></pre>
<p>We're just drawing from two lists and applying a function between every combination of elements. This can be done in the applicative style as well:</p>
<pre><code>ghci&gt; (*) &lt;$&gt; [2,5,10] &lt;*&gt; [8,10,11]  
[16,20,22,40,50,55,80,100,110]
</code></pre>
<p>This seems clearer to me, because it's easier to see that we're just calling * between two non-deterministic computations. If we wanted all possible products of those two lists that are more than 50, we'd just do:</p>
<pre><code>ghci&gt; filter (&gt;50) $ (*) &lt;$&gt; [2,5,10] &lt;*&gt; [8,10,11]  
[55,80,100,110]
</code></pre>
<p>It's easy to see how pure f &lt;<em>&gt; xs equals fmap f xs with lists. pure f is just [f] and [f] &lt;</em>&gt; xs will apply every function in the left list to every value in the right one, but there's just one function in the left list, so it's like mapping.</p>
<p>Another instance of Applicative that we've already encountered is IO. This is how the instance is implemented:</p>
<pre><code>instance Applicative IO where  
    pure = return  
    a &lt;*&gt; b = do  
        f &lt;- a  
        x &lt;- b  
        return (f x)
</code></pre>
<p>ahahahah!</p>
<p>Since pure is all about putting a value in a minimal context that still holds it as its result, it makes sense that pure is just return, because return does exactly that; it makes an I/O action that doesn't do anything, it just yields some value as its result, but it doesn't really do any I/O operations like printing to the terminal or reading from a file.</p>
<p>If &lt;<em>&gt; were specialized for IO it would have a type of (&lt;</em>&gt;) :: IO (a -&gt; b) -&gt; IO a -&gt; IO b. It would take an I/O action that yields a function as its result and another I/O action and create a new I/O action from those two that, when performed, first performs the first one to get the function and then performs the second one to get the value and then it would yield that function applied to the value as its result. We used do syntax to implement it here. Remember, do syntax is about taking several I/O actions and gluing them into one, which is exactly what we do here.</p>
<p>With Maybe and [], we could think of &lt;*&gt; as simply extracting a function from its left parameter and then sort of applying it over the right one. With IO, extracting is still in the game, but now we also have a notion of sequencing, because we're taking two I/O actions and we're sequencing, or gluing, them into one. We have to extract the function from the first I/O action, but to extract a result from an I/O action, it has to be performed.</p>
<p>Consider this:</p>
<pre><code>myAction :: IO String  
myAction = do  
    a &lt;- getLine  
    b &lt;- getLine  
    return $ a ++ b
</code></pre>
<p>This is an I/O action that will prompt the user for two lines and yield as its result those two lines concatenated. We achieved it by gluing together two getLine I/O actions and a return, because we wanted our new glued I/O action to hold the result of a ++ b. Another way of writing this would be to use the applicative style.</p>
<pre><code>myAction :: IO String  
myAction = (++) &lt;$&gt; getLine &lt;*&gt; getLine
</code></pre>
<p>What we were doing before was making an I/O action that applied a function between the results of two other I/O actions, and this is the same thing. Remember, getLine is an I/O action with the type getLine :: IO String. When we use &lt;*&gt; between two applicative functors, the result is an applicative functor, so this all makes sense.</p>
<p>If we regress to the box analogy, we can imagine getLine as a box that will go out into the real world and fetch us a string. Doing (++) &lt;$&gt; getLine &lt;*&gt; getLine makes a new, bigger box that sends those two boxes out to fetch lines from the terminal and then presents the concatenation of those two lines as its result.</p>
<p>The type of the expression (++) &lt;$&gt; getLine &lt;*&gt; getLine is IO String, which means that this expression is a completely normal I/O action like any other, which also holds a result value inside it, just like other I/O actions. That's why we can do stuff like:</p>
<pre><code>main = do  
    a &lt;- (++) &lt;$&gt; getLine &lt;*&gt; getLine  
    putStrLn $ "The two lines concatenated turn out to be: " ++ a
</code></pre>
<p>If you ever find yourself binding some I/O actions to names and then calling some function on them and presenting that as the result by using return, consider using the applicative style because it's arguably a bit more concise and terse.</p>
<p>Another instance of Applicative is (-&gt;) r, so functions. They are rarely used with the applicative style outside of code golf, but they're still interesting as applicatives, so let's take a look at how the function instance is implemented.
If you're confused about what (-&gt;) r means, check out the previous section where we explain how (-&gt;) r is a functor.</p>
<pre><code>instance Applicative ((-&gt;) r) where  
    pure x = (\_ -&gt; x)  
    f &lt;*&gt; g = \x -&gt; f x (g x)
</code></pre>
<p>When we wrap a value into an applicative functor with pure, the result it yields always has to be that value. A minimal default context that still yields that value as a result. That's why in the function instance implementation, pure takes a value and creates a function that ignores its parameter and always returns that value. If we look at the type for pure, but specialized for the (-&gt;) r instance, it's pure :: a -&gt; (r -&gt; a).</p>
<pre><code>ghci&gt; (pure 3) "blah"  
3
</code></pre>
<p>Because of currying, function application is left-associative, so we can omit the parentheses.</p>
<pre><code>ghci&gt; pure 3 "blah"  
3
</code></pre>
<p>The instance implementation for &lt;*&gt; is a bit cryptic, so it's best if we just take a look at how to use functions as applicative functors in the applicative style.</p>
<pre><code>ghci&gt; :t (+) &lt;$&gt; (+3) &lt;*&gt; (*100)  
(+) &lt;$&gt; (+3) &lt;*&gt; (*100) :: (Num a) =&gt; a -&gt; a  
ghci&gt; (+) &lt;$&gt; (+3) &lt;*&gt; (*100) $ 5  
508
</code></pre>
<p>Calling &lt;<em>&gt; with two applicative functors results in an applicative functor, so if we use it on two functions, we get back a function. So what goes on here? When we do (+) &lt;$&gt; (+3) &lt;</em>&gt; (<em>100), we're making a function that will use + on the results of (+3) and (</em>100) and return that. To demonstrate on a real example, when we did (+) &lt;$&gt; (+3) &lt;<em>&gt; (</em>100) $ 5, the 5 first got applied to (+3) and (*100), resulting in 8 and 500. Then, + gets called with 8 and 500, resulting in 508.</p>
<pre><code>ghci&gt; (\x y z -&gt; [x,y,z]) &lt;$&gt; (+3) &lt;*&gt; (*2) &lt;*&gt; (/2) $ 5  
[8.0,10.0,2.5]
</code></pre>
<p>SLAP</p>
<p>Same here. We create a function that will call the function \x y z -&gt; [x,y,z] with the eventual results from (+3), (*2) and (/2). The 5 gets fed to each of the three functions and then \x y z -&gt; [x, y, z] gets called with those results.</p>
<p>You can think of functions as boxes that contain their eventual results, so doing k &lt;$&gt; f &lt;<em>&gt; g creates a function that will call k with the eventual results from f and g. When we do something like (+) &lt;$&gt; Just 3 &lt;</em>&gt; Just 5, we're using + on values that might or might not be there, which also results in a value that might or might not be there. When we do (+) &lt;$&gt; (+10) &lt;*&gt; (+5), we're using + on the future return values of (+10) and (+5) and the result is also something that will produce a value only when called with a parameter.</p>
<p>We don't often use functions as applicatives, but this is still really interesting. It's not very important that you get how the (-&gt;) r instance for Applicative works, so don't despair if you're not getting this right now. Try playing with the applicative style and functions to build up an intuition for functions as applicatives.</p>
<p>An instance of Applicative that we haven't encountered yet is ZipList, and it lives in Control.Applicative.</p>
<p>It turns out there are actually more ways for lists to be applicative functors. One way is the one we already covered, which says that calling &lt;<em>&gt; with a list of functions and a list of values results in a list which has all the possible combinations of applying functions from the left list to the values in the right list. If we do [(+3),(</em>2)] &lt;<em>&gt; [1,2], (+3) will be applied to both 1 and 2 and (</em>2) will also be applied to both 1 and 2, resulting in a list that has four elements, namely [4,5,2,4].</p>
<p>However, [(+3),(<em>2)] &lt;</em>&gt; [1,2] could also work in such a way that the first function in the left list gets applied to the first value in the right one, the second function gets applied to the second value, and so on. That would result in a list with two values, namely [4,4]. You could look at it as [1 + 3, 2 * 2].</p>
<p>Because one type can't have two instances for the same typeclass, the ZipList a type was introduced, which has one constructor ZipList that has just one field, and that field is a list. Here's the instance:</p>
<pre><code>instance Applicative ZipList where  
        pure x = ZipList (repeat x)  
        ZipList fs &lt;*&gt; ZipList xs = ZipList (zipWith (\f x -&gt; f x) fs xs)
</code></pre>
<p>&lt;*&gt; does just what we said. It applies the first function to the first value, the second function to the second value, etc. This is done with zipWith (\f x -&gt; f x) fs xs. Because of how zipWith works, the resulting list will be as long as the shorter of the two lists.</p>
<p>pure is also interesting here. It takes a value and puts it in a list that just has that value repeating indefinitely. pure "haha" results in ZipList (["haha","haha","haha".... This might be a bit confusing since we said that pure should put a value in a minimal context that still yields that value. And you might be thinking that an infinite list of something is hardly minimal. But it makes sense with zip lists, because it has to produce the value on every position. This also satisfies the law that pure f &lt;<em>&gt; xs should equal fmap f xs. If pure 3 just returned ZipList [3], pure (</em>2) &lt;*&gt; ZipList [1,5,10] would result in ZipList [2], because the resulting list of two zipped lists has the length of the shorter of the two. If we zip a finite list with an infinite list, the length of the resulting list will always be equal to the length of the finite list.</p>
<p>So how do zip lists work in an applicative style? Let's see. Oh, the ZipList a type doesn't have a Show instance, so we have to use the getZipList function to extract a raw list out of a zip list.</p>
<pre><code>ghci&gt; getZipList $ (+) &lt;$&gt; ZipList [1,2,3] &lt;*&gt; ZipList [100,100,100]  
[101,102,103]  
ghci&gt; getZipList $ (+) &lt;$&gt; ZipList [1,2,3] &lt;*&gt; ZipList [100,100..]  
[101,102,103]  
ghci&gt; getZipList $ max &lt;$&gt; ZipList [1,2,3,4,5,3] &lt;*&gt; ZipList [5,3,1,2]  
[5,3,3,4]  
ghci&gt; getZipList $ (,,) &lt;$&gt; ZipList "dog" &lt;*&gt; ZipList "cat" &lt;*&gt; ZipList "rat"  
[('d','c','r'),('o','a','a'),('g','t','t')]
</code></pre>
<p>The (,,) function is the same as \x y z -&gt; (x,y,z). Also, the (,) function is the same as \x y -&gt; (x,y).</p>
<p>Aside from zipWith, the standard library has functions such as zipWith3, zipWith4, all the way up to 7. zipWith takes a function that takes two parameters and zips two lists with it. zipWith3 takes a function that takes three parameters and zips three lists with it, and so on. By using zip lists with an applicative style, we don't have to have a separate zip function for each number of lists that we want to zip together. We just use the applicative style to zip together an arbitrary amount of lists with a function, and that's pretty cool.</p>
<p>Control.Applicative defines a function that's called liftA2, which has a type of liftA2 :: (Applicative f) =&gt; (a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; f c . It's defined like this:</p>
<pre><code>liftA2 :: (Applicative f) =&gt; (a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; f c  
liftA2 f a b = f &lt;$&gt; a &lt;*&gt; b
</code></pre>
<p>Nothing special, it just applies a function between two applicatives, hiding the applicative style that we've become familiar with. The reason we're looking at it is because it clearly showcases why applicative functors are more powerful than just ordinary functors. With ordinary functors, we can just map functions over one functor. But with applicative functors, we can apply a function between several functors. It's also interesting to look at this function's type as (a -&gt; b -&gt; c) -&gt; (f a -&gt; f b -&gt; f c). When we look at it like this, we can say that liftA2 takes a normal binary function and promotes it to a function that operates on two functors.</p>
<p>Here's an interesting concept: we can take two applicative functors and combine them into one applicative functor that has inside it the results of those two applicative functors in a list. For instance, we have Just 3 and Just 4. Let's assume that the second one has a singleton list inside it, because that's really easy to achieve:</p>
<pre><code>ghci&gt; fmap (\x -&gt; [x]) (Just 4)  
Just [4]
</code></pre>
<p>OK, so let's say we have Just 3 and Just [4]. How do we get Just [3,4]? Easy.</p>
<pre><code>ghci&gt; liftA2 (:) (Just 3) (Just [4])  
Just [3,4]  
ghci&gt; (:) &lt;$&gt; Just 3 &lt;*&gt; Just [4]  
Just [3,4]
</code></pre>
<p>Remember, : is a function that takes an element and a list and returns a new list with that element at the beginning. Now that we have Just [3,4], could we combine that with Just 2 to produce Just [2,3,4]? Of course we could. It seems that we can combine any amount of applicatives into one applicative that has a list of the results of those applicatives inside it. Let's try implementing a function that takes a list of applicatives and returns an applicative that has a list as its result value. We'll call it sequenceA.</p>
<pre><code>sequenceA :: (Applicative f) =&gt; [f a] -&gt; f [a]  
sequenceA [] = pure []  
sequenceA (x:xs) = (:) &lt;$&gt; x &lt;*&gt; sequenceA xs
</code></pre>
<p>Ah, recursion! First, we look at the type. It will transform a list of applicatives into an applicative with a list. From that, we can lay some groundwork for an edge condition. If we want to turn an empty list into an applicative with a list of results, well, we just put an empty list in a default context. Now comes the recursion. If we have a list with a head and a tail (remember, x is an applicative and xs is a list of them), we call sequenceA on the tail, which results in an applicative with a list. Then, we just prepend the value inside the applicative x into that applicative with a list, and that's it!</p>
<p>So if we do sequenceA [Just 1, Just 2], that's (:) &lt;$&gt; Just 1 &lt;<em>&gt; sequenceA [Just 2] . That equals (:) &lt;$&gt; Just 1 &lt;</em>&gt; ((:) &lt;$&gt; Just 2 &lt;<em>&gt; sequenceA []). Ah! We know that sequenceA [] ends up as being Just [], so this expression is now (:) &lt;$&gt; Just 1 &lt;</em>&gt; ((:) &lt;$&gt; Just 2 &lt;<em>&gt; Just []), which is (:) &lt;$&gt; Just 1 &lt;</em>&gt; Just [2], which is Just [1,2]!</p>
<p>Another way to implement sequenceA is with a fold. Remember, pretty much any function where we go over a list element by element and accumulate a result along the way can be implemented with a fold.</p>
<pre><code>sequenceA :: (Applicative f) =&gt; [f a] -&gt; f [a]  
sequenceA = foldr (liftA2 (:)) (pure [])
</code></pre>
<p>We approach the list from the right and start off with an accumulator value of pure []. We do liftA2 (:) between the accumulator and the last element of the list, which results in an applicative that has a singleton in it. Then we do liftA2 (:) with the now last element and the current accumulator and so on, until we're left with just the accumulator, which holds a list of the results of all the applicatives.</p>
<p>Let's give our function a whirl on some applicatives.</p>
<pre><code>ghci&gt; sequenceA [Just 3, Just 2, Just 1]  
Just [3,2,1]  
ghci&gt; sequenceA [Just 3, Nothing, Just 1]  
Nothing  
ghci&gt; sequenceA [(+3),(+2),(+1)] 3  
[6,5,4]  
ghci&gt; sequenceA [[1,2,3],[4,5,6]]  
[[1,4],[1,5],[1,6],[2,4],[2,5],[2,6],[3,4],[3,5],[3,6]]  
ghci&gt; sequenceA [[1,2,3],[4,5,6],[3,4,4],[]]  
[]
</code></pre>
<p>Ah! Pretty cool. When used on Maybe values, sequenceA creates a Maybe value with all the results inside it as a list. If one of the values was Nothing, then the result is also a Nothing. This is cool when you have a list of Maybe values and you're interested in the values only if none of them is a Nothing.</p>
<p>When used with functions, sequenceA takes a list of functions and returns a function that returns a list. In our example, we made a function that took a number as a parameter and applied it to each function in the list and then returned a list of results. sequenceA [(+3),(+2),(+1)] 3 will call (+3) with 3, (+2) with 3 and (+1) with 3 and present all those results as a list.</p>
<p>Doing (+) &lt;$&gt; (+3) &lt;<em>&gt; (</em>2) will create a function that takes a parameter, feeds it to both (+3) and (<em>2) and then calls + with those two results. In the same vein, it makes sense that sequenceA [(+3),(</em>2)] makes a function that takes a parameter and feeds it to all of the functions in the list. Instead of calling + with the results of the functions, a combination of : and pure [] is used to gather those results in a list, which is the result of that function.</p>
<p>Using sequenceA is cool when we have a list of functions and we want to feed the same input to all of them and then view the list of results. For instance, we have a number and we're wondering whether it satisfies all of the predicates in a list. One way to do that would be like so:</p>
<pre><code>ghci&gt; map (\f -&gt; f 7) [(&gt;4),(&lt;10),odd]  
[True,True,True]  
ghci&gt; and $ map (\f -&gt; f 7) [(&gt;4),(&lt;10),odd]  
True
</code></pre>
<p>Remember, and takes a list of booleans and returns True if they're all True. Another way to achieve the same thing would be with sequenceA:</p>
<pre><code>ghci&gt; sequenceA [(&gt;4),(&lt;10),odd] 7  
[True,True,True]  
ghci&gt; and $ sequenceA [(&gt;4),(&lt;10),odd] 7  
True
</code></pre>
<p>sequenceA [(&gt;4),(&lt;10),odd] creates a function that will take a number and feed it to all of the predicates in [(&gt;4),(&lt;10),odd] and return a list of booleans. It turns a list with the type (Num a) =&gt; [a -&gt; Bool] into a function with the type (Num a) =&gt; a -&gt; [Bool]. Pretty neat, huh?</p>
<p>Because lists are homogenous, all the functions in the list have to be functions of the same type, of course. You can't have a list like [ord, (+3)], because ord takes a character and returns a number, whereas (+3) takes a number and returns a number.</p>
<p>When used with [], sequenceA takes a list of lists and returns a list of lists. Hmm, interesting. It actually creates lists that have all possible combinations of their elements. For illustration, here's the above done with sequenceA and then done with a list comprehension:</p>
<pre><code>ghci&gt; sequenceA [[1,2,3],[4,5,6]]  
[[1,4],[1,5],[1,6],[2,4],[2,5],[2,6],[3,4],[3,5],[3,6]]  
ghci&gt; [[x,y] | x &lt;- [1,2,3], y &lt;- [4,5,6]]  
[[1,4],[1,5],[1,6],[2,4],[2,5],[2,6],[3,4],[3,5],[3,6]]  
ghci&gt; sequenceA [[1,2],[3,4]]  
[[1,3],[1,4],[2,3],[2,4]]  
ghci&gt; [[x,y] | x &lt;- [1,2], y &lt;- [3,4]]  
[[1,3],[1,4],[2,3],[2,4]]  
ghci&gt; sequenceA [[1,2],[3,4],[5,6]]  
[[1,3,5],[1,3,6],[1,4,5],[1,4,6],[2,3,5],[2,3,6],[2,4,5],[2,4,6]]  
ghci&gt; [[x,y,z] | x &lt;- [1,2], y &lt;- [3,4], z &lt;- [5,6]]  
[[1,3,5],[1,3,6],[1,4,5],[1,4,6],[2,3,5],[2,3,6],[2,4,5],[2,4,6]]
</code></pre>
<p>This might be a bit hard to grasp, but if you play with it for a while, you'll see how it works. Let's say that we're doing sequenceA [[1,2],[3,4]]. To see how this happens, let's use the sequenceA (x:xs) = (:) &lt;$&gt; x &lt;*&gt; sequenceA xs definition of sequenceA and the edge condition sequenceA [] = pure []. You don't have to follow this evaluation, but it might help you if have trouble imagining how sequenceA works on lists of lists, because it can be a bit mind-bending.</p>
<pre><code>We start off with sequenceA [[1,2],[3,4]]
That evaluates to (:) &lt;$&gt; [1,2] &lt;*&gt; sequenceA [[3,4]]
Evaluating the inner sequenceA further, we get (:) &lt;$&gt; [1,2] &lt;*&gt; ((:) &lt;$&gt; [3,4] &lt;*&gt; sequenceA [])
We've reached the edge condition, so this is now (:) &lt;$&gt; [1,2] &lt;*&gt; ((:) &lt;$&gt; [3,4] &lt;*&gt; [[]])
Now, we evaluate the (:) &lt;$&gt; [3,4] &lt;*&gt; [[]] part, which will use : with every possible value in the left list (possible values are 3 and 4) with every possible value on the right list (only possible value is []), which results in [3:[], 4:[]], which is [[3],[4]]. So now we have (:) &lt;$&gt; [1,2] &lt;*&gt; [[3],[4]]
Now, : is used with every possible value from the left list (1 and 2) with every possible value in the right list ([3] and [4]), which results in [1:[3], 1:[4], 2:[3], 2:[4]], which is [[1,3],[1,4],[2,3],[2,4]
</code></pre>
<p>Doing (+) &lt;$&gt; [1,2] &lt;*&gt; [4,5,6]results in a non-deterministic computation x + y where x takes on every value from [1,2] and y takes on every value from [4,5,6]. We represent that as a list which holds all of the possible results. Similarly, when we do sequence [[1,2],[3,4],[5,6],[7,8]], the result is a non-deterministic computation [x,y,z,w], where x takes on every value from [1,2], y takes on every value from [3,4] and so on. To represent the result of that non-deterministic computation, we use a list, where each element in the list is one possible list. That's why the result is a list of lists.</p>
<p>When used with I/O actions, sequenceA is the same thing as sequence! It takes a list of I/O actions and returns an I/O action that will perform each of those actions and have as its result a list of the results of those I/O actions. That's because to turn an [IO a] value into an IO [a] value, to make an I/O action that yields a list of results when performed, all those I/O actions have to be sequenced so that they're then performed one after the other when evaluation is forced. You can't get the result of an I/O action without performing it.</p>
<pre><code>ghci&gt; sequenceA [getLine, getLine, getLine]  
heyh  
ho  
woo  
["heyh","ho","woo"]
</code></pre>
<p>Like normal functors, applicative functors come with a few laws. The most important one is the one that we already mentioned, namely that pure f &lt;*&gt; x = fmap f x holds. As an exercise, you can prove this law for some of the applicative functors that we've met in this chapter.The other functor laws are:</p>
<pre><code>pure id &lt;*&gt; v = v
pure (.) &lt;*&gt; u &lt;*&gt; v &lt;*&gt; w = u &lt;*&gt; (v &lt;*&gt; w)
pure f &lt;*&gt; pure x = pure (f x)
u &lt;*&gt; pure y = pure ($ y) &lt;*&gt; u
</code></pre>
<p>We won't go over them in detail right now because that would take up a lot of pages and it would probably be kind of boring, but if you're up to the task, you can take a closer look at them and see if they hold for some of the instances.</p>
<p>In conclusion, applicative functors aren't just interesting, they're also useful, because they allow us to combine different computations, such as I/O computations, non-deterministic computations, computations that might have failed, etc. by using the applicative style. Just by using &lt;$&gt; and &lt;*&gt; we can use normal functions to uniformly operate on any number of applicative functors and take advantage of the semantics of each one.
The newtype keyword
why_ so serious?</p>
<p>So far, we've learned how to make our own algebraic data types by using the data keyword. We've also learned how to give existing types synonyms with the type keyword. In this section, we'll be taking a look at how to make new types out of existing data types by using the newtype keyword and why we'd want to do that in the first place.</p>
<p>In the previous section, we saw that there are actually more ways for the list type to be an applicative functor. One way is to have &lt;*&gt; take every function out of the list that is its left parameter and apply it to every value in the list that is on the right, resulting in every possible combination of applying a function from the left list to a value in the right list.</p>
<pre><code>ghci&gt; [(+1),(*100),(*5)] &lt;*&gt; [1,2,3]  
[2,3,4,100,200,300,5,10,15]
</code></pre>
<p>The second way is to take the first function on the left side of &lt;*&gt; and apply it to the first value on the right, then take the second function from the list on the left side and apply it to the second value on the right, and so on. Ultimately, it's kind of like zipping the two lists together. But lists are already an instance of Applicative, so how did we also make lists an instance of Applicative in this second way? If you remember, we said that the ZipList a type was introduced for this reason, which has one value constructor, ZipList, that has just one field. We put the list that we're wrapping in that field. Then, ZipList was made an instance of Applicative, so that when we want to use lists as applicatives in the zipping manner, we just wrap them with the ZipList constructor and then once we're done, unwrap them with getZipList:</p>
<pre><code>ghci&gt; getZipList $ ZipList [(+1),(*100),(*5)] &lt;*&gt; ZipList [1,2,3]  
[2,200,15]
</code></pre>
<p>So, what does this have to do with this newtype keyword? Well, think about how we might write the data declaration for our ZipList a type. One way would be to do it like so:</p>
<pre><code>data ZipList a = ZipList [a]
</code></pre>
<p>A type that has just one value constructor and that value constructor has just one field that is a list of things. We might also want to use record syntax so that we automatically get a function that extracts a list from a ZipList:</p>
<pre><code>data ZipList a = ZipList { getZipList :: [a] }
</code></pre>
<p>This looks fine and would actually work pretty well. We had two ways of making an existing type an instance of a type class, so we used the data keyword to just wrap that type into another type and made the other type an instance in the second way.</p>
<p>The newtype keyword in Haskell is made exactly for these cases when we want to just take one type and wrap it in something to present it as another type. In the actual libraries, ZipList a is defined like this:</p>
<pre><code>newtype ZipList a = ZipList { getZipList :: [a] }
</code></pre>
<p>Instead of the data keyword, the newtype keyword is used. Now why is that? Well for one, newtype is faster. If you use the data keyword to wrap a type, there's some overhead to all that wrapping and unwrapping when your program is running. But if you use newtype, Haskell knows that you're just using it to wrap an existing type into a new type (hence the name), because you want it to be the same internally but have a different type. With that in mind, Haskell can get rid of the wrapping and unwrapping once it resolves which value is of what type.</p>
<p>So why not just use newtype all the time instead of data then? Well, when you make a new type from an existing type by using the newtype keyword, you can only have one value constructor and that value constructor can only have one field. But with data, you can make data types that have several value constructors and each constructor can have zero or more fields:</p>
<pre><code>data Profession = Fighter | Archer | Accountant

data Race = Human | Elf | Orc | Goblin

data PlayerCharacter = PlayerCharacter Race Profession
</code></pre>
<p>When using newtype, you're restricted to just one constructor with one field.</p>
<p>We can also use the deriving keyword with newtype just like we would with data. We can derive instances for Eq, Ord, Enum, Bounded, Show and Read. If we derive the instance for a type class, the type that we're wrapping has to be in that type class to begin with. It makes sense, because newtype just wraps an existing type. So now if we do the following, we can print and equate values of our new type:</p>
<pre><code>newtype CharList = CharList { getCharList :: [Char] } deriving (Eq, Show)
</code></pre>
<p>Let's give that a go:</p>
<pre><code>ghci&gt; CharList "this will be shown!"  
CharList {getCharList = "this will be shown!"}  
ghci&gt; CharList "benny" == CharList "benny"  
True  
ghci&gt; CharList "benny" == CharList "oisters"  
False
</code></pre>
<p>In this particular newtype, the value constructor has the following type:</p>
<pre><code>CharList :: [Char] -&gt; CharList
</code></pre>
<p>It takes a [Char] value, such as "my sharona" and returns a CharList value. From the above examples where we used the CharList value constructor, we see that really is the case. Conversely, the getCharList function, which was generated for us because we used record syntax in our newtype, has this type:</p>
<pre><code>getCharList :: CharList -&gt; [Char]
</code></pre>
<p>It takes a CharList value and converts it to a [Char] value. You can think of this as wrapping and unwrapping, but you can also think of it as converting values from one type to the other.
Using newtype to make type class instances</p>
<p>Many times, we want to make our types instances of certain type classes, but the type parameters just don't match up for what we want to do. It's easy to make Maybe an instance of Functor, because the Functor type class is defined like this:</p>
<pre><code>class Functor f where  
    fmap :: (a -&gt; b) -&gt; f a -&gt; f b
</code></pre>
<p>So we just start out with:</p>
<pre><code>instance Functor Maybe where
</code></pre>
<p>And then implement fmap. All the type parameters add up because the Maybe takes the place of f in the definition of the Functor type class and so if we look at fmap like it only worked on Maybe, it ends up behaving like:</p>
<pre><code>fmap :: (a -&gt; b) -&gt; Maybe a -&gt; Maybe b
</code></pre>
<p>wow, very evil</p>
<p>Isn't that just peachy? Now what if we wanted to make the tuple an instance of Functor in such a way that when we fmap a function over a tuple, it gets applied to the first component of the tuple? That way, doing fmap (+3) (1,1) would result in (4,1). It turns out that writing the instance for that is kind of hard. With Maybe, we just say instance Functor Maybe where because only type constructors that take exactly one parameter can be made an instance of Functor. But it seems like there's no way to do something like that with (a,b) so that the type parameter a ends up being the one that changes when we use fmap. To get around this, we can newtype our tuple in such a way that the second type parameter represents the type of the first component in the tuple:</p>
<pre><code>newtype Pair b a = Pair { getPair :: (a,b) }
</code></pre>
<p>And now, we can make it an instance of Functor so that the function is mapped over the first component:</p>
<pre><code>instance Functor (Pair c) where  
    fmap f (Pair (x,y)) = Pair (f x, y)
</code></pre>
<p>As you can see, we can pattern match on types defined with newtype. We pattern match to get the underlying tuple, then we apply the function f to the first component in the tuple and then we use the Pair value constructor to convert the tuple back to our Pair b a. If we imagine what the type fmap would be if it only worked on our new pairs, it would be:</p>
<pre><code>fmap :: (a -&gt; b) -&gt; Pair c a -&gt; Pair c b
</code></pre>
<p>Again, we said instance Functor (Pair c) where and so Pair c took the place of the f in the type class definition for Functor:</p>
<pre><code>class Functor f where  
    fmap :: (a -&gt; b) -&gt; f a -&gt; f b
</code></pre>
<p>So now, if we convert a tuple into a Pair b a, we can use fmap over it and the function will be mapped over the first component:</p>
<pre><code>ghci&gt; getPair $ fmap (*100) (Pair (2,3))  
(200,3)  
ghci&gt; getPair $ fmap reverse (Pair ("london calling", 3))  
("gnillac nodnol",3)
</code></pre>
<p>On newtype laziness</p>
<p>We mentioned that newtype is usually faster than data. The only thing that can be done with newtype is turning an existing type into a new type, so internally, Haskell can represent the values of types defined with newtype just like the original ones, only it has to keep in mind that the their types are now distinct. This fact means that not only is newtype faster, it's also lazier. Let's take a look at what this means.</p>
<p>Like we've said before, Haskell is lazy by default, which means that only when we try to actually print the results of our functions will any computation take place. Furthemore, only those computations that are necessary for our function to tell us the result will get carried out. The undefined value in Haskell represents an erronous computation. If we try to evaluate it (that is, force Haskell to actually compute it) by printing it to the terminal, Haskell will throw a hissy fit (technically referred to as an exception):</p>
<pre><code>ghci&gt; undefined  
*** Exception: Prelude.undefined
</code></pre>
<p>However, if we make a list that has some undefined values in it but request only the head of the list, which is not undefined, everything will go smoothly because Haskell doesn't really need to evaluate any other elements in a list if we only want to see what the first element is:</p>
<pre><code>ghci&gt; head [3,4,5,undefined,2,undefined]  
3
</code></pre>
<p>Now consider the following type:</p>
<pre><code>data CoolBool = CoolBool { getCoolBool :: Bool }
</code></pre>
<p>It's your run-of-the-mill algebraic data type that was defined with the data keyword. It has one value constructor, which has one field whose type is Bool. Let's make a function that pattern matches on a CoolBool and returns the value "hello" regardless of whether the Bool inside the CoolBool was True or False:</p>
<pre><code>helloMe :: CoolBool -&gt; String  
helloMe (CoolBool _) = "hello"
</code></pre>
<p>Instead of applying this function to a normal CoolBool, let's throw it a curveball and apply it to undefined!</p>
<pre><code>ghci&gt; helloMe undefined  
"*** Exception: Prelude.undefined
</code></pre>
<p>Yikes! An exception! Now why did this exception happen? Types defined with the data keyword can have multiple value constructors (even though CoolBool only has one). So in order to see if the value given to our function conforms to the (CoolBool _) pattern, Haskell has to evaluate the value just enough to see which value constructor was used when we made the value. And when we try to evaluate an undefined value, even a little, an exception is thrown.</p>
<p>Instead of using the data keyword for CoolBool, let's try using newtype:</p>
<pre><code>newtype CoolBool = CoolBool { getCoolBool :: Bool }
</code></pre>
<p>We don't have to change our helloMe function, because the pattern matching syntax is the same if you use newtype or data to define your type. Let's do the same thing here and apply helloMe to an undefined value:</p>
<pre><code>ghci&gt; helloMe undefined  
"hello"
</code></pre>
<p>top of the mornin to ya!!!</p>
<p>It worked! Hmmm, why is that? Well, like we've said, when we use newtype, Haskell can internally represent the values of the new type in the same way as the original values. It doesn't have to add another box around them, it just has to be aware of the values being of different types. And because Haskell knows that types made with the newtype keyword can only have one constructor, it doesn't have to evaluate the value passed to the function to make sure that it conforms to the (CoolBool _) pattern because newtype types can only have one possible value constructor and one field!</p>
<p>This difference in behavior may seem trivial, but it's actually pretty important because it helps us realize that even though types defined with data and newtype behave similarly from the programmer's point of view because they both have value constructors and fields, they are actually two different mechanisms. Whereas data can be used to make your own types from scratch, newtype is for making a completely new type out of an existing type. Pattern matching on newtype values isn't like taking something out of a box (like it is with data), it's more about making a direct conversion from one type to another.
type vs. newtype vs. data</p>
<p>At this point, you may be a bit confused about what exactly the difference between type, data and newtype is, so let's refresh our memory a bit.</p>
<p>The type keyword is for making type synonyms. What that means is that we just give another name to an already existing type so that the type is easier to refer to. Say we did the following:</p>
<pre><code>type IntList = [Int]
</code></pre>
<p>All this does is to allow us to refer to the [Int] type as IntList. They can be used interchangeably. We don't get an IntList value constructor or anything like that. Because [Int] and IntList are only two ways to refer to the same type, it doesn't matter which name we use in our type annotations:</p>
<pre><code>ghci&gt; ([1,2,3] :: IntList) ++ ([1,2,3] :: [Int])  
[1,2,3,1,2,3]
</code></pre>
<p>We use type synonyms when we want to make our type signatures more descriptive by giving types names that tell us something about their purpose in the context of the functions where they're being used. For instance, when we used an association list of type [(String,String)] to represent a phone book, we gave it the type synonym of PhoneBook so that the type signatures of our functions were easier to read.</p>
<p>The newtype keyword is for taking existing types and wrapping them in new types, mostly so that it's easier to make them instances of certain type classes. When we use newtype to wrap an existing type, the type that we get is separate from the original type. If we make the following newtype:</p>
<pre><code>newtype CharList = CharList { getCharList :: [Char] }
</code></pre>
<p>We can't use ++ to put together a CharList and a list of type [Char]. We can't even use ++ to put together two CharLists, because ++ works only on lists and the CharList type isn't a list, even though it could be said that it contains one. We can, however, convert two CharLists to lists, ++ them and then convert that back to a CharList.</p>
<p>When we use record syntax in our newtype declarations, we get functions for converting between the new type and the original type: namely the value constructor of our newtype and the function for extracting the value in its field. The new type also isn't automatically made an instance of the type classes that the original type belongs to, so we have to derive or manually write them.</p>
<p>In practice, you can think of newtype declarations as data declarations that can only have one constructor and one field. If you catch yourself writing such a data declaration, consider using newtype.</p>
<p>The data keyword is for making your own data types and with them, you can go hog wild. They can have as many constructors and fields as you wish and can be used to implement any algebraic data type by yourself. Everything from lists and Maybe-like types to trees.</p>
<p>If you just want your type signatures to look cleaner and be more descriptive, you probably want type synonyms. If you want to take an existing type and wrap it in a new type in order to make it an instance of a type class, chances are you're looking for a newtype. And if you want to make something completely new, odds are good that you're looking for the data keyword.
Monoids
wow this is pretty much the gayest pirate ship ever</p>
<p>Type classes in Haskell are used to present an interface for types that have some behavior in common. We started out with simple type classes like Eq, which is for types whose values can be equated, and Ord, which is for things that can be put in an order and then moved on to more interesting ones, like Functor and Applicative.</p>
<p>When we make a type, we think about which behaviors it supports, i.e. what it can act like and then based on that we decide which type classes to make it an instance of. If it makes sense for values of our type to be equated, we make it an instance of the Eq type class. If we see that our type is some kind of functor, we make it an instance of Functor, and so on.</p>
<p>Now consider the following: * is a function that takes two numbers and multiplies them. If we multiply some number with a 1, the result is always equal to that number. It doesn't matter if we do 1 * x or x * 1, the result is always x. Similarly, ++ is also a function which takes two things and returns a third. Only instead of multiplying numbers, it takes two lists and concatenates them. And much like *, it also has a certain value which doesn't change the other one when used with ++. That value is the empty list: [].</p>
<pre><code>ghci&gt; 4 * 1  
4  
ghci&gt; 1 * 9  
9  
ghci&gt; [1,2,3] ++ []  
[1,2,3]  
ghci&gt; [] ++ [0.5, 2.5]  
[0.5,2.5]
</code></pre>
<p>It seems that both * together with 1 and ++ along with [] share some common properties:</p>
<pre><code>The function takes two parameters.
The parameters and the returned value have the same type.
There exists such a value that doesn't change other values when used with the binary function.
</code></pre>
<p>There's another thing that these two operations have in common that may not be as obvious as our previous observations: when we have three or more values and we want to use the binary function to reduce them to a single result, the order in which we apply the binary function to the values doesn't matter. It doesn't matter if we do (3 * 4) * 5 or 3 * (4 * 5). Either way, the result is 60. The same goes for ++:</p>
<pre><code>ghci&gt; (3 * 2) * (8 * 5)  
240  
ghci&gt; 3 * (2 * (8 * 5))  
240  
ghci&gt; "la" ++ ("di" ++ "da")  
"ladida"  
ghci&gt; ("la" ++ "di") ++ "da"  
"ladida"
</code></pre>
<p>We call this property associativity. * is associative, and so is ++, but -, for example, is not. The expressions (5 - 3) - 4 and 5 - (3 - 4) result in different numbers.</p>
<p>By noticing and writing down these properties, we have chanced upon monoids! A monoid is when you have an associative binary function and a value which acts as an identity with respect to that function. When something acts as an identity with respect to a function, it means that when called with that function and some other value, the result is always equal to that other value. 1 is the identity with respect to * and [] is the identity with respect to ++. There are a lot of other monoids to be found in the world of Haskell, which is why the Monoid type class exists. It's for types which can act like monoids. Let's see how the type class is defined:</p>
<pre><code>class Monoid m where  
    mempty :: m  
    mappend :: m -&gt; m -&gt; m  
    mconcat :: [m] -&gt; m  
    mconcat = foldr mappend mempty
</code></pre>
<p>woof dee do!!!</p>
<p>The Monoid type class is defined in import Data.Monoid. Let's take some time and get properly acquainted with it.</p>
<p>First of all, we see that only concrete types can be made instances of Monoid, because the m in the type class definition doesn't take any type parameters. This is different from Functor and Applicative, which require their instances to be type constructors which take one parameter.</p>
<p>The first function is mempty. It's not really a function, since it doesn't take parameters, so it's a polymorphic constant, kind of like minBound from Bounded. mempty represents the identity value for a particular monoid.</p>
<p>Next up, we have mappend, which, as you've probably guessed, is the binary function. It takes two values of the same type and returns a value of that type as well. It's worth noting that the decision to name mappend as it's named was kind of unfortunate, because it implies that we're appending two things in some way. While ++ does take two lists and append one to the other, * doesn't really do any appending, it just multiplies two numbers together. When we meet other instances of Monoid, we'll see that most of them don't append values either, so avoid thinking in terms of appending and just think in terms of mappend being a binary function that takes two monoid values and returns a third.</p>
<p>The last function in this type class definition is mconcat. It takes a list of monoid values and reduces them to a single value by doing mappend between the list's elements. It has a default implementation, which just takes mempty as a starting value and folds the list from the right with mappend. Because the default implementation is fine for most instances, we won't concern ourselves with mconcat too much from now on. When making a type an instance of Monoid, it suffices to just implement mempty and mappend. The reason mconcat is there at all is because for some instances, there might be a more efficient way to implement mconcat, but for most instances the default implementation is just fine.</p>
<p>Before moving on to specific instances of Monoid, let's take a brief look at the monoid laws. We mentioned that there has to be a value that acts as the identity with respect to the binary function and that the binary function has to be associative. It's possible to make instances of Monoid that don't follow these rules, but such instances are of no use to anyone because when using the Monoid type class, we rely on its instances acting like monoids. Otherwise, what's the point? That's why when making instances, we have to make sure they follow these laws:</p>
<pre><code>mempty `mappend` x = x
x `mappend` mempty = x
(x `mappend` y) `mappend` z = x `mappend` (y `mappend` z)
</code></pre>
<p>The first two state that mempty has to act as the identity with respect to mappend and the third says that mappend has to be associative i.e. that it the order in which we use mappend to reduce several monoid values into one doesn't matter. Haskell doesn't enforce these laws, so we as the programmer have to be careful that our instances do indeed obey them.
Lists are monoids</p>
<p>Yes, lists are monoids! Like we've seen, the ++ function and the empty list [] form a monoid. The instance is very simple:</p>
<pre><code>instance Monoid [a] where  
    mempty = []  
    mappend = (++)
</code></pre>
<p>Lists are an instance of the Monoid type class regardless of the type of the elements they hold. Notice that we wrote instance Monoid [a] and not instance Monoid [], because Monoid requires a concrete type for an instance.</p>
<p>Giving this a test run, we encounter no surprises:</p>
<pre><code>ghci&gt; [1,2,3] `mappend` [4,5,6]  
[1,2,3,4,5,6]  
ghci&gt; ("one" `mappend` "two") `mappend` "tree"  
"onetwotree"  
ghci&gt; "one" `mappend` ("two" `mappend` "tree")  
"onetwotree"  
ghci&gt; "one" `mappend` "two" `mappend` "tree"  
"onetwotree"  
ghci&gt; "pang" `mappend` mempty  
"pang"  
ghci&gt; mconcat [[1,2],[3,6],[9]]  
[1,2,3,6,9]  
ghci&gt; mempty :: [a]  
[]
</code></pre>
<p>smug as hell</p>
<p>Notice that in the last line, we had to write an explicit type annotation, because if we just did mempty, GHCi wouldn't know which instance to use, so we had to say we want the list instance. We were able to use the general type of [a] (as opposed to specifying [Int] or [String]) because the empty list can act as if it contains any type.</p>
<p>Because mconcat has a default implementation, we get it for free when we make something an instance of Monoid. In the case of the list, mconcat turns out to be just concat. It takes a list of lists and flattens it, because that's the equivalent of doing ++ between all the adjecent lists in a list.</p>
<p>The monoid laws do indeed hold for the list instance. When we have several lists and we mappend (or ++) them together, it doesn't matter which ones we do first, because they're just joined at the ends anyway. Also, the empty list acts as the identity so all is well. Notice that monoids don't require that a <code>mappend</code> b be equal to b <code>mappend</code> a. In the case of the list, they clearly aren't:</p>
<pre><code>ghci&gt; "one" `mappend` "two"  
"onetwo"  
ghci&gt; "two" `mappend` "one"  
"twoone"
</code></pre>
<p>And that's okay. The fact that for multiplication 3 * 5 and 5 * 3 are the same is just a property of multiplication, but it doesn't hold for all (and indeed, most) monoids.
Product and Sum</p>
<p>We already examined one way for numbers to be considered monoids. Just have the binary function be * and the identity value 1. It turns out that that's not the only way for numbers to be monoids. Another way is to have the binary function be + and the identity value 0:</p>
<pre><code>ghci&gt; 0 + 4  
4  
ghci&gt; 5 + 0  
5  
ghci&gt; (1 + 3) + 5  
9  
ghci&gt; 1 + (3 + 5)  
9
</code></pre>
<p>The monoid laws hold, because if you add 0 to any number, the result is that number. And addition is also associative, so we get no problems there. So now that there are two equally valid ways for numbers to be monoids, which way do choose? Well, we don't have to. Remember, when there are several ways for some type to be an instance of the same type class, we can wrap that type in a newtype and then make the new type an instance of the type class in a different way. We can have our cake and eat it too.</p>
<p>The Data.Monoid module exports two types for this, namely Product and Sum. Product is defined like this:</p>
<pre><code>newtype Product a =  Product { getProduct :: a }  
    deriving (Eq, Ord, Read, Show, Bounded)
</code></pre>
<p>Simple, just a newtype wrapper with one type parameter along with some derived instances. Its instance for Monoid goes a little something like this:</p>
<pre><code>instance Num a =&gt; Monoid (Product a) where  
    mempty = Product 1  
    Product x `mappend` Product y = Product (x * y)
</code></pre>
<p>mempty is just 1 wrapped in a Product constructor. mappend pattern matches on the Product constructor, multiplies the two numbers and then wraps the resulting number back. As you can see, there's a Num a class constraint. So this means that Product a is an instance of Monoid for all a's that are already an instance of Num. To use Producta a as a monoid, we have to do some newtype wrapping and unwrapping:</p>
<pre><code>ghci&gt; getProduct $ Product 3 `mappend` Product 9  
27  
ghci&gt; getProduct $ Product 3 `mappend` mempty  
3  
ghci&gt; getProduct $ Product 3 `mappend` Product 4 `mappend` Product 2  
24  
ghci&gt; getProduct . mconcat . map Product $ [3,4,2]  
24
</code></pre>
<p>This is nice as a showcase of the Monoid type class, but no one in their right mind would use this way of multiplying numbers instead of just writing 3 * 9 and 3 * 1. But a bit later, we'll see how these Monoid instances that may seem trivial at this time can come in handy.</p>
<p>Sum is defined like Product and the instance is similar as well. We use it in the same way:</p>
<pre><code>ghci&gt; getSum $ Sum 2 `mappend` Sum 9  
11  
ghci&gt; getSum $ mempty `mappend` Sum 3  
3  
ghci&gt; getSum . mconcat . map Sum $ [1,2,3]  
6
</code></pre>
<p>Any and All</p>
<p>Another type which can act like a monoid in two distinct but equally valid ways is Bool. The first way is to have the or function || act as the binary function along with False as the identity value. The way or works in logic is that if any of its two parameters is True, it returns True, otherwise it returns False. So if we use False as the identity value, it will return False when or-ed with False and True when or-ed with True. The Any newtype constructor is an instance of Monoid in this fashion. It's defined like this:</p>
<pre><code>newtype Any = Any { getAny :: Bool }  
    deriving (Eq, Ord, Read, Show, Bounded)
</code></pre>
<p>Its instance looks goes like so:</p>
<pre><code>instance Monoid Any where  
        mempty = Any False  
        Any x `mappend` Any y = Any (x || y)
</code></pre>
<p>The reason it's called Any is because x <code>mappend</code> y will be True if any one of those two is True. Even if three or more Any wrapped Bools are mappended together, the result will hold True if any of them are True:</p>
<pre><code>ghci&gt; getAny $ Any True `mappend` Any False  
True  
ghci&gt; getAny $ mempty `mappend` Any True  
True  
ghci&gt; getAny . mconcat . map Any $ [False, False, False, True]  
True  
ghci&gt; getAny $ mempty `mappend` mempty  
False
</code></pre>
<p>The other way for Bool to be an instance of Monoid is to kind of do the opposite: have &amp;&amp; be the binary function and then make True the identity value. Logical and will return True only if both of its parameters are True. This is the newtype declaration, nothing fancy:</p>
<pre><code>newtype All = All { getAll :: Bool }  
        deriving (Eq, Ord, Read, Show, Bounded)
</code></pre>
<p>And this is the instance:</p>
<pre><code>instance Monoid All where  
        mempty = All True  
        All x `mappend` All y = All (x &amp;&amp; y)
</code></pre>
<p>When we mappend values of the All type, the result will be True only if all the values used in the mappend operations are True:</p>
<pre><code>ghci&gt; getAll $ mempty `mappend` All True  
True  
ghci&gt; getAll $ mempty `mappend` All False  
False  
ghci&gt; getAll . mconcat . map All $ [True, True, True]  
True  
ghci&gt; getAll . mconcat . map All $ [True, True, False]  
False
</code></pre>
<p>Just like with multiplication and addition, we usually explicitly state the binary functions instead of wrapping them in newtypes and then using mappend and mempty. mconcat seems useful for Any and All, but usually it's easier to use the or and and functions, which take lists of Bools and return True if any of them are True or if all of them are True, respectively.
The Ordering monoid</p>
<p>Hey, remember the Ordering type? It's used as the result when comparing things and it can have three values: LT, EQ and GT, which stand for less than, equal and greater than respectively:</p>
<pre><code>ghci&gt; 1 `compare` 2  
LT  
ghci&gt; 2 `compare` 2  
EQ  
ghci&gt; 3 `compare` 2  
GT
</code></pre>
<p>With lists, numbers and boolean values, finding monoids was just a matter of looking at already existing commonly used functions and seeing if they exhibit some sort of monoid behavior. With Ordering, we have to look a bit harder to recognize a monoid, but it turns out that its Monoid instance is just as intuitive as the ones we've met so far and also quite useful:</p>
<pre><code>instance Monoid Ordering where  
    mempty = EQ  
    LT `mappend` _ = LT  
    EQ `mappend` y = y  
    GT `mappend` _ = GT
</code></pre>
<p>did anyone ORDER pizza?!?! I can't BEAR these puns!</p>
<p>The instance is set up like this: when we mappend two Ordering values, the one on the left is kept, unless the value on the left is EQ, in which case the right one is the result. The identity is EQ. At first, this may seem kind of arbitrary, but it actually resembles the way we alphabetically compare words. We compare the first two letters and if they differ, we can already decide which word would go first in a dictionary. However, if the first two letters are equal, then we move on to comparing the next pair of letters and repeat the process.</p>
<p>For instance, if we were to alphabetically compare the words "ox" and "on", we'd first compare the first two letters of each word, see that they are equal and then move on to comparing the second letter of each word. We see that 'x' is alphabetically greater than 'n', and so we know how the words compare. To gain some intuition for EQ being the identity, we can notice that if we were to cram the same letter in the same position in both words, it wouldn't change their alphabetical ordering. "oix" is still alphabetically greater than and "oin".</p>
<p>It's important to note that in the Monoid instance for Ordering, x <code>mappend</code> y doesn't equal y <code>mappend</code> x. Because the first parameter is kept unless it's EQ, LT <code>mappend</code> GT will result in LT, whereas GT <code>mappend</code> LT will result in GT:</p>
<pre><code>ghci&gt; LT `mappend` GT  
LT  
ghci&gt; GT `mappend` LT  
GT  
ghci&gt; mempty `mappend` LT  
LT  
ghci&gt; mempty `mappend` GT  
GT
</code></pre>
<p>OK, so how is this monoid useful? Let's say you were writing a function that takes two strings, compares their lengths, and returns an Ordering. But if the strings are of the same length, then instead of returning EQ right away, we want to compare them alphabetically. One way to write this would be like so:</p>
<pre><code>lengthCompare :: String -&gt; String -&gt; Ordering  
lengthCompare x y = let a = length x `compare` length y   
                        b = x `compare` y  
                    in  if a == EQ then b else a
</code></pre>
<p>We name the result of comparing the lengths a and the result of the alphabetical comparison b and then if it turns out that the lengths were equal, we return their alphabetical ordering.</p>
<p>But by employing our understanding of how Ordering is a monoid, we can rewrite this function in a much simpler manner:</p>
<pre><code>import Data.Monoid

lengthCompare :: String -&gt; String -&gt; Ordering  
lengthCompare x y = (length x `compare` length y) `mappend`  
                    (x `compare` y)
</code></pre>
<p>We can try this out:</p>
<pre><code>ghci&gt; lengthCompare "zen" "ants"  
LT  
ghci&gt; lengthCompare "zen" "ant"  
GT
</code></pre>
<p>Remember, when we use mappend, its left parameter is always kept unless it's EQ, in which case the right one is kept. That's why we put the comparison that we consider to be the first, more important criterion as the first parameter. If we wanted to expand this function to also compare for the number of vowels and set this to be the second most important criterion for comparison, we'd just modify it like this:</p>
<pre><code>import Data.Monoid

lengthCompare :: String -&gt; String -&gt; Ordering  
lengthCompare x y = (length x `compare` length y) `mappend`  
                    (vowels x `compare` vowels y) `mappend`  
                    (x `compare` y)  
    where vowels = length . filter (`elem` "aeiou")
</code></pre>
<p>We made a helper function, which takes a string and tells us how many vowels it has by first filtering it only for letters that are in the string "aeiou" and then applying length to that.</p>
<pre><code>ghci&gt; lengthCompare "zen" "anna"  
LT  
ghci&gt; lengthCompare "zen" "ana"  
LT  
ghci&gt; lengthCompare "zen" "ann"  
GT
</code></pre>
<p>Very cool. Here, we see how in the first example the lengths are found to be different and so LT is returned, because the length of "zen" is less than the length of "anna". In the second example, the lengths are the same, but the second string has more vowels, so LT is returned again. In the third example, they both have the same length and the same number of vowels, so they're compared alphabetically and "zen" wins.</p>
<p>The Ordering monoid is very cool because it allows us to easily compare things by many different criteria and put those criteria in an order themselves, ranging from the most important to the least.
Maybe the monoid</p>
<p>Let's take a look at the various ways that Maybe a can be made an instance of Monoid and what those instances are useful for.</p>
<p>One way is to treat Maybe a as a monoid only if its type parameter a is a monoid as well and then implement mappend in such a way that it uses the mappend operation of the values that are wrapped with Just. We use Nothing as the identity, and so if one of the two values that we're mappending is Nothing, we keep the other value. Here's the instance declaration:</p>
<pre><code>instance Monoid a =&gt; Monoid (Maybe a) where  
    mempty = Nothing  
    Nothing `mappend` m = m  
    m `mappend` Nothing = m  
    Just m1 `mappend` Just m2 = Just (m1 `mappend` m2)
</code></pre>
<p>Notice the class constraint. It says that Maybe a is an instance of Monoid only if a is an instance of Monoid. If we mappend something with a Nothing, the result is that something. If we mappend two Just values, the contents of the Justs get mappended and then wrapped back in a Just. We can do this because the class constraint ensures that the type of what's inside the Just is an instance of Monoid.</p>
<pre><code>ghci&gt; Nothing `mappend` Just "andy"  
Just "andy"  
ghci&gt; Just LT `mappend` Nothing  
Just LT  
ghci&gt; Just (Sum 3) `mappend` Just (Sum 4)  
Just (Sum {getSum = 7})
</code></pre>
<p>This comes in use when you're dealing with monoids as results of computations that may have failed. Because of this instance, we don't have to check if the computations have failed by seeing if they're a Nothing or Just value; we can just continue to treat them as normal monoids.</p>
<p>But what if the type of the contents of the Maybe aren't an instance of Monoid? Notice that in the previous instance declaration, the only case where we have to rely on the contents being monoids is when both parameters of mappend are Just values. But if we don't know if the contents are monoids, we can't use mappend between them, so what are we to do? Well, one thing we can do is to just discard the second value and keep the first one. For this, the First a type exists and this is its definition:</p>
<pre><code>newtype First a = First { getFirst :: Maybe a }  
    deriving (Eq, Ord, Read, Show)
</code></pre>
<p>We take a Maybe a and we wrap it with a newtype. The Monoid instance is as follows:</p>
<pre><code>instance Monoid (First a) where  
    mempty = First Nothing  
    First (Just x) `mappend` _ = First (Just x)  
    First Nothing `mappend` x = x
</code></pre>
<p>Just like we said. mempty is just a Nothing wrapped with the First newtype constructor. If mappend's first parameter is a Just value, we ignore the second one. If the first one is a Nothing, then we present the second parameter as a result, regardless of whether it's a Just or a Nothing:</p>
<pre><code>ghci&gt; getFirst $ First (Just 'a') `mappend` First (Just 'b')  
Just 'a'  
ghci&gt; getFirst $ First Nothing `mappend` First (Just 'b')  
Just 'b'  
ghci&gt; getFirst $ First (Just 'a') `mappend` First Nothing  
Just 'a'
</code></pre>
<p>First is useful when we have a bunch of Maybe values and we just want to know if any of them is a Just. The mconcat function comes in handy:</p>
<pre><code>ghci&gt; getFirst . mconcat . map First $ [Nothing, Just 9, Just 10]  
Just 9
</code></pre>
<p>If we want a monoid on Maybe a such that the second parameter is kept if both parameters of mappend are Just values, Data.Monoid provides a the Last a type, which works like First a, only the last non-Nothing value is kept when mappending and using mconcat:</p>
<pre><code>ghci&gt; getLast . mconcat . map Last $ [Nothing, Just 9, Just 10]  
Just 10  
ghci&gt; getLast $ Last (Just "one") `mappend` Last (Just "two")  
Just "two"
</code></pre>
<p>Using monoids to fold data structures</p>
<p>One of the more interesting ways to put monoids to work is to make them help us define folds over various data structures. So far, we've only done folds over lists, but lists aren't the only data structure that can be folded over. We can define folds over almost any data structure. Trees especially lend themselves well to folding.</p>
<p>Because there are so many data structures that work nicely with folds, the Foldable type class was introduced. Much like Functor is for things that can be mapped over, Foldable is for things that can be folded up! It can be found in Data.Foldable and because it export functions whose names clash with the ones from the Prelude, it's best imported qualified (and served with basil):</p>
<pre><code>import qualified Foldable as F
</code></pre>
<p>To save ourselves precious keystrokes, we've chosen to import it qualified as F. Alright, so what are some of the functions that this type class defines? Well, among them are foldr, foldl, foldr1 and foldl1. Huh? But we already know these functions, what's so new about this? Let's compare the types of Foldable's foldr and the foldr from the Prelude to see how they differ:</p>
<pre><code>ghci&gt; :t foldr  
foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b  
ghci&gt; :t F.foldr  
F.foldr :: (F.Foldable t) =&gt; (a -&gt; b -&gt; b) -&gt; b -&gt; t a -&gt; b
</code></pre>
<p>Ah! So whereas foldr takes a list and folds it up, the foldr from Data.Foldable accepts any type that can be folded up, not just lists! As expected, both foldr functions do the same for lists:</p>
<pre><code>ghci&gt; foldr (*) 1 [1,2,3]  
6  
ghci&gt; F.foldr (*) 1 [1,2,3]  
6
</code></pre>
<p>Okay then, what are some other data structures that support folds? Well, there's the Maybe we all know and love!</p>
<pre><code>ghci&gt; F.foldl (+) 2 (Just 9)  
11  
ghci&gt; F.foldr (||) False (Just True)  
True
</code></pre>
<p>But folding over a Maybe value isn't terribly interesting, because when it comes to folding, it just acts like a list with one element if it's a Just value and as an empty list if it's Nothing. So let's examine a data structure that's a little more complex then.</p>
<p>Remember the tree data structure from the Making Our Own Types and Typeclasses chapter? We defined it like this:</p>
<pre><code>data Tree a = Empty | Node a (Tree a) (Tree a) deriving (Show, Read, Eq)
</code></pre>
<p>We said that a tree is either an empty tree that doesn't hold any values or it's a node that holds one value and also two other trees. After defining it, we made it an instance of Functor and with that we gained the ability to fmap functions over it. Now, we're going to make it an instance of Foldable so that we get the abilty to fold it up. One way to make a type constructor an instance of Foldable is to just directly implement foldr for it. But another, often much easier way, is to implement the foldMap function, which is also a part of the Foldable type class. The foldMap function has the following type:</p>
<pre><code>foldMap :: (Monoid m, Foldable t) =&gt; (a -&gt; m) -&gt; t a -&gt; m
</code></pre>
<p>Its first parameter is a function that takes a value of the type that our foldable structure contains (denoted here with a) and returns a monoid value. Its second parameter is a foldable structure that contains values of type a. It maps that function over the foldable structure, thus producing a foldable structure that contains monoid values. Then, by doing mappend between those monoid values, it joins them all into a single monoid value. This function may sound kind of odd at the moment, but we'll see that it's very easy to implement. What's also cool is that implementing this function is all it takes for our type to be made an instance of Foldable. So if we just implement foldMap for some type, we get foldr and foldl on that type for free!</p>
<p>This is how we make Tree an instance of Foldable:</p>
<pre><code>instance F.Foldable Tree where  
    foldMap f Empty = mempty  
    foldMap f (Node x l r) = F.foldMap f l `mappend`  
                             f x           `mappend`  
                             F.foldMap f r
</code></pre>
<p>find the visual pun or whatever</p>
<p>We think like this: if we are provided with a function that takes an element of our tree and returns a monoid value, how do we reduce our whole tree down to one single monoid value? When we were doing fmap over our tree, we applied the function that we were mapping to a node and then we recursively mapped the function over the left sub-tree as well as the right one. Here, we're tasked with not only mapping a function, but with also joining up the results into a single monoid value by using mappend. First we consider the case of the empty tree — a sad and lonely tree that has no values or sub-trees. It doesn't hold any value that we can give to our monoid-making function, so we just say that if our tree is empty, the monoid value it becomes is mempty.</p>
<p>The case of a non-empty node is a bit more interesting. It contains two sub-trees as well as a value. In this case, we recursively foldMap the same function f over the left and the right sub-trees. Remember, our foldMap results in a single monoid value. We also apply our function f to the value in the node. Now we have three monoid values (two from our sub-trees and one from applying f to the value in the node) and we just have to bang them together into a single value. For this purpose we use mappend, and naturally the left sub-tree comes first, then the node value and then the right sub-tree.</p>
<p>Notice that we didn't have to provide the function that takes a value and returns a monoid value. We receive that function as a parameter to foldMap and all we have to decide is where to apply that function and how to join up the resulting monoids from it.</p>
<p>Now that we have a Foldable instance for our tree type, we get foldr and foldl for free! Consider this tree:</p>
<pre><code>testTree = Node 5  
            (Node 3  
                (Node 1 Empty Empty)  
                (Node 6 Empty Empty)  
            )  
            (Node 9  
                (Node 8 Empty Empty)  
                (Node 10 Empty Empty)  
            )
</code></pre>
<p>It has 5 at its root and then its left node is has 3 with 1 on the left and 6 on the right. The root's right node has a 9 and then an 8 to its left and a 10 on the far right side. With a Foldable instance, we can do all of the folds that we can do on lists:</p>
<pre><code>ghci&gt; F.foldl (+) 0 testTree  
42  
ghci&gt; F.foldl (*) 1 testTree  
64800
</code></pre>
<p>And also, foldMap isn't only useful for making new instances of Foldable; it comes in handy for reducing our structure to a single monoid value. For instance, if we want to know if any number in our tree is equal to 3, we can do this:</p>
<pre><code>ghci&gt; getAny $ F.foldMap (\x -&gt; Any $ x == 3) testTree  
True
</code></pre>
<p>Here, \x -&gt; Any $ x == 3 is a function that takes a number and returns a monoid value, namely a Bool wrapped in Any. foldMap applies this function to every element in our tree and then reduces the resulting monoids into a single monoid with mappend. If we do this:</p>
<pre><code>ghci&gt; getAny $ F.foldMap (\x -&gt; Any $ x &gt; 15) testTree  
False
</code></pre>
<p>All of the nodes in our tree would hold the value Any False after having the function in the lambda applied to them. But to end up True, mappend for Any has to have at least one True value as a parameter. That's why the final result is False, which makes sense because no value in our tree is greater than 15.</p>
<p>We can also easily turn our tree into a list by doing a foldMap with the \x -&gt; [x] function. By first projecting that function onto our tree, each element becomes a singleton list. The mappend action that takes place between all those singleton list results in a single list that holds all of the elements that are in our tree:</p>
<pre><code>ghci&gt; F.foldMap (\x -&gt; [x]) testTree  
[1,3,6,5,8,9,10]
</code></pre>
<p>What's cool is that all of these trick aren't limited to trees, they work on any instance of Foldable.</p>
<pre><code>Functionally Solving Problems Table of contents A Fistful of Monads
</code></pre></article>
 
</slide>

<slide  >
  
    <hgroup>
      <h2>Monads</h2>
      <h3></h3>
    </hgroup>
    <article >
      <p>When we first talked about functors, we saw that they were a useful concept for values that can be mapped over. Then, we took that concept one step further by introducing applicative functors, which allow us to view values of certain data types as values with contexts and use normal functions on those values while preserving the meaning of those contexts.</p>
<p>In this chapter, we'll learn about monads, which are just beefed up applicative functors, much like applicative functors are only beefed up functors.
more cool than u</p>
<p>When we started off with functors, we saw that it's possible to map functions over various data types. We saw that for this purpose, the Functor type class was introduced and it had us asking the question: when we have a function of type a -&gt; b and some data type f a, how do we map that function over the data type to end up with f b? We saw how to map something over a Maybe a, a list [a], an IO a etc. We even saw how to map a function a -&gt; b over other functions of type r -&gt; a to get functions of type r -&gt; b. To answer this question of how to map a function over some data type, all we had to do was look at the type of fmap:</p>
<pre><code>fmap :: (Functor f) =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</code></pre>
<p>And then make it work for our data type by writing the appropriate Functor instance.</p>
<p>Then we saw a possible improvement of functors and said, hey, what if that function a -&gt; b is already wrapped inside a functor value? Like, what if we have Just (<em>3), how do we apply that to Just 5? What if we don't want to apply it to Just 5 but to a Nothing instead? Or if we have [(</em>2),(+4)], how would we apply that to [1,2,3]? How would that work even? For this, the Applicative type class was introduced, in which we wanted the answer to the following type:</p>
<pre><code>(&lt;*&gt;) :: (Applicative f) =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</code></pre>
<p>We also saw that we can take a normal value and wrap it inside a data type. For instance, we can take a 1 and wrap it so that it becomes a Just 1. Or we can make it into a [1]. Or an I/O action that does nothing and just yields 1. The function that does this is called pure.</p>
<p>Like we said, an applicative value can be seen as a value with an added context. A fancy value, to put it in technical terms. For instance, the character 'a' is just a normal character, whereas Just 'a' has some added context. Instead of a Char, we have a Maybe Char, which tells us that its value might be a character, but it could also be an absence of a character.</p>
<p>It was neat to see how the Applicative type class allowed us to use normal functions on these values with context and how that context was preserved. Observe:</p>
<pre><code>ghci&gt; (*) &lt;$&gt; Just 2 &lt;*&gt; Just 8  
Just 16  
ghci&gt; (++) &lt;$&gt; Just "klingon" &lt;*&gt; Nothing  
Nothing  
ghci&gt; (-) &lt;$&gt; [3,4] &lt;*&gt; [1,2,3]  
[2,1,0,3,2,1]
</code></pre>
<p>Ah, cool, so now that we treat them as applicative values, Maybe a values represent computations that might have failed, [a] values represent computations that have several results (non-deterministic computations), IO a values represent values that have side-effects, etc.</p>
<p>Monads are a natural extension of applicative functors and with them we're concerned with this: if you have a value with a context, m a, how do you apply to it a function that takes a normal a and returns a value with a context? That is, how do you apply a function of type a -&gt; m b to a value of type m a? So essentially, we will want this function:</p>
<pre><code>(&gt;&gt;=) :: (Monad m) =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</code></pre>
<p>If we have a fancy value and a function that takes a normal value but returns a fancy value, how do we feed that fancy value into the function? This is the main question that we will concern ourselves when dealing with monads. We write m a instead of f a because the m stands for Monad, but monads are just applicative functors that support &gt;&gt;=. The &gt;&gt;= function is pronounced as bind.</p>
<p>When we have a normal value a and a normal function a -&gt; b it's really easy to feed the value to the function — you just apply the function to the value normally and that's it. But when we're dealing with values that come with certain contexts, it takes a bit of thinking to see how these fancy values are fed to functions and how to take into account their behavior, but you'll see that it's easy as one two three.
Getting our feet wet with Maybe
monads, grasshoppa</p>
<p>Now that we have a vague idea of what monads are about, let's see if we can make that idea a bit less vague.</p>
<p>Much to no one's surprise, Maybe is a monad, so let's explore it a bit more and see if we can combine it with what we know about monads.
Make sure you understand applicatives at this point. It's good if you have a feel for how the various Applicative instances work and what kind of computations they represent, because monads are nothing more than taking our existing applicative knowledge and upgrading it.</p>
<p>A value of type Maybe a represents a value of type a with the context of possible failure attached. A value of Just "dharma" means that the string "dharma" is there whereas a value of Nothing represents its absence, or if you look at the string as the result of a computation, it means that the computation has failed.</p>
<p>When we looked at Maybe as a functor, we saw that if we want to fmap a function over it, it gets mapped over the insides if it's a Just value, otherwise the Nothing is kept because there's nothing to map it over!</p>
<p>Like this:</p>
<pre><code>ghci&gt; fmap (++"!") (Just "wisdom")  
Just "wisdom!"  
ghci&gt; fmap (++"!") Nothing  
Nothing
</code></pre>
<p>As an applicative functor, it functions similarly. However, applicatives also have the function wrapped. Maybe is an applicative functor in such a way that when we use &lt;*&gt; to apply a function inside a Maybe to a value that's inside a Maybe, they both have to be Just values for the result to be a Just value, otherwise the result is Nothing. It makes sense because if you're missing either the function or the thing you're applying it to, you can't make something up out of thin air, so you have to propagate the failure:</p>
<pre><code>ghci&gt; Just (+3) &lt;*&gt; Just 3  
Just 6  
ghci&gt; Nothing &lt;*&gt; Just "greed"  
Nothing  
ghci&gt; Just ord &lt;*&gt; Nothing  
Nothing
</code></pre>
<p>When we use the applicative style to have normal functions act on Maybe values, it's similar. All the values have to be Just values, otherwise it's all for Nothing!</p>
<pre><code>ghci&gt; max &lt;$&gt; Just 3 &lt;*&gt; Just 6  
Just 6  
ghci&gt; max &lt;$&gt; Just 3 &lt;*&gt; Nothing  
Nothing
</code></pre>
<p>And now, let's think about how we would do &gt;&gt;= for Maybe. Like we said, &gt;&gt;= takes a monadic value, and a function that takes a normal value and returns a monadic value and manages to apply that function to the monadic value. How does it do that, if the function takes a normal value? Well, to do that, it has to take into account the context of that monadic value.</p>
<p>In this case, &gt;&gt;= would take a Maybe a value and a function of type a -&gt; Maybe b and somehow apply the function to the Maybe a. To figure out how it does that, we can use the intuition that we have from Maybe being an applicative functor. Let's say that we have a function \x -&gt; Just (x+1). It takes a number, adds 1 to it and wraps it in a Just:</p>
<pre><code>ghci&gt; (\x -&gt; Just (x+1)) 1  
Just 2  
ghci&gt; (\x -&gt; Just (x+1)) 100  
Just 101
</code></pre>
<p>If we feed it 1, it evaluates to Just 2. If we give it the number 100, the result is Just 101. Very straightforward. Now here's the kicker: how do we feed a Maybe value to this function? If we think about how Maybe acts as an applicative functor, answering this is pretty easy. If we feed it a Just value, take what's inside the Just and apply the function to it. If give it a Nothing, hmm, well, then we're left with a function but Nothing to apply it to. In that case, let's just do what we did before and say that the result is Nothing.</p>
<p>Instead of calling it &gt;&gt;=, let's call it applyMaybe for now. It takes a Maybe a and a function that returns a Maybe b and manages to apply that function to the Maybe a. Here it is in code:</p>
<pre><code>applyMaybe :: Maybe a -&gt; (a -&gt; Maybe b) -&gt; Maybe b  
applyMaybe Nothing f  = Nothing  
applyMaybe (Just x) f = f x
</code></pre>
<p>Okay, now let's play with it for a bit. We'll use it as an infix function so that the Maybe value is on the left side and the function on the right:</p>
<pre><code>ghci&gt; Just 3 `applyMaybe` \x -&gt; Just (x+1)  
Just 4  
ghci&gt; Just "smile" `applyMaybe` \x -&gt; Just (x ++ " :)")  
Just "smile :)"  
ghci&gt; Nothing `applyMaybe` \x -&gt; Just (x+1)  
Nothing  
ghci&gt; Nothing `applyMaybe` \x -&gt; Just (x ++ " :)")  
Nothing
</code></pre>
<p>In the above example, we see that when we used applyMaybe with a Just value and a function, the function simply got applied to the value inside the Just. When we tried to use it with a Nothing, the whole result was Nothing. What about if the function returns a Nothing? Let's see:</p>
<pre><code>ghci&gt; Just 3 `applyMaybe` \x -&gt; if x &gt; 2 then Just x else Nothing  
Just 3  
ghci&gt; Just 1 `applyMaybe` \x -&gt; if x &gt; 2 then Just x else Nothing  
Nothing
</code></pre>
<p>Just what we expected. If the monadic value on the left is a Nothing, the whole thing is Nothing. And if the function on the right returns a Nothing, the result is Nothing again. This is very similar to when we used Maybe as an applicative and we got a Nothing result if somewhere in there was a Nothing.</p>
<p>It looks like that for Maybe, we've figured out how to take a fancy value and feed it to a function that takes a normal value and returns a fancy one. We did this by keeping in mind that a Maybe value represents a computation that might have failed.</p>
<p>You might be asking yourself, how is this useful? It may seem like applicative functors are stronger than monads, since applicative functors allow us to take a normal function and make it operate on values with contexts. We'll see that monads can do that as well because they're an upgrade of applicative functors, and that they can also do some cool stuff that applicative functors can't.</p>
<p>We'll come back to Maybe in a minute, but first, let's check out the type class that belongs to monads.
The Monad type class</p>
<p>Just like functors have the Functor type class and applicative functors have the Applicative type class, monads come with their own type class: Monad! Wow, who would have thought? This is what the type class looks like:</p>
<pre><code>class Monad m where  
    return :: a -&gt; m a

    (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b

    (&gt;&gt;) :: m a -&gt; m b -&gt; m b  
    x &gt;&gt; y = x &gt;&gt;= \_ -&gt; y

    fail :: String -&gt; m a  
    fail msg = error msg
</code></pre>
<p>this is you on monads</p>
<p>Let's start with the first line. It says class Monad m where. But wait, didn't we say that monads are just beefed up applicative functors? Shouldn't there be a class constraint in there along the lines of class (Applicative m) = &gt; Monad m where so that a type has to be an applicative functor first before it can be made a monad? Well, there should, but when Haskell was made, it hadn't occured to people that applicative functors are a good fit for Haskell so they weren't in there. But rest assured, every monad is an applicative functor, even if the Monad class declaration doesn't say so.</p>
<p>The first function that the Monad type class defines is return. It's the same as pure, only with a different name. Its type is (Monad m) =&gt; a -&gt; m a. It takes a value and puts it in a minimal default context that still holds that value. In other words, it takes something and wraps it in a monad. It always does the same thing as the pure function from the Applicative type class, which means we're already acquainted with return. We already used return when doing I/O. We used it to take a value and make a bogus I/O action that does nothing but yield that value. For Maybe it takes a value and wraps it in a Just.
Just a reminder: return is nothing like the return that's in most other languages. It doesn't end function execution or anything, it just takes a normal value and puts it in a context.
hmmm yaes</p>
<p>The next function is &gt;&gt;=, or bind. It's like function application, only instead of taking a normal value and feeding it to a normal function, it takes a monadic value (that is, a value with a context) and feeds it to a function that takes a normal value but returns a monadic value.</p>
<p>Next up, we have &gt;&gt;. We won't pay too much attention to it for now because it comes with a default implementation and we pretty much never implement it when making Monad instances.</p>
<p>The final function of the Monad type class is fail. We never use it explicitly in our code. Instead, it's used by Haskell to enable failure in a special syntactic construct for monads that we'll meet later. We don't need to concern ourselves with fail too much for now.</p>
<p>Now that we know what the Monad type class looks like, let's take a look at how Maybe is an instance of Monad!</p>
<pre><code>instance Monad Maybe where  
    return x = Just x  
    Nothing &gt;&gt;= f = Nothing  
    Just x &gt;&gt;= f  = f x  
    fail _ = Nothing
</code></pre>
<p>return is the same as pure, so that one's a no-brainer. We do what we did in the Applicative type class and wrap it in a Just.</p>
<p>The &gt;&gt;= function is the same as our applyMaybe. When feeding the Maybe a to our function, we keep in mind the context and return a Nothing if the value on the left is Nothing because if there's no value then there's no way to apply our function to it. If it's a Just we take what's inside and apply f to it.</p>
<p>We can play around with Maybe as a monad:</p>
<pre><code>ghci&gt; return "WHAT" :: Maybe String  
Just "WHAT"  
ghci&gt; Just 9 &gt;&gt;= \x -&gt; return (x*10)  
Just 90  
ghci&gt; Nothing &gt;&gt;= \x -&gt; return (x*10)  
Nothing
</code></pre>
<p>Nothing new or exciting on the first line since we already used pure with Maybe and we know that return is just pure with a different name. The next two lines showcase &gt;&gt;= a bit more.</p>
<p>Notice how when we fed Just 9 to the function \x -&gt; return (x*10), the x took on the value 9 inside the function. It seems as though we were able to extract the value from a Maybe without pattern-matching. And we still didn't lose the context of our Maybe value, because when it's Nothing, the result of using &gt;&gt;= will be Nothing as well.
Walk the line
pierre</p>
<p>Now that we know how to feed a Maybe a value to a function of type a -&gt; Maybe b while taking into account the context of possible failure, let's see how we can use &gt;&gt;= repeatedly to handle computations of several Maybe a values.</p>
<p>Pierre has decided to take a break from his job at the fish farm and try tightrope walking. He's not that bad at it, but he does have one problem: birds keep landing on his balancing pole! They come and they take a short rest, chat with their avian friends and then take off in search of breadcrumbs. This wouldn't bother him so much if the number of birds on the left side of the pole was always equal to the number of birds on the right side. But sometimes, all the birds decide that they like one side better and so they throw him off balance, which results in an embarrassing tumble for Pierre (he's using a safety net).</p>
<p>Let's say that he keeps his balance if the number of birds on the left side of the pole and on the right side of the pole is within three. So if there's one bird on the right side and four birds on the left side, he's okay. But if a fifth bird lands on the left side, then he loses his balance and takes a dive.</p>
<p>We're going to simulate birds landing on and flying away from the pole and see if Pierre is still at it after a certain number of birdy arrivals and departures. For instance, we want to see what happens to Pierre if first one bird arrives on the left side, then four birds occupy the right side and then the bird that was on the left side decides to fly away.</p>
<p>We can represent the pole with a simple pair of integers. The first component will signify the number of birds on the left side and the second component the number of birds on the right side:</p>
<pre><code>type Birds = Int  
type Pole = (Birds,Birds)
</code></pre>
<p>First we made a type synonym for Int, called Birds, because we're using integers to represent how many birds there are. And then we made a type synonym (Birds,Birds) and we called it Pole (not to be confused with a person of Polish descent).</p>
<p>Next up, how about we make a function that takes a number of birds and lands them on one side of the pole. Here are the functions:</p>
<pre><code>landLeft :: Birds -&gt; Pole -&gt; Pole  
landLeft n (left,right) = (left + n,right)

landRight :: Birds -&gt; Pole -&gt; Pole  
landRight n (left,right) = (left,right + n)
</code></pre>
<p>Pretty straightforward stuff. Let's try them out:</p>
<pre><code>ghci&gt; landLeft 2 (0,0)  
(2,0)  
ghci&gt; landRight 1 (1,2)  
(1,3)  
ghci&gt; landRight (-1) (1,2)  
(1,1)
</code></pre>
<p>To make birds fly away we just had a negative number of birds land on one side. Because landing a bird on the Pole returns a Pole, we can chain applications of landLeft and landRight:</p>
<pre><code>ghci&gt; landLeft 2 (landRight 1 (landLeft 1 (0,0)))  
(3,1)
</code></pre>
<p>When we apply the function landLeft 1 to (0,0) we get (1,0). Then, we land a bird on the right side, resulting in (1,1). Finally two birds land on the left side, resulting in (3,1). We apply a function to something by first writing the function and then writing its parameter, but here it would be better if the pole went first and then the landing function. If we make a function like this:</p>
<pre><code>x -: f = f x
</code></pre>
<p>We can apply functions by first writing the parameter and then the function:</p>
<pre><code>ghci&gt; 100 -: (*3)  
300  
ghci&gt; True -: not  
False  
ghci&gt; (0,0) -: landLeft 2  
(2,0)
</code></pre>
<p>By using this, we can repeatedly land birds on the pole in a more readable manner:</p>
<pre><code>ghci&gt; (0,0) -: landLeft 1 -: landRight 1 -: landLeft 2  
(3,1)
</code></pre>
<p>Pretty cool! This example is equivalent to the one before where we repeatedly landed birds on the pole, only it looks neater. Here, it's more obvious that we start off with (0,0) and then land one bird one the left, then one on the right and finally two on the left.</p>
<p>So far so good, but what happens if 10 birds land on one side?</p>
<pre><code>ghci&gt; landLeft 10 (0,3)  
(10,3)
</code></pre>
<p>10 birds on the left side and only 3 on the right? That's sure to send poor Pierre falling through the air! This is pretty obvious here but what if we had a sequence of landings like this:</p>
<pre><code>ghci&gt; (0,0) -: landLeft 1 -: landRight 4 -: landLeft (-1) -: landRight (-2)  
(0,2)
</code></pre>
<p>It might seem like everything is okay but if you follow the steps here, you'll see that at one time there are 4 birds on the right side and no birds on the left! To fix this, we have to take another look at our landLeft and landRight functions. From what we've seen, we want these functions to be able to fail. That is, we want them to return a new pole if the balance is okay but fail if the birds land in a lopsided manner. And what better way to add a context of failure to value than by using Maybe! Let's rework these functions:</p>
<pre><code>landLeft :: Birds -&gt; Pole -&gt; Maybe Pole  
landLeft n (left,right)  
    | abs ((left + n) - right) &lt; 4 = Just (left + n, right)  
    | otherwise                    = Nothing

landRight :: Birds -&gt; Pole -&gt; Maybe Pole  
landRight n (left,right)  
    | abs (left - (right + n)) &lt; 4 = Just (left, right + n)  
    | otherwise                    = Nothing
</code></pre>
<p>Instead of returning a Pole these functions now return a Maybe Pole. They still take the number of birds and the old pole as before, but then they check if landing that many birds on the pole would throw Pierre off balance. We use guards to check if the difference between the number of birds on the new pole is less than 4. If it is, we wrap the new pole in a Just and return that. If it isn't, we return a Nothing, indicating failure.</p>
<p>Let's give these babies a go:</p>
<pre><code>ghci&gt; landLeft 2 (0,0)  
Just (2,0)  
ghci&gt; landLeft 10 (0,3)  
Nothing
</code></pre>
<p>Nice! When we land birds without throwing Pierre off balance, we get a new pole wrapped in a Just. But when many more birds end up on one side of the pole, we get a Nothing. This is cool, but we seem to have lost the ability to repeatedly land birds on the pole. We can't do landLeft 1 (landRight 1 (0,0)) anymore because when we apply landRight 1 to (0,0), we don't get a Pole, but a Maybe Pole. landLeft 1 takes a Pole and not a Maybe Pole.</p>
<p>We need a way of taking a Maybe Pole and feeding it to a function that takes a Pole and returns a Maybe Pole. Luckily, we have &gt;&gt;=, which does just that for Maybe. Let's give it a go:</p>
<pre><code>ghci&gt; landRight 1 (0,0) &gt;&gt;= landLeft 2  
Just (2,1)
</code></pre>
<p>Remember, landLeft 2 has a type of Pole -&gt; Maybe Pole. We couldn't just feed it the Maybe Pole that is the result of landRight 1 (0,0), so we use &gt;&gt;= to take that value with a context and give it to landLeft 2. &gt;&gt;= does indeed allow us to treat the Maybe value as a value with context because if we feed a Nothing into landLeft 2, the result is Nothing and the failure is propagated:</p>
<pre><code>ghci&gt; Nothing &gt;&gt;= landLeft 2  
Nothing
</code></pre>
<p>With this, we can now chain landings that may fail because &gt;&gt;= allows us to feed a monadic value to a function that takes a normal one.</p>
<p>Here's a sequence of birdy landings:</p>
<pre><code>ghci&gt; return (0,0) &gt;&gt;= landRight 2 &gt;&gt;= landLeft 2 &gt;&gt;= landRight 2  
Just (2,4)
</code></pre>
<p>At the beginning, we used return to take a pole and wrap it in a Just. We could have just applied landRight 2 to (0,0), it would have been the same, but this way we can be more consistent by using &gt;&gt;= for every function. Just (0,0) gets fed to landRight 2, resulting in Just (0,2). This, in turn, gets fed to landLeft 2, resulting in Just (2,2), and so on.</p>
<p>Remember this example from before we introduced failure into Pierre's routine:</p>
<pre><code>ghci&gt; (0,0) -: landLeft 1 -: landRight 4 -: landLeft (-1) -: landRight (-2)  
(0,2)
</code></pre>
<p>It didn't simulate his interaction with birds very well because in the middle there his balance was off but the result didn't reflect that. But let's give that a go now by using monadic application (&gt;&gt;=) instead of normal application:</p>
<pre><code>ghci&gt; return (0,0) &gt;&gt;= landLeft 1 &gt;&gt;= landRight 4 &gt;&gt;= landLeft (-1) &gt;&gt;= landRight (-2)  
Nothing
</code></pre>
<p>iama banana</p>
<p>Awesome. The final result represents failure, which is what we expected. Let's see how this result was obtained. First, return puts (0,0) into a default context, making it a Just (0,0). Then, Just (0,0) &gt;&gt;= landLeft 1 happens. Since the Just (0,0) is a Just value, landLeft 1 gets applied to (0,0), resulting in a Just (1,0), because the birds are still relatively balanced. Next, Just (1,0) &gt;&gt;= landRight 4 takes place and the result is Just (1,4) as the balance of the birds is still intact, although just barely. Just (1,4) gets fed to landLeft (-1). This means that landLeft (-1) (1,4) takes place. Now because of how landLeft works, this results in a Nothing, because the resulting pole is off balance. Now that we have a Nothing, it gets fed to landRight (-2), but because it's a Nothing, the result is automatically Nothing, as we have nothing to apply landRight (-2) to.</p>
<p>We couldn't have achieved this by just using Maybe as an applicative. If you try it, you'll get stuck, because applicative functors don't allow for the applicative values to interact with each other very much. They can, at best, be used as parameters to a function by using the applicative style. The applicative operators will fetch their results and feed them to the function in a manner appropriate for each applicative and then put the final applicative value together, but there isn't that much interaction going on between them. Here, however, each step relies on the previous one's result. On every landing, the possible result from the previous one is examined and the pole is checked for balance. This determines whether the landing will succeed or fail.</p>
<p>We may also devise a function that ignores the current number of birds on the balancing pole and just makes Pierre slip and fall. We can call it banana:</p>
<pre><code>banana :: Pole -&gt; Maybe Pole  
banana _ = Nothing
</code></pre>
<p>Now we can chain it together with our bird landings. It will always cause our walker to fall, because it ignores whatever's passed to it and always returns a failure. Check it:</p>
<pre><code>ghci&gt; return (0,0) &gt;&gt;= landLeft 1 &gt;&gt;= banana &gt;&gt;= landRight 1  
Nothing
</code></pre>
<p>The value Just (1,0) gets fed to banana, but it produces a Nothing, which causes everything to result in a Nothing. How unfortunate!</p>
<p>Instead of making functions that ignore their input and just return a predetermined monadic value, we can use the &gt;&gt; function, whose default implementation is this:</p>
<pre><code>(&gt;&gt;) :: (Monad m) =&gt; m a -&gt; m b -&gt; m b  
m &gt;&gt; n = m &gt;&gt;= \_ -&gt; n
</code></pre>
<p>Normally, passing some value to a function that ignores its parameter and always just returns some predetermined value would always result in that predetermined value. With monads however, their context and meaning has to be considered as well. Here's how &gt;&gt; acts with Maybe:</p>
<pre><code>ghci&gt; Nothing &gt;&gt; Just 3  
Nothing  
ghci&gt; Just 3 &gt;&gt; Just 4  
Just 4  
ghci&gt; Just 3 &gt;&gt; Nothing  
Nothing
</code></pre>
<p>If you replace &gt;&gt; with &gt;&gt;= _ -&gt;, it's easy to see why it acts like it does.</p>
<p>We can replace our banana function in the chain with a &gt;&gt; and then a Nothing:</p>
<pre><code>ghci&gt; return (0,0) &gt;&gt;= landLeft 1 &gt;&gt; Nothing &gt;&gt;= landRight 1  
Nothing
</code></pre>
<p>There we go, guaranteed and obvious failure!</p>
<p>It's also worth taking a look at what this would look like if we hadn't made the clever choice of treating Maybe values as values with a failure context and feeding them to functions like we did. Here's how a series of bird landings would look like:</p>
<pre><code>routine :: Maybe Pole  
routine = case landLeft 1 (0,0) of  
    Nothing -&gt; Nothing  
    Just pole1 -&gt; case landRight 4 pole1 of   
        Nothing -&gt; Nothing  
        Just pole2 -&gt; case landLeft 2 pole2 of  
            Nothing -&gt; Nothing  
            Just pole3 -&gt; landLeft 1 pole3
</code></pre>
<p>john joe glanton</p>
<p>We land a bird on the left and then we examine the possibility of failure and the possibility of success. In the case of failure, we return a Nothing. In the case of success, we land birds on the right and then do the same thing all over again. Converting this monstrosity into a neat chain of monadic applications with &gt;&gt;= is a classic example of how the Maybe monad saves us a lot of time when we have to successively do computations that are based on computations that might have failed.</p>
<p>Notice how the Maybe implementation of &gt;&gt;= features exactly this logic of seeing if a value is Nothing and if it is, returning a Nothing right away and if it isn't, going forward with what's inside the Just.</p>
<p>In this section, we took some functions that we had and saw that they would work better if the values that they returned supported failure. By turning those values into Maybe values and replacing normal function application with &gt;&gt;=, we got a mechanism for handling failure pretty much for free, because &gt;&gt;= is supposed to preserve the context of the value to which it applies functions. In this case, the context was that our values were values with failure and so when we applied functions to such values, the possibility of failure was always taken into account.
do notation</p>
<p>Monads in Haskell are so useful that they got their own special syntax called do notation. We've already encountered do notation when we were doing I/O and there we said that it was for gluing together several I/O actions into one. Well, as it turns out, do notation isn't just for IO, but can be used for any monad. Its principle is still the same: gluing together monadic values in sequence. We're going to take a look at how do notation works and why it's useful.</p>
<p>Consider this familiar example of monadic application:</p>
<pre><code>ghci&gt; Just 3 &gt;&gt;= (\x -&gt; Just (show x ++ "!"))  
Just "3!"
</code></pre>
<p>Been there, done that. Feeding a monadic value to a function that returns one, no big deal. Notice how when we do this, x becomes 3 inside the lambda. Once we're inside that lambda, it's just a normal value rather than a monadic value. Now, what if we had another &gt;&gt;= inside that function? Check this out:</p>
<pre><code>ghci&gt; Just 3 &gt;&gt;= (\x -&gt; Just "!" &gt;&gt;= (\y -&gt; Just (show x ++ y)))  
Just "3!"
</code></pre>
<p>Ah, a nested use of &gt;&gt;=! In the outermost lambda, we feed Just "!" to the lambda \y -&gt; Just (show x ++ y). Inside this lambda, the y becomes "!". x is still 3 because we got it from the outer lambda. All this sort of reminds me of the following expression:</p>
<pre><code>ghci&gt; let x = 3; y = "!" in show x ++ y  
"3!"
</code></pre>
<p>The main difference between these two is that the values in the former example are monadic. They're values with a failure context. We can replace any of them with a failure:</p>
<pre><code>ghci&gt; Nothing &gt;&gt;= (\x -&gt; Just "!" &gt;&gt;= (\y -&gt; Just (show x ++ y)))  
Nothing  
ghci&gt; Just 3 &gt;&gt;= (\x -&gt; Nothing &gt;&gt;= (\y -&gt; Just (show x ++ y)))  
Nothing  
ghci&gt; Just 3 &gt;&gt;= (\x -&gt; Just "!" &gt;&gt;= (\y -&gt; Nothing))  
Nothing
</code></pre>
<p>In the first line, feeding a Nothing to a function naturally results in a Nothing. In the second line, we feed Just 3 to a function and the x becomes 3, but then we feed a Nothing to the inner lambda and the result of that is Nothing, which causes the outer lambda to produce Nothing as well. So this is sort of like assigning values to variables in let expressions, only that the values in question are monadic values.</p>
<p>To further illustrate this point, let's write this in a script and have each Maybe value take up its own line:</p>
<pre><code>foo :: Maybe String  
foo = Just 3   &gt;&gt;= (\x -&gt; 
      Just "!" &gt;&gt;= (\y -&gt; 
      Just (show x ++ y)))
</code></pre>
<p>To save us from writing all these annoying lambdas, Haskell gives us do notation. It allows us to write the previous piece of code like this:</p>
<pre><code>foo :: Maybe String  
foo = do  
    x &lt;- Just 3  
    y &lt;- Just "!"  
    Just (show x ++ y)
</code></pre>
<p>90s owl</p>
<p>It would seem as though we've gained the ability to temporarily extract things from Maybe values without having to check if the Maybe values are Just values or Nothing values at every step. How cool! If any of the values that we try to extract from are Nothing, the whole do expression will result in a Nothing. We're yanking out their (possibly existing) values and letting &gt;&gt;= worry about the context that comes with those values. It's important to remember that do expressions are just different syntax for chaining monadic values.</p>
<p>In a do expression, every line is a monadic value. To inspect its result, we use &lt;-. If we have a Maybe String and we bind it with &lt;- to a variable, that variable will be a String, just like when we used &gt;&gt;= to feed monadic values to lambdas. The last monadic value in a do expression, like Just (show x ++ y) here, can't be used with &lt;- to bind its result, because that wouldn't make sense if we translated the do expression back to a chain of &gt;&gt;= applications. Rather, its result is the result of the whole glued up monadic value, taking into account the possible failure of any of the previous ones.</p>
<p>For instance, examine the following line:</p>
<pre><code>ghci&gt; Just 9 &gt;&gt;= (\x -&gt; Just (x &gt; 8))  
Just True
</code></pre>
<p>Because the left parameter of &gt;&gt;= is a Just value, the lambda is applied to 9 and the result is a Just True. If we rewrite this in do notation, we get:</p>
<pre><code>marySue :: Maybe Bool  
marySue = do   
    x &lt;- Just 9  
    Just (x &gt; 8)
</code></pre>
<p>If we compare these two, it's easy to see why the result of the whole monadic value is the result of the last monadic value in the do expression with all the previous ones chained into it.</p>
<p>Our tightwalker's routine can also be expressed with do notation. landLeft and landRight take a number of birds and a pole and produce a pole wrapped in a Just, unless the tightwalker slips, in which case a Nothing is produced. We used &gt;&gt;= to chain successive steps because each one relied on the previous one and each one had an added context of possible failure. Here's two birds landing on the left side, then two birds landing on the right and then one bird landing on the left:</p>
<pre><code>routine :: Maybe Pole  
routine = do  
    start &lt;- return (0,0)  
    first &lt;- landLeft 2 start  
    second &lt;- landRight 2 first  
    landLeft 1 second
</code></pre>
<p>Let's see if he succeeds:</p>
<pre><code>ghci&gt; routine  
Just (3,2)
</code></pre>
<p>He does! Great. When we were doing these routines by explicitly writing &gt;&gt;=, we usually said something like return (0,0) &gt;&gt;= landLeft 2, because landLeft 2 is a function that returns a Maybe value. With do expressions however, each line must feature a monadic value. So we explicitly pass the previous Pole to the landLeft landRight functions. If we examined the variables to which we bound our Maybe values, start would be (0,0), first would be (2,0) and so on.</p>
<p>Because do expressions are written line by line, they may look like imperative code to some people. But the thing is, they're just sequential, as each value in each line relies on the result of the previous ones, along with their contexts (in this case, whether they succeeded or failed).</p>
<p>Again, let's take a look at what this piece of code would look like if we hadn't used the monadic aspects of Maybe:</p>
<pre><code>routine :: Maybe Pole  
routine =   
    case Just (0,0) of   
        Nothing -&gt; Nothing  
        Just start -&gt; case landLeft 2 start of  
            Nothing -&gt; Nothing  
            Just first -&gt; case landRight 2 first of  
                Nothing -&gt; Nothing  
                Just second -&gt; landLeft 1 second
</code></pre>
<p>See how in the case of success, the tuple inside Just (0,0) becomes start, the result of landLeft 2 start becomes first, etc.</p>
<p>If we want to throw the Pierre a banana peel in do notation, we can do the following:</p>
<pre><code>routine :: Maybe Pole  
routine = do  
    start &lt;- return (0,0)  
    first &lt;- landLeft 2 start  
    Nothing  
    second &lt;- landRight 2 first  
    landLeft 1 second
</code></pre>
<p>When we write a line in do notation without binding the monadic value with &lt;-, it's just like putting &gt;&gt; after the monadic value whose result we want to ignore. We sequence the monadic value but we ignore its result because we don't care what it is and it's prettier than writing _ &lt;- Nothing, which is equivalent to the above.</p>
<p>When to use do notation and when to explicitly use &gt;&gt;= is up to you. I think this example lends itself to explicitly writing &gt;&gt;= because each step relies specifically on the result of the previous one. With do notation, we had to specifically write on which pole the birds are landing, but every time we used that came directly before. But still, it gave us some insight into do notation.</p>
<p>In do notation, when we bind monadic values to names, we can utilize pattern matching, just like in let expressions and function parameters. Here's an example of pattern matching in a do expression:</p>
<pre><code>justH :: Maybe Char  
justH = do  
    (x:xs) &lt;- Just "hello"  
    return x
</code></pre>
<p>We use pattern matching to get the first character of the string "hello" and then we present it as the result. So justH evaluates to Just 'h'.</p>
<p>What if this pattern matching were to fail? When matching on a pattern in a function fails, the next pattern is matched. If the matching falls through all the patterns for a given function, an error is thrown and our program crashes. On the other hand, failed pattern matching in let expressions results in an error being produced right away, because the mechanism of falling through patterns isn't present in let expressions. When pattern matching fails in a do expression, the fail function is called. It's part of the Monad type class and it enables failed pattern matching to result in a failure in the context of the current monad instead of making our program crash. Its default implementation is this:</p>
<pre><code>fail :: (Monad m) =&gt; String -&gt; m a  
fail msg = error msg
</code></pre>
<p>So by default it does make our program crash, but monads that incorporate a context of possible failure (like Maybe) usually implement it on their own. For Maybe, its implemented like so:</p>
<pre><code>fail _ = Nothing
</code></pre>
<p>It ignores the error message and makes a Nothing. So when pattern matching fails in a Maybe value that's written in do notation, the whole value results in a Nothing. This is preferable to having our program crash. Here's a do expression with a pattern that's bound to fail:</p>
<pre><code>wopwop :: Maybe Char  
wopwop = do  
    (x:xs) &lt;- Just ""  
    return x
</code></pre>
<p>The pattern matching fails, so the effect is the same as if the whole line with the pattern was replaced with a Nothing. Let's try this out:</p>
<pre><code>ghci&gt; wopwop  
Nothing
</code></pre>
<p>The failed pattern matching has caused a failure within the context of our monad instead of causing a program-wide failure, which is pretty neat.
The list monad
dead cat</p>
<p>So far, we've seen how Maybe values can be viewed as values with a failure context and how we can incorporate failure handling into our code by using &gt;&gt;= to feed them to functions. In this section, we're going to take a look at how to use the monadic aspects of lists to bring non-determinism into our code in a clear and readable manner.</p>
<p>We've already talked about how lists represent non-deterministic values when they're used as applicatives. A value like 5 is deterministic. It has only one result and we know exactly what it is. On the other hand, a value like [3,8,9] contains several results, so we can view it as one value that is actually many values at the same time. Using lists as applicative functors showcases this non-determinism nicely:</p>
<pre><code>ghci&gt; (*) &lt;$&gt; [1,2,3] &lt;*&gt; [10,100,1000]  
[10,100,1000,20,200,2000,30,300,3000]
</code></pre>
<p>All the possible combinations of multiplying elements from the left list with elements from the right list are included in the resulting list. When dealing with non-determinism, there are many choices that we can make, so we just try all of them, and so the result is a non-deterministic value as well, only it has many more results.</p>
<p>This context of non-determinism translates to monads very nicely. Let's go ahead and see what the Monad instance for lists looks like:</p>
<pre><code>instance Monad [] where  
    return x = [x]  
    xs &gt;&gt;= f = concat (map f xs)  
    fail _ = []
</code></pre>
<p>return does the same thing as pure, so we should already be familiar with return for lists. It takes a value and puts it in a minimal default context that still yields that value. In other words, it makes a list that has only that one value as its result. This is useful for when we want to just wrap a normal value into a list so that it can interact with non-deterministic values.</p>
<p>To understand how &gt;&gt;= works for lists, it's best if we take a look at it in action to gain some intuition first. &gt;&gt;= is about taking a value with a context (a monadic value) and feeding it to a function that takes a normal value and returns one that has context. If that function just produced a normal value instead of one with a context, &gt;&gt;= wouldn't be so useful because after one use, the context would be lost. Anyway, let's try feeding a non-deterministic value to a function:</p>
<pre><code>ghci&gt; [3,4,5] &gt;&gt;= \x -&gt; [x,-x]  
[3,-3,4,-4,5,-5]
</code></pre>
<p>When we used &gt;&gt;= with Maybe, the monadic value was fed into the function while taking care of possible failures. Here, it takes care of non-determinism for us. [3,4,5] is a non-deterministic value and we feed it into a function that returns a non-deterministic value as well. The result is also non-deterministic, and it features all the possible results of taking elements from the list [3,4,5] and passing them to the function \x -&gt; [x,-x]. This function takes a number and produces two results: one negated and one that's unchanged. So when we use &gt;&gt;= to feed this list to the function, every number is negated and also kept unchanged. The x from the lambda takes on every value from the list that's fed to it.</p>
<p>To see how this is achieved, we can just follow the implementation. First, we start off with the list [3,4,5]. Then, we map the lambda over it and the result is the following:</p>
<pre><code>[[3,-3],[4,-4],[5,-5]]
</code></pre>
<p>The lambda is applied to every element and we get a list of lists. Finally, we just flatten the list and voila! We've applied a non-deterministic function to a non-deterministic value!</p>
<p>Non-determinism also includes support for failure. The empty list [] is pretty much the equivalent of Nothing, because it signifies the absence of a result. That's why failing is just defined as the empty list. The error message gets thrown away. Let's play around with lists that fail:</p>
<pre><code>ghci&gt; [] &gt;&gt;= \x -&gt; ["bad","mad","rad"]  
[]  
ghci&gt; [1,2,3] &gt;&gt;= \x -&gt; []  
[]
</code></pre>
<p>In the first line, an empty list is fed into the lambda. Because the list has no elements, none of them can be passed to the function and so the result is an empty list. This is similar to feeding Nothing to a function. In the second line, each element gets passed to the function, but the element is ignored and the function just returns an empty list. Because the function fails for every element that goes in it, the result is a failure.</p>
<p>Just like with Maybe values, we can chain several lists with &gt;&gt;=, propagating the non-determinism:</p>
<pre><code>ghci&gt; [1,2] &gt;&gt;= \n -&gt; ['a','b'] &gt;&gt;= \ch -&gt; return (n,ch)  
[(1,'a'),(1,'b'),(2,'a'),(2,'b')]
</code></pre>
<p>concatmap</p>
<p>The list [1,2] gets bound to n and ['a','b'] gets bound to ch. Then, we do return (n,ch) (or [(n,ch)]), which means taking a pair of (n,ch) and putting it in a default minimal context. In this case, it's making the smallest possible list that still presents (n,ch) as the result and features as little non-determinism as possible. Its effect on the context is minimal. What we're saying here is this: for every element in [1,2], go over every element in ['a','b'] and produce a tuple of one element from each list.</p>
<p>Generally speaking, because return takes a value and wraps it in a minimal context, it doesn't have any extra effect (like failing in Maybe or resulting in more non-determinism for lists) but it does present something as its result.
When you have non-deterministic values interacting, you can view their computation as a tree where every possible result in a list represents a separate branch.</p>
<p>Here's the previous expression rewritten in do notation:</p>
<pre><code>listOfTuples :: [(Int,Char)]  
listOfTuples = do  
    n &lt;- [1,2]  
    ch &lt;- ['a','b']  
    return (n,ch)
</code></pre>
<p>This makes it a bit more obvious that n takes on every value from [1,2] and ch takes on every value from ['a','b']. Just like with Maybe, we're extracting the elements from the monadic values and treating them like normal values and &gt;&gt;= takes care of the context for us. The context in this case is non-determinism.</p>
<p>Using lists with do notation really reminds me of something we've seen before. Check out the following piece of code:</p>
<pre><code>ghci&gt; [ (n,ch) | n &lt;- [1,2], ch &lt;- ['a','b'] ]  
[(1,'a'),(1,'b'),(2,'a'),(2,'b')]
</code></pre>
<p>Yes! List comprehensions! In our do notation example, n became every result from [1,2] and for every such result, ch was assigned a result from ['a','b'] and then the final line put (n,ch) into a default context (a singleton list) to present it as the result without introducing any additional non-determinism. In this list comprehension, the same thing happened, only we didn't have to write return at the end to present (n,ch) as the result because the output part of a list comprehension did that for us.</p>
<p>In fact, list comprehensions are just syntactic sugar for using lists as monads. In the end, list comprehensions and lists in do notation translate to using &gt;&gt;= to do computations that feature non-determinism.</p>
<p>List comprehensions allow us to filter our output. For instance, we can filter a list of numbers to search only for that numbers whose digits contain a 7:</p>
<pre><code>ghci&gt; [ x | x &lt;- [1..50], '7' `elem` show x ]  
[7,17,27,37,47]
</code></pre>
<p>We apply show to x to turn our number into a string and then we check if the character '7' is part of that string. Pretty clever. To see how filtering in list comprehensions translates to the list monad, we have to check out the guard function and the MonadPlus type class. The MonadPlus type class is for monads that can also act as monoids. Here's its definition:</p>
<pre><code>class Monad m =&gt; MonadPlus m where  
    mzero :: m a  
    mplus :: m a -&gt; m a -&gt; m a
</code></pre>
<p>mzero is synonymous to mempty from the Monoid type class and mplus corresponds to mappend. Because lists are monoids as well as monads, they can be made an instance of this type class:</p>
<pre><code>instance MonadPlus [] where  
    mzero = []  
    mplus = (++)
</code></pre>
<p>For lists mzero represents a non-deterministic computation that has no results at all — a failed computation. mplus joins two non-deterministic values into one. The guard function is defined like this:</p>
<pre><code>guard :: (MonadPlus m) =&gt; Bool -&gt; m ()  
guard True = return ()  
guard False = mzero
</code></pre>
<p>It takes a boolean value and if it's True, takes a () and puts it in a minimal default context that still succeeds. Otherwise, it makes a failed monadic value. Here it is in action:</p>
<pre><code>ghci&gt; guard (5 &gt; 2) :: Maybe ()  
Just ()  
ghci&gt; guard (1 &gt; 2) :: Maybe ()  
Nothing  
ghci&gt; guard (5 &gt; 2) :: [()]  
[()]  
ghci&gt; guard (1 &gt; 2) :: [()]  
[]
</code></pre>
<p>Looks interesting, but how is it useful? In the list monad, we use it to filter out non-deterministic computations. Observe:</p>
<pre><code>ghci&gt; [1..50] &gt;&gt;= (\x -&gt; guard ('7' `elem` show x) &gt;&gt; return x)  
[7,17,27,37,47]
</code></pre>
<p>The result here is the same as the result of our previous list comprehension. How does guard achieve this? Let's first see how guard functions in conjunction with &gt;&gt;:</p>
<pre><code>ghci&gt; guard (5 &gt; 2) &gt;&gt; return "cool" :: [String]  
["cool"]  
ghci&gt; guard (1 &gt; 2) &gt;&gt; return "cool" :: [String]  
[]
</code></pre>
<p>If guard succeeds, the result contained within it is an empty tuple. So then, we use &gt;&gt; to ignore that empty tuple and present something else as the result. However, if guard fails, then so will the return later on, because feeding an empty list to a function with &gt;&gt;= always results in an empty list. A guard basically says: if this boolean is False then produce a failure right here, otherwise make a successful value that has a dummy result of () inside it. All this does is to allow the computation to continue.</p>
<p>Here's the previous example rewritten in do notation:</p>
<pre><code>sevensOnly :: [Int]  
sevensOnly = do  
    x &lt;- [1..50]  
    guard ('7' `elem` show x)  
    return x
</code></pre>
<p>Had we forgotten to present x as the final result by using return, the resulting list would just be a list of empty tuples. Here's this again in the form of a list comprehension:</p>
<pre><code>ghci&gt; [ x | x &lt;- [1..50], '7' `elem` show x ]  
[7,17,27,37,47]
</code></pre>
<p>So filtering in list comprehensions is the same as using guard.
A knight's quest</p>
<p>Here's a problem that really lends itself to being solved with non-determinism. Say you have a chess board and only one knight piece on it. We want to find out if the knight can reach a certain position in three moves. We'll just use a pair of numbers to represent the knight's position on the chess board. The first number will determine the column he's in and the second number will determine the row.
hee haw im a horse</p>
<p>Let's make a type synonym for the knight's current position on the chess board:</p>
<pre><code>type KnightPos = (Int,Int)
</code></pre>
<p>So let's say that the knight starts at (6,2). Can he get to (6,1) in exactly three moves? Let's see. If we start off at (6,2) what's the best move to make next? I know, how about all of them! We have non-determinism at our disposal, so instead of picking one move, let's just pick all of them at once. Here's a function that takes the knight's position and returns all of its next moves:</p>
<pre><code>moveKnight :: KnightPos -&gt; [KnightPos]  
moveKnight (c,r) = do  
    (c',r') &lt;- [(c+2,r-1),(c+2,r+1),(c-2,r-1),(c-2,r+1)  
               ,(c+1,r-2),(c+1,r+2),(c-1,r-2),(c-1,r+2)  
               ]  
    guard (c' `elem` [1..8] &amp;&amp; r' `elem` [1..8])  
    return (c',r')
</code></pre>
<p>The knight can always take one step horizontally or vertically and two steps horizontally or vertically but its movement has to be both horizontal and vertical. (c',r') takes on every value from the list of movements and then guard makes sure that the new move, (c',r') is still on the board. If it it's not, it produces an empty list, which causes a failure and return (c',r') isn't carried out for that position.</p>
<p>This function can also be written without the use of lists as a monad, but we did it here just for kicks. Here is the same function done with filter:</p>
<pre><code>moveKnight :: KnightPos -&gt; [KnightPos]  
moveKnight (c,r) = filter onBoard  
    [(c+2,r-1),(c+2,r+1),(c-2,r-1),(c-2,r+1)  
    ,(c+1,r-2),(c+1,r+2),(c-1,r-2),(c-1,r+2)  
    ]  
    where onBoard (c,r) = c `elem` [1..8] &amp;&amp; r `elem` [1..8]
</code></pre>
<p>Both of these do the same thing, so pick one that you think looks nicer. Let's give it a whirl:</p>
<pre><code>ghci&gt; moveKnight (6,2)  
[(8,1),(8,3),(4,1),(4,3),(7,4),(5,4)]  
ghci&gt; moveKnight (8,1)  
[(6,2),(7,3)]
</code></pre>
<p>Works like a charm! We take one position and we just carry out all the possible moves at once, so to speak. So now that we have a non-deterministic next position, we just use &gt;&gt;= to feed it to moveKnight. Here's a function that takes a position and returns all the positions that you can reach from it in three moves:</p>
<pre><code>in3 :: KnightPos -&gt; [KnightPos]  
in3 start = do   
    first &lt;- moveKnight start  
    second &lt;- moveKnight first  
    moveKnight second
</code></pre>
<p>If you pass it (6,2), the resulting list is quite big, because if there are several ways to reach some position in three moves, it crops up in the list several times. The above without do notation:</p>
<pre><code>in3 start = return start &gt;&gt;= moveKnight &gt;&gt;= moveKnight &gt;&gt;= moveKnight
</code></pre>
<p>Using &gt;&gt;= once gives us all possible moves from the start and then when we use &gt;&gt;= the second time, for every possible first move, every possible next move is computed, and the same goes for the last move.</p>
<p>Putting a value in a default context by applying return to it and then feeding it to a function with &gt;&gt;= is the same as just normally applying the function to that value, but we did it here anyway for style.</p>
<p>Now, let's make a function that takes two positions and tells us if you can get from one to the other in exactly three steps:</p>
<pre><code>canReachIn3 :: KnightPos -&gt; KnightPos -&gt; Bool  
canReachIn3 start end = end `elem` in3 start
</code></pre>
<p>We generate all the possible positions in three steps and then we see if the position we're looking for is among them. So let's see if we can get from (6,2) to (6,1) in three moves:</p>
<pre><code>ghci&gt; (6,2) `canReachIn3` (6,1)  
True
</code></pre>
<p>Yes! How about from (6,2) to (7,3)?</p>
<pre><code>ghci&gt; (6,2) `canReachIn3` (7,3)  
False
</code></pre>
<p>No! As an exercise, you can change this function so that when you can reach one position from the other, it tells you which moves to take. Later on, we'll see how to modify this function so that we also pass it the number of moves to take instead of that number being hardcoded like it is now.
Monad laws
the court finds you guilty of peeing all over everything</p>
<p>Just like applicative functors, and functors before them, monads come with a few laws that all monad instances must abide by. Just because something is made an instance of the Monad type class doesn't mean that it's a monad, it just means that it was made an instance of a type class. For a type to truly be a monad, the monad laws must hold for that type. These laws allow us to make reasonable assumptions about the type and its behavior.</p>
<p>Haskell allows any type to be an instance of any type class as long as the types check out. It can't check if the monad laws hold for a type though, so if we're making a new instance of the Monad type class, we have to be reasonably sure that all is well with the monad laws for that type. We can rely on the types that come with the standard library to satisfy the laws, but later when we go about making our own monads, we're going to have to manually check the if the laws hold. But don't worry, they're not complicated.
Left identity</p>
<p>The first monad law states that if we take a value, put it in a default context with return and then feed it to a function by using &gt;&gt;=, it's the same as just taking the value and applying the function to it. To put it formally:</p>
<pre><code>return x &gt;&gt;= f is the same damn thing as f x
</code></pre>
<p>If you look at monadic values as values with a context and return as taking a value and putting it in a default minimal context that still presents that value as its result, it makes sense, because if that context is really minimal, feeding this monadic value to a function shouldn't be much different than just applying the function to the normal value, and indeed it isn't different at all.</p>
<p>For the Maybe monad return is defined as Just. The Maybe monad is all about possible failure, and if we have a value and want to put it in such a context, it makes sense that we treat it as a successful computation because, well, we know what the value is. Here's some return usage with Maybe:</p>
<pre><code>ghci&gt; return 3 &gt;&gt;= (\x -&gt; Just (x+100000))  
Just 100003  
ghci&gt; (\x -&gt; Just (x+100000)) 3  
Just 100003
</code></pre>
<p>For the list monad return puts something in a singleton list. The &gt;&gt;= implementation for lists goes over all the values in the list and applies the function to them, but since there's only one value in a singleton list, it's the same as applying the function to that value:</p>
<pre><code>ghci&gt; return "WoM" &gt;&gt;= (\x -&gt; [x,x,x])  
["WoM","WoM","WoM"]  
ghci&gt; (\x -&gt; [x,x,x]) "WoM"  
["WoM","WoM","WoM"]
</code></pre>
<p>We said that for IO, using return makes an I/O action that has no side-effects but just presents a value as its result. So it makes sense that this law holds for IO as well.
Right identity</p>
<p>The second law states that if we have a monadic value and we use &gt;&gt;= to feed it to return, the result is our original monadic value. Formally:</p>
<pre><code>m &gt;&gt;= return is no different than just m
</code></pre>
<p>This one might be a bit less obvious than the first one, but let's take a look at why it should hold. When we feed monadic values to functions by using &gt;&gt;=, those functions take normal values and return monadic ones. return is also one such function, if you consider its type. Like we said, return puts a value in a minimal context that still presents that value as its result. This means that, for instance, for Maybe, it doesn't introduce any failure and for lists, it doesn't introduce any extra non-determinism. Here's a test run for a few monads:</p>
<pre><code>ghci&gt; Just "move on up" &gt;&gt;= (\x -&gt; return x)  
Just "move on up"  
ghci&gt; [1,2,3,4] &gt;&gt;= (\x -&gt; return x)  
[1,2,3,4]  
ghci&gt; putStrLn "Wah!" &gt;&gt;= (\x -&gt; return x)  
Wah!
</code></pre>
<p>If we take a closer look at the list example, the implementation for &gt;&gt;= is:</p>
<pre><code>xs &gt;&gt;= f = concat (map f xs)
</code></pre>
<p>So when we feed [1,2,3,4] to return, first return gets mapped over [1,2,3,4], resulting in [[1],[2],[3],[4]] and then this gets concatenated and we have our original list.</p>
<p>Left identity and right identity are basically laws that describe how return should behave. It's an important function for making normal values into monadic ones and it wouldn't be good if the monadic value that it produced did a lot of other stuff.
Associativity</p>
<p>The final monad law says that when we have a chain of monadic function applications with &gt;&gt;=, it shouldn't matter how they're nested. Formally written:</p>
<pre><code>Doing (m &gt;&gt;= f) &gt;&gt;= g is just like doing m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)
</code></pre>
<p>Hmmm, now what's going on here? We have one monadic value, m and two monadic functions f and g. When we're doing (m &gt;&gt;= f) &gt;&gt;= g, we're feeding m to f, which results in a monadic value. Then, we feed that monadic value to g. In the expression m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g), we take a monadic value and we feed it to a function that feeds the result of f x to g. It's not easy to see how those two are equal, so let's take a look at an example that makes this equality a bit clearer.</p>
<p>Remember when we had our tightrope walker Pierre walk a rope while birds landed on his balancing pole? To simulate birds landing on his balancing pole, we made a chain of several functions that might produce failure:</p>
<pre><code>ghci&gt; return (0,0) &gt;&gt;= landRight 2 &gt;&gt;= landLeft 2 &gt;&gt;= landRight 2  
Just (2,4)
</code></pre>
<p>We started with Just (0,0) and then bound that value to the next monadic function, landRight 2. The result of that was another monadic value which got bound into the next monadic function, and so on. If we were to explicitly parenthesize this, we'd write:</p>
<pre><code>ghci&gt; ((return (0,0) &gt;&gt;= landRight 2) &gt;&gt;= landLeft 2) &gt;&gt;= landRight 2  
Just (2,4)
</code></pre>
<p>But we can also write the routine like this:</p>
<pre><code>return (0,0) &gt;&gt;= (\x -&gt; 
landRight 2 x &gt;&gt;= (\y -&gt; 
landLeft 2 y &gt;&gt;= (\z -&gt; 
landRight 2 z)))
</code></pre>
<p>return (0,0) is the same as Just (0,0) and when we feed it to the lambda, the x becomes (0,0). landRight takes a number of birds and a pole (a tuple of numbers) and that's what it gets passed. This results in a Just (0,2) and when we feed this to the next lambda, y is (0,2). This goes on until the final bird landing produces a Just (2,4), which is indeed the result of the whole expression.</p>
<p>So it doesn't matter how you nest feeding values to monadic functions, what matters is their meaning. Here's another way to look at this law: consider composing two functions, f and g. Composing two functions is implemented like so:</p>
<pre><code>(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c)  
f . g = (\x -&gt; f (g x))
</code></pre>
<p>If the type of g is a -&gt; b and the type of f is b -&gt; c, we arrange them into a new function which has a type of a -&gt; c, so that its parameter is passed between those functions. Now what if those two functions were monadic, that is, what if the values they returned were monadic values? If we had a function of type a -&gt; m b, we couldn't just pass its result to a function of type b -&gt; m c, because that function accepts a normal b, not a monadic one. We could however, use &gt;&gt;= to make that happen. So by using &gt;&gt;=, we can compose two monadic functions:</p>
<pre><code>(&lt;=&lt;) :: (Monad m) =&gt; (b -&gt; m c) -&gt; (a -&gt; m b) -&gt; (a -&gt; m c)  
f &lt;=&lt; g = (\x -&gt; g x &gt;&gt;= f)
</code></pre>
<p>So now we can compose two monadic functions:</p>
<pre><code>ghci&gt; let f x = [x,-x]  
ghci&gt; let g x = [x*3,x*2]  
ghci&gt; let h = f &lt;=&lt; g  
ghci&gt; h 3  
[9,-9,6,-6]
</code></pre>
<p>Cool. So what does that have to do with the associativity law? Well, when we look at the law as a law of compositions, it states that f &lt;=&lt; (g &lt;=&lt; h) should be the same as (f &lt;=&lt; g) &lt;=&lt; h. This is just another way of saying that for monads, the nesting of operations shouldn't matter.</p>
<p>If we translate the first two laws to use &lt;=&lt;, then the left identity law states that for every monadic function f, f &lt;=&lt; return is the same as writing just f and the right identity law says that return &lt;=&lt; f is also no different from f.</p>
<p>This is very similar to how if f is a normal function, (f . g) . h is the same as f . (g . h), f . id is always the same as f and id . f is also just f.</p>
<p>In this chapter, we took a look at the basics of monads and learned how the Maybe monad and the list monad work. In the next chapter, we'll take a look at a whole bunch of other cool monads and we'll also learn how to make our own.</p>
<pre><code>Functors, Applicative Functors and Monoids Table of contents For a Few Monads More
</code></pre></article>
 
</slide>


<slide class="thank-you-slide segue nobackground">
  <aside class="gdbar right"><img src="images/logo.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <h2>&lt;Domande?&gt;</h2>
  </article>
  <p class="auto-fadein" data-config-contact>
    Michele Tomaiuolo
    <br>
    Palazzina 1, int. 5708
    <br>
    Ingegneria dell'Informazione, UniPR
    <br>
    <a href="http://www.ce.unipr.it/people/tomamic">www.ce.unipr.it/people/tomamic</a>
  </p>
</slide>

<slide class="backdrop"></slide>

</slides>

</body>
</html>